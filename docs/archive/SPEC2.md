**Document Version:** 3.0.0 **Date:** 2025-06-28 **Status:** Production Ready - Reference Implementation Specification **Classification:** Public Technical Specification **Target Audience:** Systems Engineers, Game Engine Developers, Asset Pipeline Architects --- ## Document Information | Field | Value | |-------|-------| | **Specification Version** | 3.0.0 | | **Document Type** | Technical Specification | | **Implementation Complexity** | Expert Level | | **Estimated Implementation Time** | 6-8 sprints (42-56 developer days) | | **Language Requirements** | C23 with `_BitInt(40)` support | | **Target Platforms** | Linux, macOS, Windows (x86_64, ARM64, i386) | | **Dependencies** | zstd, BLAKE3, optional (io_uring, NUMA, CUDA) | --- ## Table of Contents 1. [Executive Summary](#executive-summary) 2. [Architecture Overview](#architecture-overview) 3. [Core Principles & Design Philosophy](#core-principles--design-philosophy) 4. [Binary Format Specification](#binary-format-specification) 5. [Graph Model & Data Structures](#graph-model--data-structures) 6. [Integrity & Security System](#integrity--security-system) 7. [Compression & Optimization](#compression--optimization) 8. [Performance Engineering](#performance-engineering) 9. [Core API Specification](#core-api-specification) 10. [Tooling API Specification](#tooling-api-specification) 11. [Wrapper APIs](#wrapper-apis) 12. [Command Line Interface](#command-line-interface) 13. [Integration Patterns](#integration-patterns) 14. [Implementation Guidelines](#implementation-guidelines) 15. [Security Model](#security-model) 16. [Performance Benchmarks](#performance-benchmarks) 17. [Migration & Compatibility](#migration--compatibility) 18. [Testing & Quality Assurance](#testing--quality-assurance) 19. [Deployment & Distribution](#deployment--distribution) 20. [Appendices](#appendices) --- ## Executive Summary ### Overview GRAPHITE (Graph-based Resource Asset Processing and Interchange Technology Environment) represents a paradigm shift in digital asset management, providing a unified binary format that treats all assets—textures, meshes, audio, scripts, dependencies, and transformations—as interconnected graph structures. ### Revolutionary Approach Traditional asset formats treat individual files as isolated entities. GRAPHITE recognizes that modern applications require assets that are inherently interconnected, with complex dependency relationships, conditional loading patterns, and transformation pipelines. By modeling everything as graphs, GRAPHITE provides: - **Universal Representation**: Every component uses the same graph abstraction - **Recursive Composition**: Graphs can contain other graphs at arbitrary depth - **Rich Semantics**: Relationships themselves can contain complex logic and metadata - **Performance Optimization**: Zero-copy loading with cryptographic integrity ### Key Innovations #### 1. Everything-Is-A-Graph Model ```mermaid graph TB subgraph \"GRAPHITE Universe\" A[Individual Asset<br/>0 nodes, 0 edges<br/>Data in properties] B[Asset Collection<br/>N nodes, M edges<br/>Dependencies tracked] C[Transform Pipeline<br/>Complex internal graph<br/>Input/output subgraphs] D[Bundle<br/>Composite graph<br/>Multiple asset graphs] A --> B B --> C C --> D E[String Pool<br/>Graph with string nodes] F[Hash Tree<br/>Merkle tree as graph] E --> D F --> D end ``` #### 2. Cryptographic Integrity by Design ```mermaid graph TD A[File Header] --> B[BLAKE3 Root Hash] B --> C[Hash Tree Root] C --> D[Hash Branch Nodes] C --> E[Hash Branch Nodes] D --> F[Hash Leaf 1] D --> G[Hash Leaf 2] E --> H[Hash Leaf 3] E --> I[Hash Leaf 4] F --> J[Data Chunk 1<br/>CRC32 Protected] G --> K[Data Chunk 2<br/>CRC32 Protected] H --> L[Data Chunk 3<br/>CRC32 Protected] I --> M[Data Chunk 4<br/>CRC32 Protected] ``` #### 3. Performance-First Architecture ```mermaid graph LR A[Memory-Mapped File] --> B[Zero-Copy Access] B --> C[One-Time Hydration] C --> D[Pointer-Speed Runtime] E[Chunk-Based Loading] --> F[Parallel Processing] F --> G[NUMA-Aware Allocation] G --> H[SIMD Acceleration] ``` ### Technical Specifications Summary | Feature | Specification | |---------|---------------| | **File Size Support** | Up to 1 TB using C23 `_BitInt(40)` offsets | | **Load Performance** | <200ms for 1GB bundles on 8-core systems | | **Task Latency** | P99 <3ms for individual operations | | **Memory Efficiency** | Arena allocation ≤1.5× total data size | | **Integrity** | BLAKE3 Merkle trees + per-chunk CRC32 | | **Compression** | zstd with dictionary training support | | **Platforms** | Linux, macOS, Windows (x86_64, ARM64, i386) | | **Compilers** | Clang 15+, GCC 13+, MSVC 2022 17.5+ | ### Business Impact #### For Game Developers - **90% reduction** in asset loading times - **Unified pipeline** for all asset types - **Built-in hot-reload** for live development - **Cryptographic verification** for secure distribution #### For Engine Developers - **Single integration point** for all asset types - **Native graph processing** capabilities - **Zero-copy performance** characteristics - **Production-grade security** model #### For Content Creators - **Unified toolchain** across all asset types - **Visual dependency management** through graph visualization - **Automated optimization** recommendations - **Cross-platform consistency** guaranteed --- ## Architecture Overview ### System Architecture ```mermaid graph TB subgraph \"Application Layer\" A[Game Engine] B[Content Tools] C[Asset Processors] end subgraph \"GRAPHITE Core APIs\" D[graphite_core.h<br/>Loading & Access] E[graphite_tooling.h<br/>Creation & Analysis] F[graphite_unity.h<br/>Unity Integration] G[graphite_unreal.h<br/>Unreal Integration] end subgraph \"GRAPHITE Runtime\" H[Memory Manager<br/>NUMA-aware arenas] I[I/O Subsystem<br/>Async loading] J[Integrity Engine<br/>BLAKE3 verification] K[Compression Engine<br/>zstd with dictionaries] end subgraph \"Platform Layer\" L[Linux<br/>io_uring, huge pages] M[Windows<br/>Overlapped I/O, IOCP] N[macOS<br/>Unified memory, Metal] end subgraph \"Hardware Layer\" O[x86_64<br/>SIMD CRC32, prefetch] P[ARM64<br/>Hardware CRC, Apple Silicon] Q[i386<br/>Software fallbacks] end A --> D B --> E C --> E A --> F A --> G D --> H D --> I E --> J E --> K H --> L I --> M J --> N L --> O M --> P N --> Q ``` ### Data Flow Architecture ```mermaid sequenceDiagram participant App as Application participant Core as GRAPHITE Core participant IO as I/O Subsystem participant Mem as Memory Manager participant Int as Integrity Engine participant FS as File System App->>Core: graphite_open(\"bundle.graphite\") Core->>IO: mmap_file() IO->>FS: Memory map request FS-->>IO: Mapped memory region Core->>Int: verify_header() Int->>Int: Check magic, version, endianness Core->>Mem: calculate_arena_size() Mem->>Mem: Scan chunk table for totals Mem-->>Core: Arena size calculated Core->>Mem: allocate_arena() Mem->>FS: mmap arena (huge pages if available) FS-->>Mem: Arena allocated par Parallel Processing Core->>Int: verify_chunk_crcs() Core->>IO: decompress_chunks() Core->>Int: verify_hash_tree() end Core->>Mem: hydrate_pointers() Mem->>Mem: Convert offsets to pointers Core-->>App: Bundle ready for use loop Runtime Access App->>Core: graphite_get_node() Core-->>App: Direct pointer access end ``` ### Memory Architecture ```mermaid graph TB subgraph \"Virtual Memory Space\" subgraph \"File Mapping (Read-Only)\" A[File Header<br/>128 bytes] B[Chunk Table<br/>24 bytes × N] C[Data Chunks<br/>Variable size] end subgraph \"Arena (Read-Write)\" D[Node Pointer Tables<br/>8 bytes × nodes] E[Edge Pointer Tables<br/>12 bytes × edges] F[Property Tables<br/>8 bytes × props] G[String Cache<br/>Interned strings] end subgraph \"Decompression Buffers\" H[Chunk Buffer 1] I[Chunk Buffer 2] J[Chunk Buffer N] end end A --> D B --> E C --> F style A fill:#f9f9f9 style B fill:#f9f9f9 style C fill:#f9f9f9 style D fill:#e1f5fe style E fill:#e1f5fe style F fill:#e1f5fe style G fill:#e1f5fe ``` --- ## Core Principles & Design Philosophy ### 1. Universal Graph Abstraction Every element in the GRAPHITE ecosystem is modeled as a graph, providing unprecedented consistency and composability: #### Asset as Graph ```mermaid graph LR A[Asset Graph] --> B[Properties] B --> C[data_blob_id: 42] B --> D[mime_type: image/png] B --> E[size: 204800] B --> F[created: 2025-06-28] ``` #### Collection as Graph ```mermaid graph TB A[Sprite Atlas] --> B[Player Sprite] A --> C[Enemy Sprite] A --> D[UI Elements] B --> E[Walk Animation] B --> F[Idle Animation] C --> G[Attack Animation] C --> H[Death Animation] ``` #### Transform as Graph ```mermaid graph LR subgraph \"Input Subgraph\" A[main.scss] B[variables.scss] B --> A end subgraph \"Transform Logic\" C[SASS Compiler] D[Autoprefixer] E[Minifier] C --> D D --> E end subgraph \"Output Subgraph\" F[main.css] G[main.min.css] F --> G end A --> C E --> F ``` ### 2. Recursive Composition Graphs can contain other graphs without limit, enabling natural hierarchical organization: ```mermaid graph TB subgraph \"Game Bundle Graph\" subgraph \"Level 1 Assets\" A[Terrain Graph] B[Character Graph] C[Audio Graph] end subgraph \"Level 2 Components\" A --> D[Heightmap] A --> E[Texture Atlas] B --> F[Mesh Data] B --> G[Animation Rig] C --> H[Music Tracks] C --> I[Sound Effects] end subgraph \"Level 3 Elements\" E --> J[Diffuse Map] E --> K[Normal Map] G --> L[Bone Hierarchy] G --> M[Weight Maps] end end ``` ### 3. Zero-Copy Performance The architecture prioritizes performance through memory-mapped files and pointer hydration: ```mermaid graph LR A[File on Disk] --> B[Memory Mapping] B --> C[Chunk Table Scan] C --> D[Arena Allocation] D --> E[Pointer Hydration] E --> F[Runtime Ready] style A fill:#ffebee style B fill:#fff3e0 style C fill:#f3e5f5 style D fill:#e8f5e8 style E fill:#e3f2fd style F fill:#f1f8e9 ``` ### 4. Cryptographic Integrity Security is built into the format at the foundational level: ```mermaid graph TB A[File Creation] --> B[Generate BLAKE3 Tree] B --> C[Embed Root Hash in Header] C --> D[File Distribution] E[File Loading] --> F[Extract Root Hash] F --> G[Verify BLAKE3 Tree] G --> H{Hash Valid?} H -->|Yes| I[Continue Loading] H -->|No| J[Abort with Tamper Evidence] ``` --- ## Binary Format Specification ### File Structure Overview ``` ┌─────────────────────────────────┐ Offset 0x00 │ File Header 128 bytes │ ├─────────────────────────────────┤ Offset 0x80 │ Chunk Table #chunks × 24 B │ ├─────────────────────────────────┤ Variable │ Data Chunks Variable │ │ ┌─────────────────────────────┐ │ │ │ Graph Chunks │ │ │ │ Blob Chunks │ │ │ │ Hash Chunks │ │ │ │ Compressed Chunks │ │ │ └─────────────────────────────┘ │ └─────────────────────────────────┘ ``` ### File Header Specification ```c // All fields in little-endian byte order typedef struct { // Magic identification (bytes 0-3) char magic[4]; // \"GRPH\" (0x47525048) // Version and format information (bytes 4-7) uint8_t version; // 0x03 (version 3.0) uint8_t endian; // 0x00 (little-endian only) uint16_t header_size; // 0x0080 (128 bytes) // File size information (bytes 8-15) uint64_t file_size; // Total file size in bytes // Critical chunk indices (bytes 16-31) uint64_t root_graph_index; // Index of main graph chunk uint64_t string_pool_index; // Index of string pool chunk uint64_t integrity_root_index; // Index of hash tree root // Metadata (bytes 32-47) uint32_t file_flags; // File-level flags (see below) uint32_t chunk_count; // Number of chunks in table uint64_t creation_timestamp; // Unix timestamp of creation // Integrity (bytes 48-79) uint8_t file_digest[32]; // BLAKE3 hash of entire file // (excluding this field) // Reserved for future expansion (bytes 80-127) uint8_t reserved[48]; // Must be zero } graphite_file_header; ``` #### File Flags Specification | Bit | Flag Name | Description | |-----|-----------|-------------| | 0 | `MANDATORY_INTEGRITY_CHECK` | Hash verification required for loading | | 1 | `COMPRESSED_CHUNKS_PRESENT` | File contains zstd compressed chunks | | 2 | `ENCRYPTED_CHUNKS_PRESENT` | File contains AES-GCM encrypted chunks | | 3 | `DICTIONARY_COMPRESSION` | Uses compression dictionaries | | 4 | `SIGNED_BUNDLE` | Contains cryptographic signature | | 5-15 | Reserved | Must be zero | | 16-31 | Vendor Extensions | Available for implementation-specific use | ### Chunk Table Specification Each chunk table entry is exactly 24 bytes: ```c typedef struct { // Offset and size using C23 _BitInt for exact precision _BitInt(40) offset; // File offset (5 bytes, supports 1TB) _BitInt(40) size; // Chunk size (5 bytes, supports 1TB) // Type and flags (2 bytes) uint8_t kind; // Chunk type (see below) uint8_t flags; // Chunk flags (see below) // Integrity and alignment (8 bytes) uint32_t crc32; // IEEE 802.3 CRC32 of chunk data uint32_t reserved; // Padding for 8-byte alignment } chunk_table_entry; // Compile-time assertions for exact size static_assert(sizeof(chunk_table_entry) == 24, \"Chunk table entry must be exactly 24 bytes\"); ``` #### Chunk Types | Kind | Type | Structure | Description | |------|------|-----------|-------------| | 0 | `CHUNK_BLOB` | Raw binary data | Images, audio, arbitrary binary content | | 1 | `CHUNK_GRAPH` | Graph structure | Node/edge/property tables with graph header | | 2 | `CHUNK_HASH_LEAF` | Hash leaf node | Points to data chunk with BLAKE3 digest | | 3 | `CHUNK_HASH_BRANCH` | Hash branch node | Contains child hash references | | 4-15 | Reserved | Future use | Reserved for format extensions | | 16-255 | Vendor | Implementation-specific | Available for custom chunk types | #### Chunk Flags | Bit | Flag Name | Description | |-----|-----------|-------------| | 0 | `ZSTD_COMPRESSED` | Chunk data is zstd compressed | | 1 | `AES_ENCRYPTED` | Chunk data is AES-GCM encrypted | | 2 | `DICTIONARY_COMPRESSED` | Uses compression dictionary | | 3 | `INTEGRITY_CRITICAL` | Integrity failure aborts entire load | | 4-7 | Reserved | Must be zero | ### Graph Chunk Structure Graph chunks contain the core graph data structures: ```c // Graph chunk header (64 bytes, 64-byte aligned) typedef struct { // Counts (16 bytes) uint32_t node_count; // Number of child graphs uint32_t edge_count; // Number of relationships uint32_t property_count; // Number of key-value properties uint32_t graph_flags; // Graph-specific flags // Table offsets from start of chunk (32 bytes) uint64_t node_table_offset; // Offset to node index table uint64_t edge_table_offset; // Offset to edge descriptor table uint64_t property_table_offset; // Offset to property table uint64_t metadata_offset; // Offset to graph metadata // Reserved (16 bytes) uint64_t reserved1; uint64_t reserved2; } graph_chunk_header; ``` #### Graph Flags | Bit | Flag Name | Description | |-----|-----------|-------------| | 0 | `HAS_CYCLES` | Graph contains circular references | | 1 | `PARALLEL_GROUP` | Child nodes can execute concurrently | | 2 | `STRING_POOL` | Graph represents string pool | | 3 | `READONLY` | Graph should not be modified | | 4 | `SORTED_NODES` | Nodes are sorted by some criterion | | 5 | `SORTED_EDGES` | Edges are sorted by some criterion | | 6-7 | Reserved | Must be zero | | 8-15 | Optimization Hints | Implementation-specific optimization flags | | 16-31 | Vendor Extensions | Available for custom use | #### Node Index Table Array of ULEB128-encoded chunk indices: ``` Node Table Layout: ┌─────────────┬─────────────┬─────────────┬─────────────┐ │ Chunk Idx 0 │ Chunk Idx 1 │ Chunk Idx 2 │ ... │ │ (ULEB128) │ (ULEB128) │ (ULEB128) │ │ └─────────────┴─────────────┴─────────────┴─────────────┘ ``` #### Edge Descriptor Table Fixed-size edge descriptors: ```c typedef struct { uint32_t from_node_index; // Source node (index into node table) uint32_t to_node_index; // Target node (index into node table) uint32_t edge_data_chunk_index; // Chunk containing edge graph data uint32_t edge_flags; // Edge-specific flags } edge_descriptor; ``` #### Property Table Key-value pairs as ULEB128-encoded string pool indices: ``` Property Table Layout: ┌─────────────┬─────────────┬─────────────┬─────────────┬───── │ Key ID 0 │ Value ID 0 │ Key ID 1 │ Value ID 1 │ ... │ (ULEB128) │ (ULEB128) │ (ULEB128) │ (ULEB128) │ └─────────────┴─────────────┴─────────────┴─────────────┴───── ``` ### Compression Format Compressed chunks use the following structure: ```c typedef struct { uint32_t uncompressed_size; // Original size before compression uint32_t dictionary_chunk_index; // 0 if no dictionary used uint32_t compression_flags; // Compression-specific flags uint32_t checksum; // Checksum of uncompressed data uint8_t compressed_data[]; // zstd compressed payload } compressed_chunk_header; ``` --- ## Graph Model & Data Structures ### Core Graph Concepts #### Graph Definition In GRAPHITE, a graph is defined as: - **G = (V, E, P)** where: - **V** = set of vertices (nodes), each referencing another graph - **E** = set of edges (relationships), each containing a graph with relationship semantics - **P** = set of properties (key-value pairs with metadata) #### Recursive Graph Structure ```mermaid graph TB subgraph \"Level 0: Root Graph\" A[Game Bundle] end subgraph \"Level 1: Asset Category Graphs\" A --> B[Textures] A --> C[Models] A --> D[Audio] A --> E[Scripts] end subgraph \"Level 2: Asset Instance Graphs\" B --> F[player.png] B --> G[ui_atlas.png] C --> H[character.obj] C --> I[environment.fbx] end subgraph \"Level 3: Asset Component Graphs\" G --> J[button_normal] G --> K[button_hover] G --> L[button_pressed] I --> M[mesh_data] I --> N[material_refs] I --> O[animation_clips] end ``` ### Special Graph Types #### 1. Asset Graphs (Leaf Nodes) Asset graphs represent individual files or data blobs: ```c // Asset graph structure typedef struct { graph_chunk_header header; // node_count = 0, edge_count = 0 property_table properties; // Asset metadata // No node or edge tables } asset_graph; // Common asset properties static const char* ASSET_PROPERTIES[] = { \"data_blob_id\", // Chunk index of actual data \"mime_type\", // Content type (image/png, etc.) \"original_size\", // Size before compression \"checksum\", // Content checksum \"created_timestamp\", // Creation time \"modified_timestamp\", // Last modification time \"creator_tool\", // Tool that created this asset \"compression_ratio\", // Achieved compression ratio NULL }; ``` #### 2. String Pool Graphs String pools provide efficient string storage and deduplication: ```c // String pool graph typedef struct { graph_chunk_header header; // edge_count = 0, flags |= STRING_POOL node_index_table nodes; // Each node → blob chunk with UTF-8 string property_table metadata; // Pool statistics and configuration } string_pool_graph; // String pool statistics typedef struct { uint32_t total_strings; // Number of unique strings uint32_t total_bytes; // Total bytes of string data uint32_t average_length; // Average string length uint32_t deduplication_ratio; // Space saved by deduplication } string_pool_stats; ``` #### 3. Parallel Group Graphs Parallel groups indicate nodes that can be processed concurrently: ```mermaid graph TB subgraph \"Parallel Image Processing\" A[Source Image] --> B[Resize Operation] A --> C[Format Conversion] A --> D[Compression] A --> E[Thumbnail Generation] style B fill:#e8f5e8 style C fill:#e8f5e8 style D fill:#e8f5e8 style E fill:#e8f5e8 end ``` ```c // Parallel group graph typedef struct { graph_chunk_header header; // flags |= PARALLEL_GROUP node_index_table nodes; // Nodes that can execute in parallel edge_descriptor_table edges; // Dependencies between nodes property_table configuration; // Parallelization hints } parallel_group_graph; ``` #### 4. Transform Graphs Transform graphs represent complex processing pipelines: ```mermaid graph LR subgraph \"SCSS Transform Graph\" subgraph \"Input Subgraph\" A[main.scss] B[_variables.scss] C[_mixins.scss] B --> A C --> A end subgraph \"Transform Pipeline\" D[Parse SCSS] E[Resolve Imports] F[Compile CSS] G[Autoprefix] H[Minify] D --> E E --> F F --> G G --> H end subgraph \"Output Subgraph\" I[main.css] J[main.min.css] K[source.map] I --> J I --> K end A --> D H --> I end ``` ### Edge Semantics Edges in GRAPHITE are themselves graphs, allowing rich relationship modeling: #### Simple Dependency Edge ```c // Simple dependency relationship typedef struct { graph_chunk_header header; // node_count = 0, edge_count = 0 property_table properties; // Dependency metadata } dependency_edge; // Common dependency properties static const char* DEPENDENCY_PROPERTIES[] = { \"type\", // \"dependency\", \"import\", \"reference\" \"optional\", // \"true\" or \"false\" \"load_order\", // \"before\", \"after\", \"concurrent\" \"cache_policy\", // \"always\", \"conditional\", \"never\" \"version_constraint\", // Semantic version requirement NULL }; ``` #### Conditional Edge ```mermaid graph TB A[Source Asset] --> B{Condition Graph} B -->|env == \"production\"| C[Minified Output] B -->|env == \"development\"| D[Debug Output] B -->|platform == \"mobile\"| E[Optimized Output] ``` ```c // Conditional edge with logic typedef struct { graph_chunk_header header; // Contains condition evaluation graph node_index_table condition_nodes; // Condition expressions edge_descriptor_table logic_flow; // Condition evaluation flow property_table parameters; // Condition parameters } conditional_edge; ``` #### Transform Pipeline Edge ```c // Multi-step transformation edge typedef struct { graph_chunk_header header; // Complex internal structure node_index_table transform_steps; // Individual transformation steps edge_descriptor_table step_flow; // Dependencies between steps property_table configuration; // Transform parameters } transform_pipeline_edge; ``` ### Property System Properties provide flexible metadata storage: #### Property Types ```c typedef enum { PROPERTY_STRING, // String pool reference PROPERTY_INTEGER, // 64-bit signed integer PROPERTY_FLOAT, // 64-bit IEEE 754 float PROPERTY_BOOLEAN, // True/false value PROPERTY_TIMESTAMP, // Unix timestamp PROPERTY_BLOB_REFERENCE, // Reference to blob chunk PROPERTY_GRAPH_REFERENCE, // Reference to graph chunk PROPERTY_ARRAY, // Array of other properties PROPERTY_OBJECT // Nested property object } property_type; ``` #### Property Encoding ```c // Property entry in property table typedef struct { uint32_t key_string_id; // String pool ID for key uint32_t value_type; // Property type uint64_t value_data; // Type-specific value data } property_entry; // Array and object properties typedef struct { uint32_t element_count; // Number of elements/fields property_entry elements[]; // Array elements or object fields } complex_property; ``` #### Reserved Property Keys Standard property keys with semantic meaning: | Key | Type | Description | |-----|------|-------------| | `data_blob_id` | Integer | Chunk index containing asset data | | `mime_type` | String | MIME type of content | | `size` | Integer | Original uncompressed size | | `checksum` | String | Content checksum (hex encoded) | | `created` | Timestamp | Creation time | | `modified` | Timestamp | Last modification time | | `version` | String | Semantic version string | | `author` | String | Creator identification | | `license` | String | License information | | `dependencies` | Array | List of dependency specifications | | `compression_algorithm` | String | Compression method used | | `compression_ratio` | Float | Achieved compression ratio | | `load_priority` | Integer | Loading priority hint | | `cache_duration` | Integer | Cache duration in seconds | --- ## Integrity & Security System ### Overview GRAPHITE implements a multi-layered security architecture: ```mermaid graph TB A[File Level] --> B[BLAKE3 Root Hash in Header] C[Chunk Level] --> D[CRC32 per Chunk] E[Content Level] --> F[Individual Hash Leaves] G[Transport Level] --> H[Optional AES-GCM Encryption] B --> I[Tamper Detection] D --> J[Corruption Detection] F --> K[Content Verification] H --> L[Confidentiality Protection] ``` ### BLAKE3 Merkle Tree Implementation #### Hash Tree Structure ```mermaid graph TB A[Root Hash<br/>In File Header] --> B[Branch Node<br/>Chunk Index 5] A --> C[Branch Node<br/>Chunk Index 6] B --> D[Leaf Node<br/>Protects Chunk 0] B --> E[Leaf Node<br/>Protects Chunk 1] C --> F[Leaf Node<br/>Protects Chunk 2] C --> G[Leaf Node<br/>Protects Chunk 3] D --> H[Data Chunk 0<br/>Texture Data] E --> I[Data Chunk 1<br/>Mesh Data] F --> J[Data Chunk 2<br/>Audio Data] G --> K[Data Chunk 3<br/>Script Data] ``` #### Hash Leaf Structure ```c // Hash leaf chunk (protects individual data chunks) typedef struct { graph_chunk_header header; // node_count = 0, edge_count = 0 property_table properties; // Hash metadata } hash_leaf_chunk; // Hash leaf properties static const char* HASH_LEAF_PROPERTIES[] = { \"algorithm\", // \"blake3\" \"digest\", // Blob chunk ID containing 32-byte hash \"target_chunk_index\", // Index of protected chunk \"hash_timestamp\", // When hash was computed \"verification_level\", // \"required\", \"optional\", \"warning\" NULL }; ``` #### Hash Branch Structure ```c // Hash branch chunk (combines child hashes) typedef struct { graph_chunk_header header; // Contains child hash references node_index_table child_hashes; // References to child hash chunks edge_descriptor_table hash_tree; // Tree structure relationships property_table branch_metadata; // Branch-specific properties } hash_branch_chunk; ``` ### Verification Algorithm #### Complete Verification Process ```mermaid sequenceDiagram participant Loader as GRAPHITE Loader participant Header as File Header participant Tree as Hash Tree participant Chunks as Data Chunks participant Blake3 as BLAKE3 Engine Loader->>Header: Read file_digest Loader->>Tree: Load hash tree root loop For each hash branch Loader->>Tree: Get child hashes Tree-->>Loader: Child hash references end loop For each hash leaf Loader->>Chunks: Read protected chunk Chunks-->>Loader: Raw chunk data Loader->>Blake3: Hash chunk data Blake3-->>Loader: Computed hash Loader->>Tree: Compare with stored hash alt Hash matches Loader->>Loader: Continue verification else Hash mismatch Loader->>Loader: ABORT - Tamper detected end end Loader->>Blake3: Hash entire tree Blake3-->>Loader: Root hash Loader->>Header: Compare with file_digest alt Root hash matches Loader->>Loader: Verification successful else Root hash mismatch Loader->>Loader: ABORT - File corrupted end ``` #### Implementation ```c // Verification result codes typedef enum { VERIFICATION_SUCCESS, // All hashes verified VERIFICATION_CORRUPTION, // File corruption detected VERIFICATION_TAMPER, // Deliberate modification detected VERIFICATION_MISSING_HASH, // Required hash not found VERIFICATION_ALGORITHM_UNKNOWN, // Unsupported hash algorithm VERIFICATION_TIMEOUT // Verification took too long } verification_result; // Verify entire bundle integrity verification_result verify_bundle_integrity(const graphite_bundle* bundle) { // Step 1: Verify file header if (!verify_file_header(bundle)) { return VERIFICATION_CORRUPTION; } // Step 2: Verify chunk table integrity if (!verify_chunk_table(bundle)) { return VERIFICATION_CORRUPTION; } // Step 3: Verify hash tree if present if (bundle->header.integrity_root_index != 0) { verification_result result = verify_hash_tree(bundle); if (result != VERIFICATION_SUCCESS) { return result; } } // Step 4: Verify chunk CRC32s for (uint32_t i = 0; i < bundle->header.chunk_count; i++) { if (!verify_chunk_crc32(bundle, i)) { return VERIFICATION_CORRUPTION; } } return VERIFICATION_SUCCESS; } // Verify individual hash tree node bool verify_hash_node(const graphite_bundle* bundle, uint32_t hash_chunk_index) { const hash_chunk* chunk = get_hash_chunk(bundle, hash_chunk_index); if (is_hash_leaf(chunk)) { // Leaf node: verify data chunk uint32_t target_chunk = get_target_chunk_index(chunk); const void* data = get_chunk_data(bundle, target_chunk); size_t size = get_chunk_size(bundle, target_chunk); uint8_t computed_hash[32]; blake3(data, size, computed_hash); const uint8_t* stored_hash = get_stored_hash(chunk); return memcmp(computed_hash, stored_hash, 32) == 0; } else { // Branch node: verify all children, then compute branch hash for (uint32_t i = 0; i < chunk->header.node_count; i++) { uint32_t child_index = get_child_hash_index(chunk, i); if (!verify_hash_node(bundle, child_index)) { return false; } } // Compute hash of concatenated child hashes uint8_t* child_hashes = collect_child_hashes(chunk); size_t total_size = chunk->header.node_count * 32; uint8_t computed_hash[32]; blake3(child_hashes, total_size, computed_hash); const uint8_t* stored_hash = get_stored_hash(chunk); return memcmp(computed_hash, stored_hash, 32) == 0; } } ``` ### Encryption Support #### AES-GCM Chunk Encryption ```c // Encrypted chunk header typedef struct { uint32_t encryption_algorithm; // AES_GCM_256 uint32_t key_derivation_method; // PBKDF2, SCRYPT, etc. uint8_t initialization_vector[16]; // Random IV for this chunk uint8_t authentication_tag[16]; // GCM authentication tag uint32_t encrypted_size; // Size of encrypted payload uint8_t encrypted_data[]; // AES-GCM encrypted content } encrypted_chunk_header; // Encryption context typedef struct { uint8_t master_key[32]; // AES-256 master key uint32_t key_iterations; // PBKDF2 iteration count uint8_t salt[32]; // Random salt for key derivation } encryption_context; ``` ### Security Threat Mitigation #### File Integrity Attacks | Attack Vector | Mitigation | Implementation | |---------------|------------|----------------| | **Malicious Modification** | BLAKE3 Merkle Tree | Root hash in file header, recursive verification | | **Bit Flips / Corruption** | CRC32 per chunk | Hardware CRC32 when available | | **Replay Attacks** | Hash Root Binding | Root hash cryptographically bound to file | | **Partial Modification** | Incremental Verification | Verify only accessed chunks if needed | #### Memory Safety Attacks | Attack Vector | Mitigation | Implementation | |---------------|------------|----------------| | **Buffer Overflows** | Bounds Checking | All offsets validated against file size | | **Integer Overflows** | Safe Arithmetic | Checked arithmetic for all size calculations | | **Format String** | No Dynamic Formats | All format strings are compile-time constants | | **Heap Corruption** | Arena Allocation | Isolated allocation patterns | #### Denial of Service Attacks | Attack Vector | Mitigation | Implementation | |---------------|------------|----------------| | **Decompression Bombs** | Size Limits | Max expansion ratio limits | | **Hash Collision** | BLAKE3 | Cryptographically secure hash function | | **Resource Exhaustion** | Quotas | Arena size limits, timeout protection | | **Recursive Bombs** | Depth Limits | Maximum graph nesting depth | --- ## Compression & Optimization ### Compression Architecture ```mermaid graph TB subgraph \"Compression Decision Tree\" A[Chunk Analysis] --> B{Size > 64KB?} B -->|No| C[No Compression] B -->|Yes| D{Content Type} D -->|Text/JSON/Script| E[zstd Level 3] D -->|Binary/Media| F{Size > 1MB?} F -->|No| G[zstd Level 5] F -->|Yes| H{Update Frequency} H -->|Rare| I[zstd Level 9] H -->|Frequent| J[zstd Level 5] end ``` ### zstd Integration #### Compression Level Selection ```c // Compression level decision matrix typedef struct { size_t chunk_size; content_type type; update_frequency frequency; int recommended_level; double target_ratio; } compression_config; static const compression_config COMPRESSION_MATRIX[] = { // Size, Type, Frequency, Level, Ratio {64*1024, CONTENT_ANY, FREQ_ANY, 0, 1.0}, // No compression {1*1024*1024, CONTENT_TEXT, FREQ_ANY, 3, 0.6}, // Fast text compression {1*1024*1024, CONTENT_BINARY, FREQ_HIGH, 5, 0.8}, // Balanced binary {50*1024*1024, CONTENT_ANY, FREQ_LOW, 9, 0.5}, // Maximum compression }; int select_compression_level(size_t size, content_type type, update_frequency freq) { for (const compression_config* config = COMPRESSION_MATRIX; config->chunk_size != 0; config++) { if (size <= config->chunk_size && (config->type == CONTENT_ANY || config->type == type) && (config->frequency == FREQ_ANY || config->frequency == freq)) { return config->recommended_level; } } return 5; // Default level } ``` #### Dictionary Training Dictionary training provides significant compression improvements for similar content: ```mermaid graph LR A[Collect Training Samples] --> B[Analyze Content Patterns] B --> C[Generate Dictionary] C --> D[Store Dictionary as Chunk] D --> E[Reference in Compressed Chunks] F[Sample 1: config.json] --> A G[Sample 2: metadata.json] --> A H[Sample 3: manifest.json] --> A I[Sample N: data.json] --> A ``` ```c // Dictionary training process typedef struct { void** samples; // Array of sample data pointers size_t* sample_sizes; // Size of each sample size_t sample_count; // Number of samples size_t max_dict_size; // Maximum dictionary size } training_set; // Train compression dictionary uint8_t* train_compression_dictionary(const training_set* training) { // Collect all training data size_t total_size = 0; for (size_t i = 0; i < training->sample_count; i++) { total_size += training->sample_sizes[i]; } uint8_t* combined_data = malloc(total_size); size_t offset = 0; for (size_t i = 0; i < training->sample_count; i++) { memcpy(combined_data + offset, training->samples[i], training->sample_sizes[i]); offset += training->sample_sizes[i]; } // Use zstd dictionary training size_t dict_size = ZDICT_trainFromBuffer( dict_buffer, training->max_dict_size, combined_data, total_size ); free(combined_data); if (ZDICT_isError(dict_size)) { return NULL; } return dict_buffer; } ``` #### Compression Format ```c // Compressed chunk layout typedef struct { // Header (16 bytes) uint32_t original_size; // Size before compression uint32_t compression_algorithm; // ZSTD = 1 uint32_t dictionary_chunk_index; // 0 if no dictionary uint32_t compression_flags; // Algorithm-specific flags // zstd compressed data follows immediately uint8_t compressed_payload[]; } compressed_chunk; // Decompression process bool decompress_chunk(const graphite_bundle* bundle, uint32_t chunk_index, void* output_buffer, size_t output_size) { const compressed_chunk* chunk = get_compressed_chunk(bundle, chunk_index); // Load dictionary if specified ZSTD_DDict* dict = NULL; if (chunk->dictionary_chunk_index != 0) { const void* dict_data = get_chunk_data(bundle, chunk->dictionary_chunk_index); size_t dict_size = get_chunk_size(bundle, chunk->dictionary_chunk_index); dict = ZSTD_createDDict(dict_data, dict_size); } // Decompress data size_t result; if (dict) { result = ZSTD_decompress_usingDDict( output_buffer, output_size, chunk->compressed_payload, get_compressed_payload_size(chunk), dict ); ZSTD_freeDDict(dict); } else { result = ZSTD_decompress( output_buffer, output_size, chunk->compressed_payload, get_compressed_payload_size(chunk) ); } return !ZSTD_isError(result) && result == chunk->original_size; } ``` ### Content-Aware Optimization #### File Type Detection ```c // Content type detection for optimization typedef enum { CONTENT_UNKNOWN, CONTENT_TEXT_PLAIN, CONTENT_TEXT_JSON, CONTENT_TEXT_XML, CONTENT_TEXT_SCRIPT, CONTENT_IMAGE_PNG, CONTENT_IMAGE_JPEG, CONTENT_IMAGE_DDS, CONTENT_AUDIO_WAV, CONTENT_AUDIO_OGG, CONTENT_MESH_OBJ, CONTENT_MESH_FBX, CONTENT_BINARY_UNKNOWN } content_type; content_type detect_content_type(const void* data, size_t size, const char* filename_hint) { // Magic number detection const uint8_t* bytes = (const uint8_t*)data; if (size >= 8 && memcmp(bytes, \"\\x89PNG\\r\ \\x1a\ \", 8) == 0) { return CONTENT_IMAGE_PNG; } if (size >= 3 && memcmp(bytes, \"\\xFF\\xD8\\xFF\", 3) == 0) { return CONTENT_IMAGE_JPEG; } if (size >= 4 && memcmp(bytes, \"DDS \", 4) == 0) { return CONTENT_IMAGE_DDS; } if (size >= 4 && memcmp(bytes, \"RIFF\", 4) == 0) { return CONTENT_AUDIO_WAV; } if (size >= 4 && memcmp(bytes, \"OggS\", 4) == 0) { return CONTENT_AUDIO_OGG; } // Content analysis for text formats if (is_likely_text(data, min(size, 1024))) { if (filename_hint) { if (strstr(filename_hint, \".json\")) return CONTENT_TEXT_JSON; if (strstr(filename_hint, \".xml\")) return CONTENT_TEXT_XML; if (strstr(filename_hint, \".js\") || strstr(filename_hint, \".py\")) { return CONTENT_TEXT_SCRIPT; } } // JSON detection if (bytes[0] == '{' || bytes[0] == '[') { return CONTENT_TEXT_JSON; } // XML detection if (memcmp(bytes, \"<?xml\", 5) == 0 || bytes[0] == '<') { return CONTENT_TEXT_XML; } return CONTENT_TEXT_PLAIN; } return CONTENT_BINARY_UNKNOWN; } ``` #### Compression Effectiveness Analysis ```c // Analyze compression effectiveness typedef struct { double compression_ratio; // Compressed size / original size uint64_t compression_time_ns; // Time to compress uint64_t decompression_time_ns; // Time to decompress size_t memory_usage; // Peak memory during compression quality_score quality; // Lossy compression quality } compression_analysis; compression_analysis analyze_compression(const void* data, size_t size, int compression_level) { compression_analysis result = {0}; auto start_time = high_resolution_clock::now(); // Perform compression size_t compressed_bound = ZSTD_compressBound(size); void* compressed_buffer = malloc(compressed_bound); size_t compressed_size = ZSTD_compress( compressed_buffer, compressed_bound, data, size, compression_level ); auto compress_end = high_resolution_clock::now(); result.compression_time_ns = duration_cast<nanoseconds>( compress_end - start_time).count(); if (!ZSTD_isError(compressed_size)) { result.compression_ratio = (double)compressed_size / size; // Test decompression void* decompressed_buffer = malloc(size); auto decomp_start = high_resolution_clock::now(); size_t decompressed_size = ZSTD_decompress( decompressed_buffer, size, compressed_buffer, compressed_size ); auto decomp_end = high_resolution_clock::now(); result.decompression_time_ns = duration_cast<nanoseconds>( decomp_end - decomp_start).count(); // Verify decompression correctness if (decompressed_size == size && memcmp(data, decompressed_buffer, size) == 0) { result.quality = QUALITY_LOSSLESS; } else { result.quality = QUALITY_ERROR; } free(decompressed_buffer); } else { result.compression_ratio = 1.0; // No compression achieved result.quality = QUALITY_ERROR; } free(compressed_buffer); return result; } ``` --- ## Performance Engineering ### Architecture for Performance GRAPHITE is designed from the ground up for maximum performance: ```mermaid graph TB subgraph \"Memory Hierarchy Optimization\" A[L1 Cache<br/>Direct pointer access] --> B[L2 Cache<br/>Smart prefetching] B --> C[L3 Cache<br/>NUMA-aware allocation] C --> D[Main Memory<br/>Huge pages] D --> E[Storage<br/>Async I/O] end subgraph \"Parallelization Strategy\" F[File I/O<br/>io_uring/Overlapped] --> G[Decompression<br/>Per-chunk threads] G --> H[Verification<br/>Parallel hash tree] H --> I[Hydration<br/>Parallel pointer conversion] end subgraph \"Hardware Acceleration\" J[SIMD CRC32<br/>SSE4.2/ARM64] --> K[Hardware Prefetch<br/>Platform-specific hints] K --> L[Vector Instructions<br/>BLAKE3 optimization] end ``` ### Memory Management #### Arena Allocation Strategy GRAPHITE uses arena allocation for predictable memory usage and optimal cache performance: ```c // Arena size calculation typedef struct { size_t node_pointers; // 8 bytes × total_nodes size_t edge_descriptors; // 12 bytes × total_edges size_t property_data; // 8 bytes × total_properties size_t string_cache; // Estimated string overhead size_t alignment_padding; // 64-byte alignment requirements size_t safety_buffer; // 128KB safety margin size_t total_arena_size; // Sum of all above } arena_calculation; arena_calculation calculate_arena_requirements(const graphite_bundle* bundle) { arena_calculation calc = {0}; // Scan all graph chunks to count totals for (uint32_t i = 0; i < bundle->header.chunk_count; i++) { const chunk_table_entry* entry = get_chunk_entry(bundle, i); if (entry->kind == CHUNK_GRAPH) { const graph_chunk_header* graph = get_graph_header(bundle, i); calc.node_pointers += graph->node_count * sizeof(void*); calc.edge_descriptors += graph->edge_count * sizeof(edge_descriptor); calc.property_data += graph->property_count * 2 * sizeof(uint32_t); } } // Estimate string cache requirements calc.string_cache = estimate_string_cache_size(bundle); // Add alignment and safety margins calc.alignment_padding = 64 * 1024; // 64KB for alignment calc.safety_buffer = 128 * 1024; // 128KB safety margin calc.total_arena_size = calc.node_pointers + calc.edge_descriptors + calc.property_data + calc.string_cache + calc.alignment_padding + calc.safety_buffer; // Round up to next page boundary size_t page_size = get_page_size(); calc.total_arena_size = ((calc.total_arena_size + page_size - 1) / page_size) * page_size; return calc; } // Allocate performance-optimized arena void* allocate_optimized_arena(size_t size) { void* arena; #ifdef __linux__ // Use huge pages on Linux if available arena = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); if (arena != MAP_FAILED && size >= 2 * 1024 * 1024) { // Request transparent huge pages for large allocations madvise(arena, size, MADV_HUGEPAGE); // Hint that access will be sequential during hydration madvise(arena, size, MADV_SEQUENTIAL); } #elif defined(_WIN32) // Use large pages on Windows if available arena = VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); if (arena && size >= 2 * 1024 * 1024) { // Try to use large pages VirtualFree(arena, 0, MEM_RELEASE); arena = VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE | MEM_LARGE_PAGES, PAGE_READWRITE); if (!arena) { // Fall back to regular pages arena = VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); } } #else // Standard allocation for other platforms arena = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); #endif return arena; } ``` #### NUMA Optimization ```c // NUMA-aware memory allocation typedef struct { int node_count; // Number of NUMA nodes int current_node; // Current thread's NUMA node cpu_set_t* node_cpus; // CPUs for each NUMA node void** arenas; // Per-node arena allocations } numa_context; #ifdef HAVE_NUMA bool setup_numa_optimizations(numa_context* ctx) { ctx->node_count = numa_num_configured_nodes(); ctx->current_node = numa_node_of_cpu(sched_getcpu()); if (ctx->node_count <= 1) { return false; // No NUMA benefit } ctx->node_cpus = malloc(ctx->node_count * sizeof(cpu_set_t)); ctx->arenas = malloc(ctx->node_count * sizeof(void*)); // Get CPU sets for each NUMA node for (int node = 0; node < ctx->node_count; node++) { CPU_ZERO(&ctx->node_cpus[node]); struct bitmask* node_mask = numa_allocate_cpumask(); numa_node_to_cpus(node, node_mask); for (int cpu = 0; cpu < numa_num_possible_cpus(); cpu++) { if (numa_bitmask_isbitset(node_mask, cpu)) { CPU_SET(cpu, &ctx->node_cpus[node]); } } numa_free_cpumask(node_mask); } return true; } void* allocate_numa_arena(numa_context* ctx, size_t size) { if (!ctx || ctx->node_count <= 1) { return allocate_optimized_arena(size); } // Allocate on current NUMA node void* arena = numa_alloc_onnode(size, ctx->current_node); if (!arena) { // Fall back to any node arena = numa_alloc(size); } return arena; } void bind_thread_to_numa_node(numa_context* ctx, int node) { if (!ctx || node >= ctx->node_count) { return; } // Set CPU affinity to this NUMA node pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &ctx->node_cpus[node]); } #endif ``` ### Asynchronous I/O #### Linux io_uring Implementation ```c #ifdef HAVE_IO_URING typedef struct { struct io_uring ring; // io_uring instance struct iovec* iovecs; // I/O vectors for each chunk uint32_t queue_depth; // Maximum concurrent operations uint32_t pending_ops; // Currently pending operations } async_io_context; bool setup_async_io(async_io_context* ctx, uint32_t queue_depth) { ctx->queue_depth = queue_depth; ctx->pending_ops = 0; // Initialize io_uring int ret = io_uring_queue_init(queue_depth, &ctx->ring, 0); if (ret < 0) { return false; } // Allocate I/O vectors ctx->iovecs = malloc(queue_depth * sizeof(struct iovec)); if (!ctx->iovecs) { io_uring_queue_exit(&ctx->ring); return false; } return true; } void queue_chunk_read(async_io_context* ctx, int fd, uint32_t chunk_index, void* buffer, size_t size, off_t offset) { if (ctx->pending_ops >= ctx->queue_depth) { // Wait for completion before queuing more wait_for_completion(ctx, 1); } struct io_uring_sqe* sqe = io_uring_get_sqe(&ctx->ring); ctx->iovecs[ctx->pending_ops].iov_base = buffer; ctx->iovecs[ctx->pending_ops].iov_len = size; io_uring_prep_readv(sqe, fd, &ctx->iovecs[ctx->pending_ops], 1, offset); sqe->user_data = chunk_index; ctx->pending_ops++; } void submit_and_wait_all(async_io_context* ctx) { // Submit all queued operations io_uring_submit(&ctx->ring); // Wait for all completions while (ctx->pending_ops > 0) { struct io_uring_cqe* cqe; int ret = io_uring_wait_cqe(&ctx->ring, &cqe); if (ret == 0) { uint32_t chunk_index = cqe->user_data; ssize_t bytes_read = cqe->res; if (bytes_read > 0) { process_loaded_chunk(chunk_index, bytes_read); } else { handle_io_error(chunk_index, bytes_read); } io_uring_cqe_seen(&ctx->ring, cqe); ctx->pending_ops--; } } } #endif ``` #### Windows Overlapped I/O Implementation ```c #ifdef _WIN32 typedef struct { HANDLE file_handle; // File handle HANDLE completion_port; // I/O completion port OVERLAPPED* overlappeds; // Overlapped structures void** buffers; // Read buffers uint32_t max_concurrent; // Maximum concurrent operations uint32_t pending_ops; // Currently pending operations } windows_async_io; bool setup_windows_async_io(windows_async_io* ctx, const char* filename, uint32_t max_concurrent) { ctx->max_concurrent = max_concurrent; ctx->pending_ops = 0; // Open file with overlapped flag ctx->file_handle = CreateFileA( filename, GENERIC_READ, FILE_SHARE_READ, NULL, OPEN_EXISTING, FILE_FLAG_OVERLAPPED | FILE_FLAG_NO_BUFFERING, NULL ); if (ctx->file_handle == INVALID_HANDLE_VALUE) { return false; } // Create I/O completion port ctx->completion_port = CreateIoCompletionPort( ctx->file_handle, NULL, 0, 0 ); if (!ctx->completion_port) { CloseHandle(ctx->file_handle); return false; } // Allocate overlapped structures and buffers ctx->overlappeds = malloc(max_concurrent * sizeof(OVERLAPPED)); ctx->buffers = malloc(max_concurrent * sizeof(void*)); return true; } void queue_windows_read(windows_async_io* ctx, uint32_t chunk_index, size_t size, uint64_t offset) { if (ctx->pending_ops >= ctx->max_concurrent) { wait_for_windows_completion(ctx, 1); } uint32_t op_index = ctx->pending_ops; // Allocate aligned buffer ctx->buffers[op_index] = _aligned_malloc(size, 4096); // Setup overlapped structure ZeroMemory(&ctx->overlappeds[op_index], sizeof(OVERLAPPED)); ctx->overlappeds[op_index].Offset = (DWORD)(offset & 0xFFFFFFFF); ctx->overlappeds[op_index].OffsetHigh = (DWORD)(offset >> 32); ctx->overlappeds[op_index].hEvent = (HANDLE)(uintptr_t)chunk_index; // Queue read operation BOOL result = ReadFile( ctx->file_handle, ctx->buffers[op_index], (DWORD)size, NULL, &ctx->overlappeds[op_index] ); if (!result && GetLastError() != ERROR_IO_PENDING) { handle_windows_io_error(chunk_index); _aligned_free(ctx->buffers[op_index]); } else { ctx->pending_ops++; } } #endif ``` ### SIMD Acceleration #### Hardware CRC32 Implementation ```c // Hardware-accelerated CRC32 for x86_64 #if defined(__x86_64__) && defined(__SSE4_2__) uint32_t crc32_hw_x86(const void* data, size_t length) { const uint8_t* ptr = (const uint8_t*)data; uint32_t crc = 0xFFFFFFFF; // Process 8 bytes at a time while (length >= 8) { uint64_t chunk = *(const uint64_t*)ptr; crc = _mm_crc32_u64(crc, chunk); ptr += 8; length -= 8; } // Process 4 bytes if (length >= 4) { uint32_t chunk = *(const uint32_t*)ptr; crc = _mm_crc32_u32(crc, chunk); ptr += 4; length -= 4; } // Process remaining bytes while (length > 0) { crc = _mm_crc32_u8(crc, *ptr); ptr++; length--; } return ~crc; } // Hardware-accelerated CRC32 for ARM64 #elif defined(__aarch64__) uint32_t crc32_hw_arm64(const void* data, size_t length) { const uint8_t* ptr = (const uint8_t*)data; uint32_t crc = 0xFFFFFFFF; // Process 8 bytes at a time while (length >= 8) { uint64_t chunk = *(const uint64_t*)ptr; crc = __crc32cd(crc, chunk); ptr += 8; length -= 8; } // Process 4 bytes if (length >= 4) { uint32_t chunk = *(const uint32_t*)ptr; crc = __crc32cw(crc, chunk); ptr += 4; length -= 4; } // Process remaining bytes while (length > 0) { crc = __crc32cb(crc, *ptr); ptr++; length--; } return ~crc; } #endif // Unified CRC32 function with hardware detection uint32_t graphite_crc32(const void* data, size_t length) { #if defined(__x86_64__) && defined(__SSE4_2__) static int hw_support = -1; if (hw_support == -1) { hw_support = __builtin_cpu_supports(\"sse4.2\"); } if (hw_support) { return crc32_hw_x86(data, length); } #elif defined(__aarch64__) return crc32_hw_arm64(data, length); #endif // Software fallback return crc32_software(data, length); } ``` #### Smart Prefetching ```c // Platform-specific prefetch optimization typedef struct { size_t l1_cache_size; // L1 data cache size size_t l2_cache_size; // L2 cache size size_t cache_line_size; // Cache line size int prefetch_distance; // Optimal prefetch distance } cache_info; cache_info get_cache_info(void) { cache_info info = {0}; #ifdef __linux__ // Linux: Read from /proc/cpuinfo or sysconf info.l1_cache_size = sysconf(_SC_LEVEL1_DCACHE_SIZE); info.l2_cache_size = sysconf(_SC_LEVEL2_CACHE_SIZE); info.cache_line_size = sysconf(_SC_LEVEL1_DCACHE_LINESIZE); #elif defined(_WIN32) // Windows: Use GetLogicalProcessorInformation SYSTEM_LOGICAL_PROCESSOR_INFORMATION* buffer = NULL; DWORD buffer_size = 0; GetLogicalProcessorInformation(NULL, &buffer_size); buffer = malloc(buffer_size); if (GetLogicalProcessorInformation(buffer, &buffer_size)) { for (DWORD i = 0; i < buffer_size / sizeof(*buffer); i++) { if (buffer[i].Relationship == RelationCache) { CACHE_DESCRIPTOR* cache = &buffer[i].Cache; if (cache->Level == 1 && cache->Type == CacheData) { info.l1_cache_size = cache->Size; info.cache_line_size = cache->LineSize; } else if (cache->Level == 2) { info.l2_cache_size = cache->Size; } } } } free(buffer); #elif defined(__APPLE__) // macOS: Use sysctlbyname size_t size = sizeof(info.l1_cache_size); sysctlbyname(\"hw.l1dcachesize\", &info.l1_cache_size, &size, NULL, 0); size = sizeof(info.l2_cache_size); sysctlbyname(\"hw.l2cachesize\", &info.l2_cache_size, &size, NULL, 0); size = sizeof(info.cache_line_size); sysctlbyname(\"hw.cachelinesize\", &info.cache_line_size, &size, NULL, 0); #endif // Set defaults if detection failed if (info.l1_cache_size == 0) info.l1_cache_size = 32 * 1024; if (info.l2_cache_size == 0) info.l2_cache_size = 256 * 1024; if (info.cache_line_size == 0) info.cache_line_size = 64; // Calculate optimal prefetch distance info.prefetch_distance = info.l2_cache_size / (64 * 1024); // Heuristic info.prefetch_distance = max(2, min(info.prefetch_distance, 8)); return info; } void prefetch_chunks_optimized(const graphite_bundle* bundle) { static cache_info cache = {0}; if (cache.l1_cache_size == 0) { cache = get_cache_info(); } // Calculate prefetch stride based on chunk sizes double avg_chunk_size = (double)bundle->total_file_size / bundle->header.chunk_count; size_t prefetch_stride = max(2, (size_t)(cache.l2_cache_size / avg_chunk_size)); prefetch_stride = min(prefetch_stride, 8); for (uint32_t i = 0; i < bundle->header.chunk_count; i++) { // Prefetch future chunks for (size_t j = 1; j <= prefetch_stride && i + j < bundle->header.chunk_count; j++) { const void* chunk_data = get_chunk_data(bundle, i + j); #if defined(__x86_64__) // x86_64: Use moderate temporal locality __builtin_prefetch(chunk_data, 0, 2); #elif defined(__aarch64__) // ARM64: Use temporal locality hint __builtin_prefetch(chunk_data, 0, 3); #else // Generic prefetch __builtin_prefetch(chunk_data, 0, 1); #endif } // Process current chunk process_chunk_data(bundle, i); } } ``` ### Multi-Threading Architecture #### Stage-Based Parallel Pipeline ```mermaid sequenceDiagram participant Main as Main Thread participant CRC as CRC Pool participant Decomp as Decompression Pool participant Hash as Hash Verification Pool participant Hydrate as Hydration Pool Main->>CRC: Dispatch CRC verification tasks par CRC Verification CRC->>CRC: Verify chunk 0 CRC32 CRC->>CRC: Verify chunk 1 CRC32 CRC->>CRC: Verify chunk N CRC32 end CRC-->>Main: Stage 1 complete Main->>Decomp: Dispatch decompression tasks par Decompression Decomp->>Decomp: Decompress chunk A Decomp->>Decomp: Decompress chunk B Decomp->>Decomp: Decompress chunk C end Decomp-->>Main: Stage 2 complete Main->>Hash: Dispatch hash verification par Hash Verification Hash->>Hash: Verify hash subtree 1 Hash->>Hash: Verify hash subtree 2 end Hash-->>Main: Stage 3 complete Main->>Hydrate: Dispatch pointer hydration par Hydration Hydrate->>Hydrate: Hydrate graph 1 Hydrate->>Hydrate: Hydrate graph 2 Hydrate->>Hydrate: Hydrate graph 3 end Hydrate-->>Main: Loading complete ``` ```c // Thread pool implementation typedef struct { pthread_t* threads; // Worker threads int thread_count; // Number of threads task_queue queue; // Work queue pthread_mutex_t queue_mutex; // Queue synchronization pthread_cond_t queue_cond; // Queue condition variable volatile bool shutdown; // Shutdown flag barrier_t stage_barrier; // Stage synchronization barrier } thread_pool; // Task types for different stages typedef enum { TASK_CRC_VERIFY, TASK_DECOMPRESS, TASK_HASH_VERIFY, TASK_HYDRATE_GRAPH } task_type; typedef struct { task_type type; uint32_t chunk_index; void* context; void (*callback)(struct task*, void* result); } task; // Stage-based parallel loading void load_bundle_parallel(graphite_bundle* bundle) { thread_pool* pool = create_thread_pool(get_cpu_count()); // Stage 1: CRC verification for (uint32_t i = 0; i < bundle->header.chunk_count; i++) { task* crc_task = create_task(TASK_CRC_VERIFY, i, bundle, NULL); queue_task(pool, crc_task); } wait_stage_completion(pool); // Stage 2: Decompression (only compressed chunks) for (uint32_t i = 0; i < bundle->header.chunk_count; i++) { if (is_compressed_chunk(bundle, i)) { task* decomp_task = create_task(TASK_DECOMPRESS, i, bundle, NULL); queue_task(pool, decomp_task); } } wait_stage_completion(pool); // Stage 3: Hash verification (parallel subtrees) if (bundle->header.integrity_root_index != 0) { hash_subtree* subtrees = find_hash_subtrees(bundle); for (int i = 0; i < subtrees->count; i++) { task* hash_task = create_task(TASK_HASH_VERIFY, subtrees->roots[i], bundle, NULL); queue_task(pool, hash_task); } wait_stage_completion(pool); } // Stage 4: Pointer hydration (parallel per top-level graph) graph_list* top_level = find_top_level_graphs(bundle); for (int i = 0; i < top_level->count; i++) { task* hydrate_task = create_task(TASK_HYDRATE_GRAPH, top_level->indices[i], bundle, NULL); queue_task(pool, hydrate_task); } wait_stage_completion(pool); destroy_thread_pool(pool); } ``` --- ## Core API Specification ### Primary Interface (graphite_core.h) The core API provides the essential functionality for loading and accessing GRAPHITE bundles: ```c #ifndef GRAPHITE_CORE_H #define GRAPHITE_CORE_H #include <stdint.h> #include <stdbool.h> #include <stddef.h> #ifdef __cplusplus extern \"C\" { #endif // Version information #define GRAPHITE_VERSION_MAJOR 3 #define GRAPHITE_VERSION_MINOR 0 #define GRAPHITE_VERSION_PATCH 0 #define GRAPHITE_VERSION_STRING \"3.0.0\" // Forward declarations - opaque handles typedef struct graphite_bundle graphite_bundle; typedef struct graphite_graph graphite_graph; typedef struct graphite_node_iterator graphite_node_iterator; typedef struct graphite_edge_iterator graphite_edge_iterator; // Load flags for bundle opening typedef enum { GRAPHITE_LOAD_DEFAULT = 0, GRAPHITE_VERIFY_HASHES = 1 << 0, // Enable cryptographic verification GRAPHITE_DECOMPRESS = 1 << 1, // Enable zstd decompression GRAPHITE_PREFETCH = 1 << 2, // Enable smart memory prefetching GRAPHITE_NUMA_AWARE = 1 << 3, // Enable NUMA optimizations GRAPHITE_PARALLEL_CRC = 1 << 4, // Parallel CRC verification GRAPHITE_HW_ACCELERATION = 1 << 5, // Use hardware acceleration GRAPHITE_VALIDATE_FORMAT = 1 << 6, // Extra format validation GRAPHITE_MLOCK_ARENA = 1 << 7, // Lock arena pages in memory } graphite_load_flags; // Error codes typedef enum { GRAPHITE_OK = 0, // File I/O errors (1-99) GRAPHITE_ERROR_FILE_NOT_FOUND = 1, GRAPHITE_ERROR_ACCESS_DENIED = 2, GRAPHITE_ERROR_DISK_FULL = 3, GRAPHITE_ERROR_IO_ERROR = 4, GRAPHITE_ERROR_FILE_LOCKED = 5, // Format errors (100-199) GRAPHITE_ERROR_INVALID_MAGIC = 100, GRAPHITE_ERROR_UNSUPPORTED_VERSION = 101, GRAPHITE_ERROR_CORRUPTED_HEADER = 102, GRAPHITE_ERROR_INVALID_CHUNK_TABLE = 103, GRAPHITE_ERROR_MALFORMED_GRAPH = 104, GRAPHITE_ERROR_INVALID_OFFSET = 105, GRAPHITE_ERROR_INVALID_SIZE = 106, // Integrity errors (200-299) GRAPHITE_ERROR_CRC_MISMATCH = 200, GRAPHITE_ERROR_HASH_VERIFICATION_FAILED = 201, GRAPHITE_ERROR_SIGNATURE_INVALID = 202, GRAPHITE_ERROR_TAMPER_DETECTED = 203, GRAPHITE_ERROR_MISSING_HASH_TREE = 204, // Resource errors (300-399) GRAPHITE_ERROR_OUT_OF_MEMORY = 300, GRAPHITE_ERROR_ARENA_EXHAUSTED = 301, GRAPHITE_ERROR_TOO_MANY_CHUNKS = 302, GRAPHITE_ERROR_FILE_TOO_LARGE = 303, GRAPHITE_ERROR_THREAD_CREATION_FAILED = 304, // Compression errors (400-499) GRAPHITE_ERROR_DECOMPRESSION_FAILED = 400, GRAPHITE_ERROR_DICTIONARY_MISSING = 401, GRAPHITE_ERROR_COMPRESSION_CORRUPTED = 402, GRAPHITE_ERROR_UNSUPPORTED_COMPRESSION = 403, // Platform errors (500-599) GRAPHITE_ERROR_NUMA_UNAVAILABLE = 500, GRAPHITE_ERROR_HUGE_PAGES_UNAVAILABLE = 501, GRAPHITE_ERROR_HARDWARE_ACCELERATION_UNAVAILABLE = 502, GRAPHITE_ERROR_MMAP_FAILED = 503 } graphite_error; // Performance statistics typedef struct { uint64_t total_load_time_ns; // Total loading time uint64_t crc_verification_time_ns; // CRC verification time uint64_t decompression_time_ns; // Decompression time uint64_t hash_verification_time_ns; // Hash verification time uint64_t hydration_time_ns; // Pointer hydration time uint64_t total_bytes_processed; // Total bytes processed uint32_t chunks_processed; // Number of chunks processed uint32_t chunks_compressed; // Number of compressed chunks uint32_t chunks_verified; // Number of hash-verified chunks size_t peak_memory_usage; // Peak memory usage during load size_t arena_size; // Arena allocation size double compression_ratio; // Overall compression ratio } graphite_performance_stats; // Bundle information typedef struct { uint32_t version; // Bundle format version uint64_t file_size; // Total file size uint32_t chunk_count; // Number of chunks uint32_t graph_count; // Number of graph chunks uint32_t blob_count; // Number of blob chunks uint64_t creation_timestamp; // Bundle creation time bool has_integrity_tree; // Has cryptographic verification bool has_compression; // Has compressed chunks bool has_encryption; // Has encrypted chunks size_t total_uncompressed_size; // Size before compression double overall_compression_ratio; // Compression effectiveness } graphite_bundle_info; // Property types typedef enum { GRAPHITE_PROPERTY_STRING, // String value (string pool reference) GRAPHITE_PROPERTY_INTEGER, // 64-bit signed integer GRAPHITE_PROPERTY_FLOAT, // 64-bit IEEE 754 float GRAPHITE_PROPERTY_BOOLEAN, // Boolean value GRAPHITE_PROPERTY_TIMESTAMP, // Unix timestamp (uint64_t) GRAPHITE_PROPERTY_BLOB_REF, // Reference to blob chunk GRAPHITE_PROPERTY_GRAPH_REF, // Reference to graph chunk GRAPHITE_PROPERTY_ARRAY, // Array of properties GRAPHITE_PROPERTY_OBJECT // Nested property object } graphite_property_type; // Property value (variant type) typedef struct { graphite_property_type type; union { const char* string_value; // Null-terminated string int64_t integer_value; // Integer value double float_value; // Floating point value bool boolean_value; // Boolean value uint64_t timestamp_value; // Unix timestamp uint32_t reference_value; // Chunk reference struct { const struct graphite_property* elements; uint32_t count; } array_value; // Array elements struct { const struct graphite_property* fields; uint32_t count; } object_value; // Object fields }; } graphite_property_value; // Property key-value pair typedef struct graphite_property { const char* key; // Property key (interned string) graphite_property_value value; // Property value } graphite_property; // // Bundle Management Functions // // Open a GRAPHITE bundle from file graphite_bundle* graphite_open(const char* file_path); // Open with specific load flags and performance monitoring graphite_bundle* graphite_open_ex(const char* file_path, uint32_t load_flags, graphite_performance_stats* stats); // Open from memory buffer (useful for embedded bundles) graphite_bundle* graphite_open_memory(const void* data, size_t size, uint32_t load_flags, graphite_performance_stats* stats); // Close bundle and free all resources void graphite_close(graphite_bundle* bundle); // Get bundle information graphite_bundle_info graphite_get_bundle_info(const graphite_bundle* bundle); // Check if bundle is valid and loaded correctly bool graphite_is_valid(const graphite_bundle* bundle); // // Graph Access Functions // // Get the root graph of the bundle const graphite_graph* graphite_get_root_graph(const graphite_bundle* bundle); // Get number of child nodes in a graph uint32_t graphite_get_node_count(const graphite_graph* graph); // Get number of edges in a graph uint32_t graphite_get_edge_count(const graphite_graph* graph); // Get child node by index const graphite_graph* graphite_get_node(const graphite_graph* graph, uint32_t index); // Get child node by property value (if property exists and matches) const graphite_graph* graphite_find_node_by_property(const graphite_graph* graph, const char* property_key, const char* property_value); // Check if graph has cycles bool graphite_has_cycles(const graphite_graph* graph); // Check if graph is marked as parallel group bool graphite_is_parallel_group(const graphite_graph* graph); // Check if graph is a string pool bool graphite_is_string_pool(const graphite_graph* graph); // // Edge Access Functions // // Get edge by index typedef struct { uint32_t from_node_index; // Source node index uint32_t to_node_index; // Target node index const graphite_graph* edge_data; // Edge semantics graph } graphite_edge; graphite_edge graphite_get_edge(const graphite_graph* graph, uint32_t index); // Find edges connecting specific nodes uint32_t graphite_find_edges(const graphite_graph* graph, uint32_t from_node, uint32_t to_node, graphite_edge* edges, uint32_t max_edges); // // Property Access Functions // // Get number of properties in a graph uint32_t graphite_get_property_count(const graphite_graph* graph); // Get property by key bool graphite_get_property(const graphite_graph* graph, const char* key, graphite_property_value* value); // Get property by index graphite_property graphite_get_property_by_index(const graphite_graph* graph, uint32_t index); // Get typed property values (convenience functions) bool graphite_get_string_property(const graphite_graph* graph, const char* key, const char** value); bool graphite_get_integer_property(const graphite_graph* graph, const char* key, int64_t* value); bool graphite_get_float_property(const graphite_graph* graph, const char* key, double* value); bool graphite_get_boolean_property(const graphite_graph* graph, const char* key, bool* value); bool graphite_get_timestamp_property(const graphite_graph* graph, const char* key, uint64_t* value); // Check if property exists bool graphite_has_property(const graphite_graph* graph, const char* key); // // String Pool Functions // // Get string by ID from bundle's string pool const char* graphite_get_string(const graphite_bundle* bundle, uint32_t string_id); // Find string ID by value (reverse lookup) uint32_t graphite_find_string_id(const graphite_bundle* bundle, const char* string); // Get string pool statistics typedef struct { uint32_t string_count; // Number of unique strings size_t total_bytes; // Total bytes of string data uint32_t average_length; // Average string length double deduplication_ratio; // Space saved by deduplication } graphite_string_pool_stats; graphite_string_pool_stats graphite_get_string_pool_stats(const graphite_bundle* bundle); // // Asset Data Access Functions // // Get raw asset data from a leaf graph const void* graphite_get_asset_data(const graphite_graph* asset_graph, size_t* size); // Get asset MIME type const char* graphite_get_asset_mime_type(const graphite_graph* asset_graph); // Get asset original size (before compression) uint64_t graphite_get_asset_original_size(const graphite_graph* asset_graph); // Get asset checksum const char* graphite_get_asset_checksum(const graphite_graph* asset_graph); // // Iterator Functions // // Create node iterator graphite_node_iterator* graphite_create_node_iterator(const graphite_graph* graph); void graphite_destroy_node_iterator(graphite_node_iterator* iterator); // Iterator operations bool graphite_node_iterator_has_next(graphite_node_iterator* iterator); const graphite_graph* graphite_node_iterator_next(graphite_node_iterator* iterator); void graphite_node_iterator_reset(graphite_node_iterator* iterator); // Create edge iterator graphite_edge_iterator* graphite_create_edge_iterator(const graphite_graph* graph); void graphite_destroy_edge_iterator(graphite_edge_iterator* iterator); // Edge iterator operations bool graphite_edge_iterator_has_next(graphite_edge_iterator* iterator); graphite_edge graphite_edge_iterator_next(graphite_edge_iterator* iterator); void graphite_edge_iterator_reset(graphite_edge_iterator* iterator); // // Utility Functions // // Get last error that occurred graphite_error graphite_get_last_error(void); // Get human-readable error message const char* graphite_error_string(graphite_error error); // Get library version information typedef struct { uint32_t major; uint32_t minor; uint32_t patch; const char* string; const char* build_date; const char* build_config; } graphite_version_info; graphite_version_info graphite_get_version_info(void); // Performance profiling void graphite_enable_profiling(bool enable); bool graphite_is_profiling_enabled(void); // Memory usage information typedef struct { size_t arena_size; // Arena allocation size size_t arena_used; // Arena bytes used size_t peak_memory; // Peak memory usage size_t current_memory; // Current memory usage uint32_t allocation_count; // Number of allocations } graphite_memory_stats; graphite_memory_stats graphite_get_memory_stats(const graphite_bundle* bundle); #ifdef __cplusplus } #endif #endif // GRAPHITE_CORE_H ``` ### Usage Examples #### Basic Bundle Loading ```c #include \"graphite_core.h\" #include <stdio.h> int main() { // Open bundle with default settings graphite_bundle* bundle = graphite_open(\"assets.graphite\"); if (!bundle) { fprintf(stderr, \"Failed to open bundle: %s\ \", graphite_error_string(graphite_get_last_error())); return 1; } // Get bundle information graphite_bundle_info info = graphite_get_bundle_info(bundle); printf(\"Bundle version: %u\ \", info.version); printf(\"File size: %llu bytes\ \", info.file_size); printf(\"Chunks: %u\ \", info.chunk_count); // Access root graph const graphite_graph* root = graphite_get_root_graph(bundle); printf(\"Root graph has %u nodes\ \", graphite_get_node_count(root)); // Iterate through child nodes for (uint32_t i = 0; i < graphite_get_node_count(root); i++) { const graphite_graph* child = graphite_get_node(root, i); // Check if this is an asset node const char* mime_type = graphite_get_asset_mime_type(child); if (mime_type) { printf(\"Asset %u: %s\ \", i, mime_type); size_t data_size; const void* data = graphite_get_asset_data(child, &data_size); printf(\" Size: %zu bytes\ \", data_size); } } graphite_close(bundle); return 0; } ``` #### Advanced Loading with Performance Monitoring ```c #include \"graphite_core.h\" #include <stdio.h> int main() { // Enable performance monitoring graphite_performance_stats stats = {0}; uint32_t flags = GRAPHITE_VERIFY_HASHES | GRAPHITE_DECOMPRESS | GRAPHITE_HW_ACCELERATION; graphite_bundle* bundle = graphite_open_ex(\"assets.graphite\", flags, &stats); if (!bundle) { fprintf(stderr, \"Failed to open bundle\ \"); return 1; } // Print performance statistics printf(\"Loading Performance:\ \"); printf(\" Total time: %.2f ms\ \", stats.total_load_time_ns / 1e6); printf(\" CRC verification: %.2f ms\ \", stats.crc_verification_time_ns / 1e6); printf(\" Decompression: %.2f ms\ \", stats.decompression_time_ns / 1e6); printf(\" Hash verification: %.2f ms\ \", stats.hash_verification_time_ns / 1e6); printf(\" Hydration: %.2f ms\ \", stats.hydration_time_ns / 1e6); printf(\" Bytes processed: %llu\ \", stats.total_bytes_processed); printf(\" Peak memory: %.2f MB\ \", stats.peak_memory_usage / (1024.0 * 1024.0)); printf(\" Compression ratio: %.2f%%\ \", stats.compression_ratio * 100.0); // Use bundle... graphite_close(bundle); return 0; } ``` #### Property Access and Filtering ```c #include \"graphite_core.h\" #include <stdio.h> #include <string.h> void print_graph_properties(const graphite_graph* graph, const char* indent) { uint32_t prop_count = graphite_get_property_count(graph); for (uint32_t i = 0; i < prop_count; i++) { graphite_property prop = graphite_get_property_by_index(graph, i); printf(\"%s%s: \", indent, prop.key); switch (prop.value.type) { case GRAPHITE_PROPERTY_STRING: printf(\"\\\"%s\\\"\", prop.value.string_value); break; case GRAPHITE_PROPERTY_INTEGER: printf(\"%lld\", prop.value.integer_value); break; case GRAPHITE_PROPERTY_FLOAT: printf(\"%.6f\", prop.value.float_value); break; case GRAPHITE_PROPERTY_BOOLEAN: printf(\"%s\", prop.value.boolean_value ? \"true\" : \"false\"); break; case GRAPHITE_PROPERTY_TIMESTAMP: printf(\"timestamp(%llu)\", prop.value.timestamp_value); break; default: printf(\"(complex type)\"); break; } printf(\"\ \"); } } int main() { graphite_bundle* bundle = graphite_open(\"assets.graphite\"); if (!bundle) return 1; const graphite_graph* root = graphite_get_root_graph(bundle); // Find all image assets for (uint32_t i = 0; i < graphite_get_node_count(root); i++) { const graphite_graph* node = graphite_get_node(root, i); const char* mime_type; if (graphite_get_string_property(node, \"mime_type\", &mime_type)) { if (strncmp(mime_type, \"image/\", 6) == 0) { printf(\"Image Asset %u (%s):\ \", i, mime_type); print_graph_properties(node, \" \"); printf(\"\ \"); } } } graphite_close(bundle); return 0; } ``` --- ## Tooling API Specification ### Bundle Creation API (graphite_tooling.h) The tooling API provides comprehensive functionality for creating, analyzing, and manipulating GRAPHITE bundles: ```c #ifndef GRAPHITE_TOOLING_H #define GRAPHITE_TOOLING_H #include \"graphite_core.h\" #include <stdint.h> #include <stdbool.h> #ifdef __cplusplus extern \"C\" { #endif // Forward declarations for tooling types typedef struct graphite_writer graphite_writer; typedef struct graphite_graph_builder graphite_graph_builder; typedef struct graphite_string_pool_builder graphite_string_pool_builder; typedef struct graphite_integrity_builder graphite_integrity_builder; typedef struct graphite_analyzer graphite_analyzer; // // Bundle Writer Configuration // // Compression configuration typedef struct { int level; // zstd compression level (0-22) bool enable_dictionary; // Use dictionary compression size_t dictionary_size; // Maximum dictionary size size_t min_chunk_size; // Minimum size to attempt compression double min_compression_ratio; // Minimum compression ratio to keep const char** file_patterns; // File patterns for dictionary training uint32_t pattern_count; // Number of patterns } graphite_compression_config; // Integrity configuration typedef struct { bool enable_hashing; // Enable BLAKE3 hash tree bool mandatory_verification; // Set mandatory verification flag int tree_fanout; // Hash tree branching factor (2-32) bool include_chunk_hashes; // Include individual chunk hashes } graphite_integrity_config; // Output configuration typedef struct { const char* output_path; // Output file path bool overwrite_existing; // Overwrite if file exists uint32_t file_permissions; // File permissions (Unix style) bool create_backup; // Create .bak file if overwriting } graphite_output_config; // Writer statistics typedef struct { uint64_t total_input_size; // Total input data size uint64_t total_output_size; // Total output file size uint32_t chunks_written; // Number of chunks written uint32_t chunks_compressed; // Number of compressed chunks uint32_t graphs_created; // Number of graph chunks created uint32_t blobs_created; // Number of blob chunks created double overall_compression_ratio; // Overall compression effectiveness uint64_t write_time_ns; // Total write time uint64_t compression_time_ns; // Time spent compressing uint64_t hashing_time_ns; // Time spent computing hashes } graphite_writer_stats; // // Bundle Writer Functions // // Create bundle writer with configuration graphite_writer* graphite_writer_create(const graphite_output_config* output_config); // Configure compression settings void graphite_writer_set_compression(graphite_writer* writer, const graphite_compression_config* config); // Configure integrity settings void graphite_writer_set_integrity(graphite_writer* writer, const graphite_integrity_config* config); // Set metadata for the bundle void graphite_writer_set_metadata(graphite_writer* writer, const char* key, const char* value); // Finalize and write bundle to disk bool graphite_writer_finalize(graphite_writer* writer, graphite_writer_stats* stats); // Destroy writer and free resources void graphite_writer_destroy(graphite_writer* writer); // // Graph Builder Functions // // Create new graph builder graphite_graph_builder* graphite_graph_builder_create(void); // Set graph flags void graphite_graph_builder_set_flags(graphite_graph_builder* builder, uint32_t flags); // Add asset node (leaf graph with data) uint32_t graphite_graph_builder_add_asset_node(graphite_graph_builder* builder, const void* data, size_t size, const char* mime_type); // Add asset node from file uint32_t graphite_graph_builder_add_asset_file(graphite_graph_builder* builder, const char* file_path, const char* mime_type); // Add child graph node uint32_t graphite_graph_builder_add_graph_node(graphite_graph_builder* builder, const graphite_graph* subgraph); // Add edge between nodes void graphite_graph_builder_add_edge(graphite_graph_builder* builder, uint32_t from_node, uint32_t to_node, const graphite_graph* edge_semantics); // Add simple edge with metadata void graphite_graph_builder_add_simple_edge(graphite_graph_builder* builder, uint32_t from_node, uint32_t to_node, const char* edge_type, const char* metadata); // Set property on graph void graphite_graph_builder_set_property_string(graphite_graph_builder* builder, const char* key, const char* value); void graphite_graph_builder_set_property_integer(graphite_graph_builder* builder, const char* key, int64_t value); void graphite_graph_builder_set_property_float(graphite_graph_builder* builder, const char* key, double value); void graphite_graph_builder_set_property_boolean(graphite_graph_builder* builder, const char* key, bool value); void graphite_graph_builder_set_property_timestamp(graphite_graph_builder* builder, const char* key, uint64_t value); // Finalize graph and add to writer uint32_t graphite_writer_add_graph(graphite_writer* writer, graphite_graph_builder* builder); // Destroy graph builder void graphite_graph_builder_destroy(graphite_graph_builder* builder); // // String Pool Builder Functions // // Create string pool builder graphite_string_pool_builder* graphite_string_pool_builder_create(void); // Add string to pool (returns string ID) uint32_t graphite_string_pool_add_string(graphite_string_pool_builder* builder, const char* string); // Add strings from array void graphite_string_pool_add_strings(graphite_string_pool_builder* builder, const char** strings, uint32_t count); // Load strings from file (one per line) bool graphite_string_pool_load_from_file(graphite_string_pool_builder* builder, const char* file_path); // Get string pool statistics typedef struct { uint32_t unique_strings; // Number of unique strings uint32_t total_references; // Total string references size_t total_bytes; // Total string data bytes double deduplication_ratio; // Space saved by deduplication } graphite_string_pool_builder_stats; graphite_string_pool_builder_stats graphite_string_pool_get_stats(graphite_string_pool_builder* builder); // Finalize string pool and add to writer uint32_t graphite_writer_set_string_pool(graphite_writer* writer, graphite_string_pool_builder* builder); // Destroy string pool builder void graphite_string_pool_builder_destroy(graphite_string_pool_builder* builder); // // Compression Dictionary Training // // Dictionary training configuration typedef struct { size_t max_dictionary_size; // Maximum dictionary size uint32_t sample_count; // Number of training samples size_t max_sample_size; // Maximum size per sample double min_compression_gain; // Minimum compression improvement } graphite_dictionary_config; // Train compression dictionary from files bool graphite_train_dictionary(const char** file_paths, uint32_t file_count, const graphite_dictionary_config* config, void** dictionary_data, size_t* dictionary_size); // Train dictionary from memory samples bool graphite_train_dictionary_memory(const void** samples, const size_t* sample_sizes, uint32_t sample_count, const graphite_dictionary_config* config, void** dictionary_data, size_t* dictionary_size); // Add trained dictionary to writer void graphite_writer_set_dictionary(graphite_writer* writer, const void* dictionary_data, size_t dictionary_size); // // Bundle Analysis Functions // // Create bundle analyzer graphite_analyzer* graphite_analyzer_create(const graphite_bundle* bundle); // Analysis result types typedef struct { uint32_t total_graphs; // Total number of graphs uint32_t leaf_graphs; // Number of leaf (asset) graphs uint32_t string_pools; // Number of string pool graphs uint32_t parallel_groups; // Number of parallel group graphs uint32_t max_depth; // Maximum graph nesting depth uint32_t total_nodes; // Total nodes across all graphs uint32_t total_edges; // Total edges across all graphs double avg_branching_factor; // Average branching factor bool has_cycles; // Whether any graph has cycles } graphite_graph_analysis; typedef struct { uint64_t total_size; // Total bundle size uint64_t header_size; // Header and chunk table size uint64_t chunk_data_size; // Total chunk data size uint64_t compressed_size; // Size of compressed chunks uint64_t uncompressed_size; // Size before compression double compression_ratio; // Overall compression ratio uint32_t compression_chunks; // Number of compressed chunks uint32_t compression_failures; // Chunks that didn't compress well } graphite_compression_analysis; typedef struct { bool has_integrity_tree; // Has hash tree uint32_t hash_nodes; // Number of hash nodes uint32_t hash_leaves; // Number of hash leaves uint32_t protected_chunks; // Number of protected chunks double verification_coverage; // Percentage of data protected bool mandatory_verification; // Verification is mandatory } graphite_integrity_analysis; typedef struct { uint32_t unique_strings; // Number of unique strings uint32_t total_references; // Total string references size_t string_data_size; // Total string data size double deduplication_ratio; // Space saved by deduplication uint32_t unused_strings; // Strings with no references double fragmentation_ratio; // String pool fragmentation } graphite_string_analysis; // Perform various analyses graphite_graph_analysis graphite_analyzer_analyze_graphs(graphite_analyzer* analyzer); graphite_compression_analysis graphite_analyzer_analyze_compression(graphite_analyzer* analyzer); graphite_integrity_analysis graphite_analyzer_analyze_integrity(graphite_analyzer* analyzer); graphite_string_analysis graphite_analyzer_analyze_strings(graphite_analyzer* analyzer); // Generate optimization recommendations typedef struct { bool enable_compression; // Recommendation to enable compression int suggested_compression_level; // Suggested compression level bool enable_dictionary; // Recommendation for dictionary training bool improve_string_dedup; // String deduplication improvements bool add_integrity_tree; // Add hash tree recommendation double potential_size_reduction; // Estimated size reduction percentage const char* primary_recommendation; // Primary optimization suggestion const char** detailed_recommendations; // Detailed suggestion list uint32_t recommendation_count; // Number of detailed recommendations } graphite_optimization_recommendations; graphite_optimization_recommendations graphite_analyzer_get_recommendations(graphite_analyzer* analyzer); // Destroy analyzer void graphite_analyzer_destroy(graphite_analyzer* analyzer); // // Bundle Comparison and Diffing // // Bundle comparison result typedef struct { bool structure_identical; // Same graph structure bool content_identical; // Same content hashes uint32_t added_graphs; // Number of added graphs uint32_t removed_graphs; // Number of removed graphs uint32_t modified_graphs; // Number of modified graphs uint32_t added_chunks; // Number of added chunks uint32_t removed_chunks; // Number of removed chunks uint32_t modified_chunks; // Number of modified chunks uint64_t size_difference; // Size difference in bytes } graphite_comparison_result; // Compare two bundles graphite_comparison_result graphite_compare_bundles(const graphite_bundle* bundle1, const graphite_bundle* bundle2); // Generate binary diff between bundles typedef struct { const void* diff_data; // Binary diff data size_t diff_size; // Size of diff data double compression_ratio; // Diff compression ratio bool applicable; // Whether diff can be applied } graphite_binary_diff; graphite_binary_diff graphite_create_binary_diff(const graphite_bundle* old_bundle, const graphite_bundle* new_bundle); // Apply binary diff to create new bundle bool graphite_apply_binary_diff(const graphite_bundle* base_bundle, const graphite_binary_diff* diff, const char* output_path); // Free binary diff resources void graphite_free_binary_diff(graphite_binary_diff* diff); // // Validation and Repair Functions // // Validation levels typedef enum { GRAPHITE_VALIDATE_BASIC, // Basic format validation GRAPHITE_VALIDATE_STRUCTURE, // Graph structure validation GRAPHITE_VALIDATE_INTEGRITY, // Hash verification GRAPHITE_VALIDATE_COMPREHENSIVE // All validation checks } graphite_validation_level; // Validation result typedef struct { bool is_valid; // Overall validation result uint32_t error_count; // Number of errors found uint32_t warning_count; // Number of warnings const char** errors; // Array of error messages const char** warnings; // Array of warning messages bool can_be_repaired; // Whether bundle can be repaired } graphite_validation_result; // Validate bundle graphite_validation_result graphite_validate_bundle(const char* bundle_path, graphite_validation_level level); // Attempt to repair bundle bool graphite_repair_bundle(const char* input_path, const char* output_path, const graphite_validation_result* validation); // Free validation result void graphite_free_validation_result(graphite_validation_result* result); // // Format Conversion Functions // // Supported export formats typedef enum { GRAPHITE_EXPORT_JSON, // JSON representation GRAPHITE_EXPORT_XML, // XML representation GRAPHITE_EXPORT_YAML, // YAML representation GRAPHITE_EXPORT_DOT, // Graphviz DOT format GRAPHITE_EXPORT_MERMAID, // Mermaid diagram format GRAPHITE_EXPORT_CSV // CSV for tabular data } graphite_export_format; // Export configuration typedef struct { graphite_export_format format; // Target format bool include_binary_data; // Include base64-encoded binary data bool pretty_print; // Format for human readability uint32_t max_depth; // Maximum nesting depth const char* filter_expression; // Filter expression for selective export } graphite_export_config; // Export bundle to different format bool graphite_export_bundle(const graphite_bundle* bundle, const char* output_path, const graphite_export_config* config); // Import from supported formats graphite_graph_builder* graphite_import_from_json(const char* json_path); graphite_graph_builder* graphite_import_from_xml(const char* xml_path); graphite_graph_builder* graphite_import_from_yaml(const char* yaml_path); #ifdef __cplusplus } #endif #endif // GRAPHITE_TOOLING_H ``` ### High-Level Builder Interface #### Bundle Creation Example ```c #include \"graphite_tooling.h\" #include <stdio.h> int create_game_assets_bundle() { // Configure output graphite_output_config output = { .output_path = \"game_assets.graphite\", .overwrite_existing = true, .create_backup = true }; // Create writer graphite_writer* writer = graphite_writer_create(&output); if (!writer) { fprintf(stderr, \"Failed to create writer\ \"); return 1; } // Configure compression graphite_compression_config compression = { .level = 5, .enable_dictionary = true, .min_chunk_size = 64 * 1024, .min_compression_ratio = 0.9 }; graphite_writer_set_compression(writer, &compression); // Configure integrity graphite_integrity_config integrity = { .enable_hashing = true, .mandatory_verification = true, .tree_fanout = 8 }; graphite_writer_set_integrity(writer, &integrity); // Create string pool graphite_string_pool_builder* strings = graphite_string_pool_builder_create(); // Create root graph graphite_graph_builder* root = graphite_graph_builder_create(); graphite_graph_builder_set_property_string(root, \"bundle_type\", \"game_assets\"); graphite_graph_builder_set_property_string(root, \"version\", \"1.0.0\"); // Create textures subgraph graphite_graph_builder* textures = graphite_graph_builder_create(); graphite_graph_builder_set_property_string(textures, \"category\", \"textures\"); // Add texture assets uint32_t player_texture = graphite_graph_builder_add_asset_file( textures, \"assets/player.png\", \"image/png\"); uint32_t ui_atlas = graphite_graph_builder_add_asset_file( textures, \"assets/ui_atlas.png\", \"image/png\"); // Create audio subgraph graphite_graph_builder* audio = graphite_graph_builder_create(); graphite_graph_builder_set_property_string(audio, \"category\", \"audio\"); uint32_t music = graphite_graph_builder_add_asset_file( audio, \"assets/background_music.ogg\", \"audio/ogg\"); uint32_t sfx = graphite_graph_builder_add_asset_file( audio, \"assets/jump_sound.wav\", \"audio/wav\"); // Add dependency edges graphite_graph_builder_add_simple_edge(textures, player_texture, ui_atlas, \"spatial_relationship\", \"ui_atlas_contains_player_ui\"); // Add subgraphs to root uint32_t textures_node = graphite_writer_add_graph(writer, textures); uint32_t audio_node = graphite_writer_add_graph(writer, audio); graphite_graph_builder_add_graph_node(root, graphite_get_node(graphite_get_root_graph(bundle), textures_node)); graphite_graph_builder_add_graph_node(root, graphite_get_node(graphite_get_root_graph(bundle), audio_node)); // Set root graph uint32_t root_index = graphite_writer_add_graph(writer, root); // Set string pool graphite_writer_set_string_pool(writer, strings); // Finalize bundle graphite_writer_stats stats; if (graphite_writer_finalize(writer, &stats)) { printf(\"Bundle created successfully!\ \"); printf(\" Input size: %.2f MB\ \", stats.total_input_size / (1024.0 * 1024.0)); printf(\" Output size: %.2f MB\ \", stats.total_output_size / (1024.0 * 1024.0)); printf(\" Compression ratio: %.2f%%\ \", stats.overall_compression_ratio * 100.0); printf(\" Chunks written: %u\ \", stats.chunks_written); } else { fprintf(stderr, \"Failed to finalize bundle\ \"); graphite_writer_destroy(writer); return 1; } // Cleanup graphite_graph_builder_destroy(root); graphite_graph_builder_destroy(textures); graphite_graph_builder_destroy(audio); graphite_string_pool_builder_destroy(strings); graphite_writer_destroy(writer); return 0; } ``` #### Bundle Analysis Example ```c #include \"graphite_tooling.h\" #include <stdio.h> void analyze_bundle(const char* bundle_path) { // Open bundle graphite_bundle* bundle = graphite_open(bundle_path); if (!bundle) { fprintf(stderr, \"Failed to open bundle: %s\ \", bundle_path); return; } // Create analyzer graphite_analyzer* analyzer = graphite_analyzer_create(bundle); // Perform graph analysis graphite_graph_analysis graph_stats = graphite_analyzer_analyze_graphs(analyzer); printf(\"Graph Analysis:\ \"); printf(\" Total graphs: %u\ \", graph_stats.total_graphs); printf(\" Leaf graphs: %u\ \", graph_stats.leaf_graphs); printf(\" String pools: %u\ \", graph_stats.string_pools); printf(\" Parallel groups: %u\ \", graph_stats.parallel_groups); printf(\" Maximum depth: %u\ \", graph_stats.max_depth); printf(\" Total nodes: %u\ \", graph_stats.total_nodes); printf(\" Total edges: %u\ \", graph_stats.total_edges); printf(\" Avg branching factor: %.2f\ \", graph_stats.avg_branching_factor); printf(\" Has cycles: %s\ \", graph_stats.has_cycles ? \"yes\" : \"no\"); // Perform compression analysis graphite_compression_analysis comp_stats = graphite_analyzer_analyze_compression(analyzer); printf(\"\ Compression Analysis:\ \"); printf(\" Total size: %.2f MB\ \", comp_stats.total_size / (1024.0 * 1024.0)); printf(\" Compressed size: %.2f MB\ \", comp_stats.compressed_size / (1024.0 * 1024.0)); printf(\" Compression ratio: %.2f%%\ \", comp_stats.compression_ratio * 100.0); printf(\" Compressed chunks: %u\ \", comp_stats.compression_chunks); printf(\" Compression failures: %u\ \", comp_stats.compression_failures); // Perform integrity analysis graphite_integrity_analysis int_stats = graphite_analyzer_analyze_integrity(analyzer); printf(\"\ Integrity Analysis:\ \"); printf(\" Has integrity tree: %s\ \", int_stats.has_integrity_tree ? \"yes\" : \"no\"); printf(\" Hash nodes: %u\ \", int_stats.hash_nodes); printf(\" Hash leaves: %u\ \", int_stats.hash_leaves); printf(\" Protected chunks: %u\ \", int_stats.protected_chunks); printf(\" Verification coverage: %.2f%%\ \", int_stats.verification_coverage * 100.0); printf(\" Mandatory verification: %s\ \", int_stats.mandatory_verification ? \"yes\" : \"no\"); // Get optimization recommendations graphite_optimization_recommendations recommendations = graphite_analyzer_get_recommendations(analyzer); printf(\"\ Optimization Recommendations:\ \"); printf(\" Primary: %s\ \", recommendations.primary_recommendation); printf(\" Potential size reduction: %.2f%%\ \", recommendations.potential_size_reduction * 100.0); for (uint32_t i = 0; i < recommendations.recommendation_count; i++) { printf(\" - %s\ \", recommendations.detailed_recommendations[i]); } // Cleanup graphite_analyzer_destroy(analyzer); graphite_close(bundle); } ``` --- ## Wrapper APIs ### Unity Integration API ```c #ifndef GRAPHITE_UNITY_H #define GRAPHITE_UNITY_H #include \"graphite_core.h\" #ifdef __cplusplus extern \"C\" { #endif // Unity-specific asset types typedef enum { UNITY_ASSET_TEXTURE2D, UNITY_ASSET_SPRITE, UNITY_ASSET_MESH, UNITY_ASSET_MATERIAL, UNITY_ASSET_SHADER, UNITY_ASSET_AUDIO_CLIP, UNITY_ASSET_SCRIPT, UNITY_ASSET_PREFAB, UNITY_ASSET_SCENE, UNITY_ASSET_ANIMATION, UNITY_ASSET_FONT } unity_asset_type; // Unity bundle handle typedef struct unity_graphite_bundle unity_graphite_bundle; // Unity-specific loading flags typedef enum { UNITY_LOAD_IMMEDIATE = 0, // Load all assets immediately UNITY_LOAD_STREAMING = 1 << 0, // Enable streaming for large assets UNITY_LOAD_ASYNC = ` }