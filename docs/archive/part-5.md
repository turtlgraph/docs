``## 22. Implementation Guidelines This section provides comprehensive guidance for implementing GRAPHITE in production environments, covering architectural decisions, coding standards, and best practices. ### 22.1 Architecture Guidelines #### 22.1.1 Modular Design Principles ```c // Core module structure for GRAPHITE implementation typedef struct graphite_module { const char* name; const char* version; const graphite_module_interface* interface; void* private_data; graphite_module_state state; } graphite_module; // Well-defined module interfaces typedef struct { graphite_result (*init)(void** context, const graphite_config* config); graphite_result (*process)(void* context, const graphite_input* input, graphite_output* output); void (*cleanup)(void* context); graphite_result (*get_info)(void* context, graphite_module_info* info); } graphite_module_interface; // Example: Compression module implementation static const graphite_module_interface compression_interface = { .init = compression_init, .process = compression_process, .cleanup = compression_cleanup, .get_info = compression_get_info }; // Module registry for dependency injection typedef struct { hashtable* modules; // name -> module mapping dynamic_array* load_order; // Module initialization order graphite_config* global_config; } graphite_module_registry; // Register modules with clear dependencies graphite_result graphite_register_module( graphite_module_registry* registry, const char* name, const graphite_module_interface* interface, const char** dependencies, size_t dependency_count ) { // Validate dependencies exist for (size_t i = 0; i < dependency_count; i++) { if (!hashtable_contains(registry->modules, dependencies[i])) { return GRAPHITE_ERROR_MISSING_DEPENDENCY; } } // Create module instance graphite_module* module = malloc(sizeof(graphite_module)); module->name = strdup(name); module->interface = interface; module->state = GRAPHITE_MODULE_REGISTERED; // Initialize module graphite_result result = interface->init(&module->private_data, registry->global_config); if (result != GRAPHITE_SUCCESS) { free(module); return result; } module->state = GRAPHITE_MODULE_INITIALIZED; hashtable_insert(registry->modules, name, module); return GRAPHITE_SUCCESS; } ``` #### 22.1.2 Error Handling Strategy ```c // Comprehensive error handling system typedef enum { GRAPHITE_ERROR_CATEGORY_SYSTEM, // OS/system level errors GRAPHITE_ERROR_CATEGORY_FORMAT, // File format errors GRAPHITE_ERROR_CATEGORY_MEMORY, // Memory allocation errors GRAPHITE_ERROR_CATEGORY_IO, // I/O operation errors GRAPHITE_ERROR_CATEGORY_SECURITY, // Security/validation errors GRAPHITE_ERROR_CATEGORY_CONFIG, // Configuration errors GRAPHITE_ERROR_CATEGORY_NETWORK, // Network operation errors GRAPHITE_ERROR_CATEGORY_USER // User input errors } graphite_error_category; typedef struct { graphite_result code; graphite_error_category category; const char* message; const char* file; int line; const char* function; uint64_t timestamp; void* context_data; } graphite_error_info; // Error context for detailed debugging typedef struct { graphite_error_info* error_stack; size_t stack_size; size_t stack_capacity; graphite_log_callback log_callback; void* log_user_data; } graphite_error_context; // Error reporting macros #define GRAPHITE_SET_ERROR(ctx, code, cat, msg) \\ graphite_set_error_impl(ctx, code, cat, msg, __FILE__, __LINE__, __func__) #define GRAPHITE_PROPAGATE_ERROR(ctx, result) \\ do { \\ if (result != GRAPHITE_SUCCESS) { \\ graphite_add_error_context(ctx, __FILE__, __LINE__, __func__); \\ return result; \\ } \\ } while(0) // Error handling implementation void graphite_set_error_impl( graphite_error_context* ctx, graphite_result code, graphite_error_category category, const char* message, const char* file, int line, const char* function ) { if (!ctx) return; // Ensure stack capacity if (ctx->stack_size >= ctx->stack_capacity) { size_t new_capacity = ctx->stack_capacity ? ctx->stack_capacity * 2 : 16; graphite_error_info* new_stack = realloc(ctx->error_stack, new_capacity * sizeof(graphite_error_info)); if (!new_stack) return; // Can't report out of memory for error reporting ctx->error_stack = new_stack; ctx->stack_capacity = new_capacity; } // Add error to stack graphite_error_info* error = &ctx->error_stack[ctx->stack_size++]; error->code = code; error->category = category; error->message = message; error->file = file; error->line = line; error->function = function; error->timestamp = graphite_get_time_ms(); // Log error if callback provided if (ctx->log_callback) { ctx->log_callback(GRAPHITE_LOG_ERROR, message, ctx->log_user_data); } } // Resource cleanup with error handling typedef struct { void (*cleanup_func)(void* resource); void* resource; const char* description; } graphite_cleanup_item; typedef struct { graphite_cleanup_item* items; size_t count; size_t capacity; } graphite_cleanup_stack; #define GRAPHITE_DEFER_CLEANUP(stack, func, resource, desc) \\ graphite_defer_cleanup(stack, (void(*)(void*))func, resource, desc) void graphite_defer_cleanup( graphite_cleanup_stack* stack, void (*cleanup_func)(void*), void* resource, const char* description ) { if (stack->count >= stack->capacity) { size_t new_capacity = stack->capacity ? stack->capacity * 2 : 16; graphite_cleanup_item* new_items = realloc(stack->items, new_capacity * sizeof(graphite_cleanup_item)); if (!new_items) return; // Silent failure in cleanup registration stack->items = new_items; stack->capacity = new_capacity; } graphite_cleanup_item* item = &stack->items[stack->count++]; item->cleanup_func = cleanup_func; item->resource = resource; item->description = description; } void graphite_execute_cleanup(graphite_cleanup_stack* stack) { // Execute in reverse order (LIFO) for (int i = (int)stack->count - 1; i >= 0; i--) { graphite_cleanup_item* item = &stack->items[i]; if (item->cleanup_func && item->resource) { item->cleanup_func(item->resource); } } stack->count = 0; } ``` ### 22.2 Performance Implementation Guidelines #### 22.2.1 Memory Management Best Practices ```c // Pool-based allocation for frequent small objects typedef struct { void* memory_block; size_t block_size; size_t object_size; size_t object_count; uint32_t* free_bitmap; // Bitmap of free objects size_t next_free_hint; // Hint for next free object atomic_size_t allocated_count; } graphite_object_pool; graphite_object_pool* graphite_pool_create(size_t object_size, size_t initial_count) { // Align object size to cache line boundary size_t aligned_size = (object_size + 63) & ~63; graphite_object_pool* pool = malloc(sizeof(graphite_object_pool)); if (!pool) return NULL; pool->object_size = aligned_size; pool->object_count = initial_count; pool->block_size = aligned_size * initial_count; // Allocate aligned memory block pool->memory_block = graphite_aligned_alloc(pool->block_size, 64); if (!pool->memory_block) { free(pool); return NULL; } // Initialize free bitmap (all objects initially free) size_t bitmap_size = (initial_count + 31) / 32; pool->free_bitmap = calloc(bitmap_size, sizeof(uint32_t)); if (!pool->free_bitmap) { graphite_aligned_free(pool->memory_block); free(pool); return NULL; } // Mark all objects as free for (size_t i = 0; i < initial_count; i++) { size_t word_idx = i / 32; size_t bit_idx = i % 32; pool->free_bitmap[word_idx] |= (1U << bit_idx); } pool->next_free_hint = 0; atomic_init(&pool->allocated_count, 0); return pool; } void* graphite_pool_alloc(graphite_object_pool* pool) { // Fast path: check hint first size_t start_idx = pool->next_free_hint; for (size_t i = 0; i < pool->object_count; i++) { size_t idx = (start_idx + i) % pool->object_count; size_t word_idx = idx / 32; size_t bit_idx = idx % 32; uint32_t mask = 1U << bit_idx; if (pool->free_bitmap[word_idx] & mask) { // Found free object, mark as allocated pool->free_bitmap[word_idx] &= ~mask; pool->next_free_hint = (idx + 1) % pool->object_count; atomic_fetch_add(&pool->allocated_count, 1); // Return aligned pointer return (uint8_t*)pool->memory_block + (idx * pool->object_size); } } return NULL; // Pool exhausted } void graphite_pool_free(graphite_object_pool* pool, void* ptr) { if (!ptr || ptr < pool->memory_block) return; // Calculate object index ptrdiff_t offset = (uint8_t*)ptr - (uint8_t*)pool->memory_block; if (offset % pool->object_size != 0) return; // Invalid pointer size_t idx = offset / pool->object_size; if (idx >= pool->object_count) return; // Out of bounds // Mark as free size_t word_idx = idx / 32; size_t bit_idx = idx % 32; uint32_t mask = 1U << bit_idx; if (!(pool->free_bitmap[word_idx] & mask)) { pool->free_bitmap[word_idx] |= mask; atomic_fetch_sub(&pool->allocated_count, 1); // Update hint for faster allocation if (idx < pool->next_free_hint) { pool->next_free_hint = idx; } } } // RAII-style resource management #define GRAPHITE_SCOPED_POOL_ALLOC(pool, type) \\ __attribute__((cleanup(graphite_pool_free_cleanup))) \\ type* ptr = (type*)graphite_pool_alloc(pool); \\ if (!ptr) return GRAPHITE_ERROR_ALLOCATION static void graphite_pool_free_cleanup(void* ptr_to_ptr) { void** ptr = (void**)ptr_to_ptr; if (*ptr) { // Note: This requires pool context - in practice, use a wrapper // that stores pool reference with the allocation graphite_pool_free(current_pool, *ptr); } } ``` #### 22.2.2 Cache-Friendly Data Structures ```c // Structure of Arrays (SoA) for better cache utilization typedef struct { // Instead of Array of Structures (AoS): // struct { uint32_t id; float position[3]; uint32_t flags; } nodes[]; // Use Structure of Arrays (SoA): uint32_t* ids; // Cache line aligned float* positions; // 3 floats per node, packed uint32_t* flags; // Cache line aligned size_t count; size_t capacity; // Memory layout optimized for common access patterns void* memory_block; // Single allocation for all arrays } graphite_node_array; graphite_node_array* graphite_nodes_create(size_t initial_capacity) { graphite_node_array* nodes = malloc(sizeof(graphite_node_array)); if (!nodes) return NULL; // Calculate memory layout with cache line alignment size_t ids_size = initial_capacity * sizeof(uint32_t); size_t positions_size = initial_capacity * 3 * sizeof(float); size_t flags_size = initial_capacity * sizeof(uint32_t); // Align each array to cache line boundary ids_size = (ids_size + 63) & ~63; positions_size = (positions_size + 63) & ~63; flags_size = (flags_size + 63) & ~63; size_t total_size = ids_size + positions_size + flags_size; nodes->memory_block = graphite_aligned_alloc(total_size, 64); if (!nodes->memory_block) { free(nodes); return NULL; } // Set up array pointers uint8_t* base = (uint8_t*)nodes->memory_block; nodes->ids = (uint32_t*)base; nodes->positions = (float*)(base + ids_size); nodes->flags = (uint32_t*)(base + ids_size + positions_size); nodes->count = 0; nodes->capacity = initial_capacity; return nodes; } // Cache-friendly iteration patterns void graphite_nodes_process_positions(graphite_node_array* nodes, graphite_matrix4 transform) { // Process in chunks that fit in cache const size_t chunk_size = 64; // Tune based on cache size for (size_t start = 0; start < nodes->count; start += chunk_size) { size_t end = start + chunk_size; if (end > nodes->count) end = nodes->count; // Prefetch next chunk if (end < nodes->count) { __builtin_prefetch(&nodes->positions[end * 3], 0, 3); } // Process current chunk for (size_t i = start; i < end; i++) { float* pos = &nodes->positions[i * 3]; graphite_transform_point(transform, pos); } } } // Branch-friendly data organization typedef struct { // Group related data to minimize branches struct { uint32_t visible_count; uint32_t* visible_indices; } visible; struct { uint32_t culled_count; uint32_t* culled_indices; } culled; struct { uint32_t dirty_count; uint32_t* dirty_indices; } dirty; } graphite_node_buckets; // Bucket sorting for cache-friendly processing void graphite_bucket_nodes_by_state(graphite_node_array* nodes, graphite_node_buckets* buckets) { buckets->visible.visible_count = 0; buckets->culled.culled_count = 0; buckets->dirty.dirty_count = 0; // Single pass bucketing for (size_t i = 0; i < nodes->count; i++) { uint32_t flags = nodes->flags[i]; if (flags & GRAPHITE_NODE_VISIBLE) { buckets->visible.visible_indices[buckets->visible.visible_count++] = i; } else if (flags & GRAPHITE_NODE_CULLED) { buckets->culled.culled_indices[buckets->culled.culled_count++] = i; } if (flags & GRAPHITE_NODE_DIRTY) { buckets->dirty.dirty_indices[buckets->dirty.dirty_count++] = i; } } } ``` ### 22.3 Threading and Concurrency Guidelines #### 22.3.1 Lock-Free Data Structures ```c // Lock-free queue for work distribution typedef struct { atomic_ptr head; atomic_ptr tail; atomic_size_t size; } graphite_lockfree_queue; typedef struct graphite_queue_node { atomic_ptr next; void* data; } graphite_queue_node; graphite_lockfree_queue* graphite_queue_create(void) { graphite_lockfree_queue* queue = malloc(sizeof(graphite_lockfree_queue)); if (!queue) return NULL; // Create dummy node graphite_queue_node* dummy = malloc(sizeof(graphite_queue_node)); if (!dummy) { free(queue); return NULL; } atomic_init(&dummy->next, NULL); dummy->data = NULL; atomic_init(&queue->head, dummy); atomic_init(&queue->tail, dummy); atomic_init(&queue->size, 0); return queue; } bool graphite_queue_enqueue(graphite_lockfree_queue* queue, void* data) { graphite_queue_node* node = malloc(sizeof(graphite_queue_node)); if (!node) return false; atomic_init(&node->next, NULL); node->data = data; graphite_queue_node* tail; while (true) { tail = atomic_load(&queue->tail); graphite_queue_node* next = atomic_load(&tail->next); if (tail == atomic_load(&queue->tail)) { // Tail hasn't changed if (next == NULL) { // Try to link node at the end of the list if (atomic_compare_exchange_weak(&tail->next, &next, node)) { break; // Successfully enqueued } } else { // Try to swing tail to the next node atomic_compare_exchange_weak(&queue->tail, &tail, next); } } } // Try to swing tail to the inserted node atomic_compare_exchange_weak(&queue->tail, &tail, node); atomic_fetch_add(&queue->size, 1); return true; } bool graphite_queue_dequeue(graphite_lockfree_queue* queue, void** data) { graphite_queue_node* head; graphite_queue_node* tail; graphite_queue_node* next; while (true) { head = atomic_load(&queue->head); tail = atomic_load(&queue->tail); next = atomic_load(&head->next); if (head == atomic_load(&queue->head)) { // Head hasn't changed if (head == tail) { if (next == NULL) { return false; // Queue is empty } // Try to swing tail to the next node atomic_compare_exchange_weak(&queue->tail, &tail, next); } else { if (next == NULL) { continue; // Another thread is modifying the queue } // Read data before CAS *data = next->data; // Try to swing head to the next node if (atomic_compare_exchange_weak(&queue->head, &head, next)) { atomic_fetch_sub(&queue->size, 1); free(head); return true; } } } } } // Work-stealing thread pool typedef struct { graphite_lockfree_queue* global_queue; graphite_lockfree_queue** worker_queues; pthread_t* threads; atomic_bool shutdown; uint32_t thread_count; uint32_t current_thread_id; // Thread-local } graphite_thread_pool; typedef struct { void (*function)(void* arg); void* argument; atomic_int* completion_counter; // For synchronization } graphite_work_item; static __thread uint32_t tls_thread_id = UINT32_MAX; void* graphite_worker_thread(void* arg) { graphite_thread_pool* pool = (graphite_thread_pool*)arg; uint32_t thread_id = atomic_fetch_add(&pool->current_thread_id, 1); tls_thread_id = thread_id; graphite_lockfree_queue* my_queue = pool->worker_queues[thread_id]; while (!atomic_load(&pool->shutdown)) { graphite_work_item* work = NULL; // Try to get work from own queue first if (graphite_queue_dequeue(my_queue, (void**)&work)) { work->function(work->argument); if (work->completion_counter) { atomic_fetch_sub(work->completion_counter, 1); } free(work); continue; } // Try to steal work from other threads for (uint32_t i = 0; i < pool->thread_count; i++) { if (i == thread_id) continue; if (graphite_queue_dequeue(pool->worker_queues[i], (void**)&work)) { work->function(work->argument); if (work->completion_counter) { atomic_fetch_sub(work->completion_counter, 1); } free(work); goto continue_work; } } // Try global queue if (graphite_queue_dequeue(pool->global_queue, (void**)&work)) { work->function(work->argument); if (work->completion_counter) { atomic_fetch_sub(work->completion_counter, 1); } free(work); continue; } continue_work: // No work available, yield CPU sched_yield(); } return NULL; } // Submit work to thread pool void graphite_pool_submit(graphite_thread_pool* pool, void (*function)(void*), void* argument, atomic_int* completion_counter) { graphite_work_item* work = malloc(sizeof(graphite_work_item)); work->function = function; work->argument = argument; work->completion_counter = completion_counter; if (completion_counter) { atomic_fetch_add(completion_counter, 1); } // If called from worker thread, use local queue if (tls_thread_id < pool->thread_count) { graphite_queue_enqueue(pool->worker_queues[tls_thread_id], work); } else { // Use global queue for external submissions graphite_queue_enqueue(pool->global_queue, work); } } ``` --- ## 23. Quality Assurance & Testing Framework Comprehensive testing strategy covering unit tests, integration tests, performance tests, and security validation. ### 23.1 Testing Pyramid #### 23.1.1 Unit Testing Framework ```c // Lightweight unit testing framework for GRAPHITE typedef enum { GRAPHITE_TEST_PASS, GRAPHITE_TEST_FAIL, GRAPHITE_TEST_SKIP } graphite_test_result; typedef struct { const char* name; const char* suite; graphite_test_result (*test_func)(void); uint64_t execution_time_ns; const char* failure_message; } graphite_test_case; typedef struct { graphite_test_case* tests; size_t test_count; size_t capacity; // Statistics size_t passed; size_t failed; size_t skipped; uint64_t total_time_ns; } graphite_test_suite; // Test assertion macros #define GRAPHITE_ASSERT_EQ(expected, actual) \\ do { \\ if ((expected) != (actual)) { \\ printf(\"ASSERTION FAILED: %s:%d\ \", __FILE__, __LINE__); \\ printf(\" Expected: %lld\ \", (long long)(expected)); \\ printf(\" Actual: %lld\ \", (long long)(actual)); \\ return GRAPHITE_TEST_FAIL; \\ } \\ } while(0) #define GRAPHITE_ASSERT_STR_EQ(expected, actual) \\ do { \\ if (strcmp((expected), (actual)) != 0) { \\ printf(\"ASSERTION FAILED: %s:%d\ \", __FILE__, __LINE__); \\ printf(\" Expected: \\\"%s\\\"\ \", (expected)); \\ printf(\" Actual: \\\"%s\\\"\ \", (actual)); \\ return GRAPHITE_TEST_FAIL; \\ } \\ } while(0) #define GRAPHITE_ASSERT_NOT_NULL(ptr) \\ do { \\ if ((ptr) == NULL) { \\ printf(\"ASSERTION FAILED: %s:%d\ \", __FILE__, __LINE__); \\ printf(\" Expected non-NULL pointer\ \"); \\ return GRAPHITE_TEST_FAIL; \\ } \\ } while(0) #define GRAPHITE_ASSERT_NULL(ptr) \\ do { \\ if ((ptr) != NULL) { \\ printf(\"ASSERTION FAILED: %s:%d\ \", __FILE__, __LINE__); \\ printf(\" Expected NULL pointer\ \"); \\ return GRAPHITE_TEST_FAIL; \\ } \\ } while(0) // Test fixture support typedef struct { void (*setup)(void); void (*teardown)(void); void* fixture_data; } graphite_test_fixture; // Example unit tests graphite_test_result test_bundle_creation(void) { // Test basic bundle creation graphite_bundle_builder* builder = graphite_builder_create(); GRAPHITE_ASSERT_NOT_NULL(builder); // Add some test data const char* test_string = \"Hello, GRAPHITE!\"; uint32_t string_id = graphite_builder_add_string(builder, test_string); GRAPHITE_ASSERT_EQ(0, string_id); // First string should have ID 0 // Create bundle graphite_bundle* bundle = graphite_builder_finalize(builder); GRAPHITE_ASSERT_NOT_NULL(bundle); // Verify string retrieval const char* retrieved = graphite_get_string(bundle, string_id); GRAPHITE_ASSERT_STR_EQ(test_string, retrieved); // Cleanup graphite_close(bundle); graphite_builder_destroy(builder); return GRAPHITE_TEST_PASS; } graphite_test_result test_graph_traversal(void) { // Create a simple graph: A -> B -> C graphite_bundle_builder* builder = graphite_builder_create(); // Create nodes graphite_node_id node_a = graphite_builder_create_node(builder); graphite_node_id node_b = graphite_builder_create_node(builder); graphite_node_id node_c = graphite_builder_create_node(builder); // Create edges graphite_builder_add_edge(builder, node_a, node_b, GRAPHITE_EDGE_REFERENCE); graphite_builder_add_edge(builder, node_b, node_c, GRAPHITE_EDGE_REFERENCE); // Finalize bundle graphite_bundle* bundle = graphite_builder_finalize(builder); GRAPHITE_ASSERT_NOT_NULL(bundle); // Test traversal const graphite_graph* root = graphite_root(bundle); GRAPHITE_ASSERT_NOT_NULL(root); // Verify graph structure GRAPHITE_ASSERT_EQ(3, root->header.node_cnt); GRAPHITE_ASSERT_EQ(2, root->header.edge_cnt); // Test edge traversal const graphite_graph* node_a_graph = graphite_get_child_graph(root, 0); GRAPHITE_ASSERT_NOT_NULL(node_a_graph); // Cleanup graphite_close(bundle); graphite_builder_destroy(builder); return GRAPHITE_TEST_PASS; } // Property-based testing support typedef struct { void* (*generate)(size_t seed); void (*free_data)(void* data); bool (*property)(void* data); const char* description; } graphite_property_test; bool property_bundle_roundtrip(void* data) { graphite_test_data* test = (graphite_test_data*)data; // Create bundle with random data graphite_bundle_builder* builder = graphite_builder_create(); for (size_t i = 0; i < test->string_count; i++) { graphite_builder_add_string(builder, test->strings[i]); } for (size_t i = 0; i < test->blob_count; i++) { graphite_builder_add_blob(builder, test->blobs[i].data, test->blobs[i].size); } graphite_bundle* bundle = graphite_builder_finalize(builder); if (!bundle) return false; // Verify all data can be retrieved correctly for (size_t i = 0; i < test->string_count; i++) { const char* retrieved = graphite_get_string(bundle, i); if (strcmp(test->strings[i], retrieved) != 0) { graphite_close(bundle); graphite_builder_destroy(builder); return false; } } for (size_t i = 0; i < test->blob_count; i++) { size_t size; const void* retrieved = graphite_get_blob(bundle, i, &size); if (size != test->blobs[i].size || memcmp(retrieved, test->blobs[i].data, size) != 0) { graphite_close(bundle); graphite_builder_destroy(builder); return false; } } graphite_close(bundle); graphite_builder_destroy(builder); return true; } // Fuzz testing integration typedef struct { uint8_t* data; size_t size; uint32_t seed; } graphite_fuzz_input; void graphite_fuzz_bundle_parser(const graphite_fuzz_input* input) { // Parse bundle with fuzzing input graphite_bundle* bundle = graphite_open_from_memory(input->data, input->size); if (bundle) { // If parsing succeeded, try to access data safely const graphite_graph* root = graphite_root(bundle); if (root) { // Traverse graph carefully for (uint32_t i = 0; i < root->header.node_cnt && i < 1000; i++) { const graphite_graph* child = graphite_get_child_graph(root, i); if (child) { // Access some data volatile uint32_t dummy = child->header.node_cnt; (void)dummy; } } } graphite_close(bundle); } } // Test runner void graphite_run_tests(void) { graphite_test_suite suite = {0}; // Register tests graphite_test_case tests[] = { {\"Bundle Creation\", \"Core\", test_bundle_creation, 0, NULL}, {\"Graph Traversal\", \"Core\", test_graph_traversal, 0, NULL}, // Add more tests... }; suite.tests = tests; suite.test_count = sizeof(tests) / sizeof(tests[0]); printf(\"Running GRAPHITE test suite...\ \"); printf(\"================================\ \"); for (size_t i = 0; i < suite.test_count; i++) { graphite_test_case* test = &suite.tests[i]; printf(\"Running %s::%s... \", test->suite, test->name); fflush(stdout); uint64_t start_time = graphite_get_precise_time_ns(); graphite_test_result result = test->test_func(); uint64_t end_time = graphite_get_precise_time_ns(); test->execution_time_ns = end_time - start_time; switch (result) { case GRAPHITE_TEST_PASS: printf(\"PASS (%.2f ms)\ \", test->execution_time_ns / 1e6); suite.passed++; break; case GRAPHITE_TEST_FAIL: printf(\"FAIL (%.2f ms)\ \", test->execution_time_ns / 1e6); suite.failed++; break; case GRAPHITE_TEST_SKIP: printf(\"SKIP\ \"); suite.skipped++; break; } suite.total_time_ns += test->execution_time_ns; } printf(\"\ \"); printf(\"Results: %zu passed, %zu failed, %zu skipped\ \", suite.passed, suite.failed, suite.skipped); printf(\"Total time: %.2f ms\ \", suite.total_time_ns / 1e6); if (suite.failed > 0) { printf(\"TESTS FAILED!\ \"); exit(1); } else { printf(\"All tests passed!\ \"); } } ``` ### 23.2 Integration Testing #### 23.2.1 End-to-End Pipeline Tests ```c // Integration test framework typedef struct { const char* temp_directory; char** created_files; size_t file_count; graphite_test_fixture fixture; } graphite_integration_context; // Test full asset pipeline graphite_test_result test_asset_pipeline_integration(void) { graphite_integration_context ctx = {0}; ctx.temp_directory = \"/tmp/graphite_test_XXXXXX\"; // Create temporary directory char* temp_dir = mkdtemp((char*)ctx.temp_directory); GRAPHITE_ASSERT_NOT_NULL(temp_dir); // Create test assets char texture_path[256]; snprintf(texture_path, sizeof(texture_path), \"%s/test_texture.png\", temp_dir); // Generate test PNG file graphite_result result = graphite_create_test_png(texture_path, 256, 256); GRAPHITE_ASSERT_EQ(GRAPHITE_SUCCESS, result); char mesh_path[256]; snprintf(mesh_path, sizeof(mesh_path), \"%s/test_mesh.gltf\", temp_dir); // Generate test GLTF file result = graphite_create_test_gltf(mesh_path, texture_path); GRAPHITE_ASSERT_EQ(GRAPHITE_SUCCESS, result); // Create transform configuration char config_path[256]; snprintf(config_path, sizeof(config_path), \"%s/transform_config.json\", temp_dir); const char* config_json = \"{\ \" \" \\\"transforms\\\": [\ \" \" {\ \" \" \\\"name\\\": \\\"texture_compress\\\",\ \" \" \\\"input_patterns\\\": [\\\"*.png\\\"],\ \" \" \\\"output_format\\\": \\\"bc7\\\",\ \" \" \\\"parameters\\\": {\\\"quality\\\": \\\"high\\\"}\ \" \" },\ \" \" {\ \" \" \\\"name\\\": \\\"mesh_optimize\\\",\ \" \" \\\"input_patterns\\\": [\\\"*.gltf\\\"],\ \" \" \\\"output_format\\\": \\\"optimized_mesh\\\"\ \" \" }\ \" \" ]\ \" \"}\ \"; FILE* config_file = fopen(config_path, \"w\"); GRAPHITE_ASSERT_NOT_NULL(config_file); fwrite(config_json, 1, strlen(config_json), config_file); fclose(config_file); // Run asset pipeline char bundle_path[256]; snprintf(bundle_path, sizeof(bundle_path), \"%s/output.graphite\", temp_dir); char command[1024]; snprintf(command, sizeof(command), \"graphite pack --config %s --output %s %s\", config_path, bundle_path, temp_dir); int exit_code = system(command); GRAPHITE_ASSERT_EQ(0, exit_code); // Verify bundle was created FILE* bundle_file = fopen(bundle_path, \"rb\"); GRAPHITE_ASSERT_NOT_NULL(bundle_file); fclose(bundle_file); // Load and verify bundle graphite_bundle* bundle = graphite_open(bundle_path); GRAPHITE_ASSERT_NOT_NULL(bundle); const graphite_graph* root = graphite_root(bundle); GRAPHITE_ASSERT_NOT_NULL(root); GRAPHITE_ASSERT_EQ(true, root->header.node_cnt > 0); // Verify integrity bool integrity_ok = graphite_verify_integrity(bundle); GRAPHITE_ASSERT_EQ(true, integrity_ok); // Cleanup graphite_close(bundle); // Remove temporary files char rm_command[512]; snprintf(rm_command, sizeof(rm_command), \"rm -rf %s\", temp_dir); system(rm_command); return GRAPHITE_TEST_PASS; } // Multi-platform testing typedef struct { const char* platform_name; const char* compiler; const char* flags; const char* test_command; } graphite_platform_config; static const graphite_platform_config test_platforms[] = { {\"Linux x86_64\", \"gcc\", \"-O3 -DNDEBUG\", \"./test_suite\"}, {\"Linux x86_64 Debug\", \"gcc\", \"-O0 -g -fsanitize=address\", \"./test_suite\"}, {\"Linux ARM64\", \"aarch64-linux-gnu-gcc\", \"-O3 -DNDEBUG\", \"qemu-aarch64 ./test_suite\"}, {\"Windows x64\", \"x86_64-w64-mingw32-gcc\", \"-O3 -DNDEBUG\", \"wine ./test_suite.exe\"}, {\"macOS x64\", \"clang\", \"-O3 -DNDEBUG -target x86_64-apple-macos10.12\", \"./test_suite\"} }; void graphite_run_cross_platform_tests(void) { size_t platform_count = sizeof(test_platforms) / sizeof(test_platforms[0]); for (size_t i = 0; i < platform_count; i++) { const graphite_platform_config* platform = &test_platforms[i]; printf(\"Testing on %s...\ \", platform->platform_name); // Build for platform char build_command[1024]; snprintf(build_command, sizeof(build_command), \"make clean && CC=%s CFLAGS='%s' make test_suite\", platform->compiler, platform->flags); int build_result = system(build_command); if (build_result != 0) { printf(\" Build FAILED\ \"); continue; } // Run tests int test_result = system(platform->test_command); if (test_result == 0) { printf(\" Tests PASSED\ \"); } else { printf(\" Tests FAILED (exit code: %d)\ \", test_result); } } } ``` ### 23.3 Performance Testing #### 23.3.1 Automated Performance Validation ```c // Performance test framework typedef struct { const char* test_name; void (*setup)(void** context); void (*benchmark)(void* context, graphite_benchmark_result* result); void (*teardown)(void* context); // Performance thresholds uint64_t max_time_ns; size_t max_memory_bytes; double min_throughput_mbps; } graphite_performance_test; // Regression detection typedef struct { graphite_benchmark_result baseline; graphite_benchmark_result current; double regression_threshold; // Percentage } graphite_regression_analysis; bool graphite_detect_regression(const graphite_regression_analysis* analysis) { // Check time regression if (analysis->baseline.mean_time_ns > 0) { double time_regression = ((double)analysis->current.mean_time_ns - analysis->baseline.mean_time_ns) / analysis->baseline.mean_time_ns * 100.0; if (time_regression > analysis->regression_threshold) { printf(\"REGRESSION: Time increased by %.1f%%\ \", time_regression); return true; } } // Check memory regression if (analysis->baseline.max_memory_bytes > 0) { double memory_regression = ((double)analysis->current.max_memory_bytes - analysis->baseline.max_memory_bytes) / analysis->baseline.max_memory_bytes * 100.0; if (memory_regression > analysis->regression_threshold) { printf(\"REGRESSION: Memory usage increased by %.1f%%\ \", memory_regression); return true; } } return false; } // Performance test implementation void setup_large_bundle_test(void** context) { // Create large test bundle *context = graphite_create_large_test_bundle(1000000); // 1M nodes } void benchmark_large_bundle_open(void* context, graphite_benchmark_result* result) { graphite_bundle* test_bundle = (graphite_bundle*)context; // Benchmark bundle opening const int iterations = 100; uint64_t* times = malloc(sizeof(uint64_t) * iterations); for (int i = 0; i < iterations; i++) { uint64_t start = graphite_get_precise_time_ns(); graphite_bundle* bundle = graphite_open(\"large_test.graphite\"); uint64_t end = graphite_get_precise_time_ns(); times[i] = end - start; if (bundle) { graphite_close(bundle); } } // Calculate statistics qsort(times, iterations, sizeof(uint64_t), compare_uint64); result->min_time_ns = times[0]; result->max_time_ns = times[iterations - 1]; result->median_time_ns = times[iterations / 2]; result->p95_time_ns = times[(iterations * 95) / 100]; result->p99_time_ns = times[(iterations * 99) / 100]; uint64_t sum = 0; for (int i = 0; i < iterations; i++) { sum += times[i]; } result->mean_time_ns = sum / iterations; free(times); } void teardown_large_bundle_test(void* context) { graphite_bundle* test_bundle = (graphite_bundle*)context; if (test_bundle) { graphite_close(test_bundle); } unlink(\"large_test.graphite\"); } // Stress testing void graphite_stress_test_concurrent_access(void) { const char* bundle_path = \"stress_test.graphite\"; const int thread_count = 32; const int iterations_per_thread = 10000; // Create test bundle graphite_create_test_bundle(bundle_path, 10000); // 10K nodes // Shared state atomic_int successful_operations = ATOMIC_VAR_INIT(0); atomic_int failed_operations = ATOMIC_VAR_INIT(0); // Thread function auto stress_worker = [](void* arg) -> void* { const char* path = (const char*)arg; for (int i = 0; i < iterations_per_thread; i++) { graphite_bundle* bundle = graphite_open(path); if (bundle) { // Perform random operations const graphite_graph* root = graphite_root(bundle); if (root && root->header.node_cnt > 0) { uint32_t random_node = rand() % root->header.node_cnt; const graphite_graph* node = graphite_get_child_graph(root, random_node); if (node) { atomic_fetch_add(&successful_operations, 1); } else { atomic_fetch_add(&failed_operations, 1); } } else { atomic_fetch_add(&failed_operations, 1); } graphite_close(bundle); } else { atomic_fetch_add(&failed_operations, 1); } } return NULL; }; // Create threads pthread_t* threads = malloc(sizeof(pthread_t) * thread_count); uint64_t start_time = graphite_get_precise_time_ns(); for (int i = 0; i < thread_count; i++) { pthread_create(&threads[i], NULL, stress_worker, (void*)bundle_path); } // Wait for completion for (int i = 0; i < thread_count; i++) { pthread_join(threads[i], NULL); } uint64_t end_time = graphite_get_precise_time_ns(); // Report results int successful = atomic_load(&successful_operations); int failed = atomic_load(&failed_operations); double duration_seconds = (end_time - start_time) / 1e9; double ops_per_second = (successful + failed) / duration_seconds; printf(\"Stress Test Results:\ \"); printf(\" Threads: %d\ \", thread_count); printf(\" Total operations: %d\ \", successful + failed); printf(\" Successful: %d (%.1f%%)\ \", successful, 100.0 * successful / (successful + failed)); printf(\" Failed: %d (%.1f%%)\ \", failed, 100.0 * failed / (successful + failed)); printf(\" Duration: %.2f seconds\ \", duration_seconds); printf(\" Throughput: %.0f ops/sec\ \", ops_per_second); free(threads); unlink(bundle_path); // Fail test if too many operations failed if (failed > (successful + failed) * 0.01) { // More than 1% failure rate printf(\"STRESS TEST FAILED: Too many failed operations\ \"); exit(1); } } ``` --- ## 24. Deployment & Distribution Comprehensive deployment strategies for GRAPHITE across different environments and distribution channels. ### 24.1 Package Management Integration #### 24.1.1 Homebrew Formula ```ruby # Formula/graphite.rb class Graphite < Formula desc \"High-performance binary graph format for asset management\" homepage \"https://github.com/graphite-format/graphite\" url \"https://github.com/graphite-format/graphite/archive/v3.0.0.tar.gz\" sha256 \"abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890\" license \"MIT\" depends_on \"cmake\" => :build depends_on \"zstd\" depends_on \"blake3\" depends_on \"libsodium\" def install # Build with optimizations system \"cmake\", \"-S\", \".\", \"-B\", \"build\", \"-DCMAKE_BUILD_TYPE=Release\", \"-DGRAPHITE_BUILD_TOOLS=ON\", \"-DGRAPHITE_BUILD_TESTS=OFF\", \"-DGRAPHITE_ENABLE_SIMD=ON\", *std_cmake_args system \"cmake\", \"--build\", \"build\" system \"cmake\", \"--install\", \"build\" # Install additional tools bin.install \"build/tools/graphite-pack\" bin.install \"build/tools/graphite-info\" bin.install \"build/tools/graphite-verify\" # Install headers and libraries lib.install \"build/lib/libgraphite.a\" lib.install \"build/lib/libgraphite.dylib\" if OS.mac? lib.install \"build/lib/libgraphite.so\" if OS.linux? include.install Dir[\"include/graphite/*.h\"] # Install CMake configuration (lib/\"cmake/graphite\").install Dir[\"cmake/*.cmake\"] end test do # Create a simple test bundle (testpath/\"test.json\").write <<~EOS { \"assets\": [ { \"name\": \"test_asset\", \"type\": \"generic\", \"data\": \"SGVsbG8gV29ybGQ=\" } ] } EOS # Test bundle creation system bin/\"graphite-pack\", \"--input\", \"test.json\", \"--output\", \"test.graphite\" assert_predicate testpath/\"test.graphite\", :exist? # Test bundle verification system bin/\"graphite-verify\", \"test.graphite\" # Test bundle info system bin/\"graphite-info\", \"test.graphite\" end end ``` #### 24.1.2 vcpkg Port ```cmake # ports/graphite/portfile.cmake vcpkg_from_github( OUT_SOURCE_PATH SOURCE_PATH REPO graphite-format/graphite REF v3.0.0 SHA512 abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890 HEAD_REF main ) vcpkg_check_features(OUT_FEATURE_OPTIONS FEATURE_OPTIONS FEATURES tools GRAPHITE_BUILD_TOOLS tests GRAPHITE_BUILD_TESTS simd GRAPHITE_ENABLE_SIMD encryption GRAPHITE_ENABLE_ENCRYPTION ) vcpkg_cmake_configure( SOURCE_PATH \"${SOURCE_PATH}\" OPTIONS ${FEATURE_OPTIONS} -DGRAPHITE_BUILD_SHARED_LIBS=ON -DGRAPHITE_INSTALL_CMAKE_CONFIG=ON ) vcpkg_cmake_build() if(\"tests\" IN_LIST FEATURES) vcpkg_cmake_config_fixup(CONFIG_PATH lib/cmake/graphite-tests) endif() vcpkg_cmake_config_fixup(CONFIG_PATH lib/cmake/graphite) if(\"tools\" IN_LIST FEATURES) vcpkg_copy_tools( TOOL_NAMES graphite-pack graphite-info graphite-verify graphite-benchmark AUTO_CLEAN ) endif() file(REMOVE_RECURSE \"${CURRENT_PACKAGES_DIR}/debug/include\") file(REMOVE_RECURSE \"${CURRENT_PACKAGES_DIR}/debug/share\") file(INSTALL \"${SOURCE_PATH}/LICENSE\" DESTINATION \"${CURRENT_PACKAGES_DIR}/share/${PORT}\" RENAME copyright) ``` ### 24.2 Container Deployment #### 24.2.1 Docker Images ```dockerfile # Dockerfile.alpine - Minimal production image FROM alpine:3.18 AS builder # Install build dependencies RUN apk add --no-cache \\ build-base \\ cmake \\ git \\ zstd-dev \\ libsodium-dev # Copy source code COPY . /src WORKDIR /src # Build GRAPHITE RUN cmake -S . -B build \\ -DCMAKE_BUILD_TYPE=Release \\ -DGRAPHITE_BUILD_TOOLS=ON \\ -DGRAPHITE_BUILD_TESTS=OFF \\ -DGRAPHITE_STATIC_LINKING=ON && \\ cmake --build build --parallel $(nproc) && \\ cmake --install build --prefix /usr/local # Production stage FROM alpine:3.18 # Install runtime dependencies RUN apk add --no-cache \\ zstd \\ libsodium # Copy built binaries COPY --from=builder /usr/local/bin/graphite* /usr/local/bin/ COPY --from=builder /usr/local/lib/libgraphite* /usr/local/lib/ COPY --from=builder /usr/local/include/graphite /usr/local/include/graphite # Create working directory WORKDIR /data # Default command ENTRYPOINT [\"graphite\"] CMD [\"--help\"] # Labels LABEL org.opencontainers.image.title=\"GRAPHITE\" LABEL org.opencontainers.image.description=\"High-performance binary graph format\" LABEL org.opencontainers.image.version=\"3.0.0\" LABEL org.opencontainers.image.source=\"https://github.com/graphite-format/graphite\" ``` ```dockerfile # Dockerfile.ubuntu - Development image with debugging tools FROM ubuntu:22.04 # Install dependencies RUN apt-get update && apt-get install -y \\ build-essential \\ cmake \\ git \\ libzstd-dev \\ libsodium-dev \\ valgrind \\ gdb \\ perf-tools-unstable \\ strace \\ && rm -rf /var/lib/apt/lists/* # Copy source and build COPY . /src WORKDIR /src RUN cmake -S . -B build \\ -DCMAKE_BUILD_TYPE=Debug \\ -DGRAPHITE_BUILD_TOOLS=ON \\ -DGRAPHITE_BUILD_TESTS=ON \\ -DGRAPHITE_ENABLE_SANITIZERS=ON && \\ cmake --build build --parallel $(nproc) && \\ cmake --install build # Install debugging symbols RUN mkdir -p /usr/lib/debug/usr/local/bin && \\ cp build/tools/*.debug /usr/lib/debug/usr/local/bin/ 2>/dev/null || true WORKDIR /data ENTRYPOINT [\"graphite\"] ``` #### 24.2.2 Kubernetes Deployment ```yaml # k8s/namespace.yaml apiVersion: v1 kind: Namespace metadata: name: graphite-system labels: name: graphite-system --- # k8s/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: graphite-config namespace: graphite-system data: config.json: | { \"compression\": { \"algorithm\": \"zstd\", \"level\": 9 }, \"security\": { \"require_signature\": true, \"max_bundle_size_mb\": 1024 }, \"performance\": { \"worker_threads\": 4, \"memory_pool_size_mb\": 256 } } --- # k8s/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: graphite-processor namespace: graphite-system spec: replicas: 3 selector: matchLabels: app: graphite-processor template: metadata: labels: app: graphite-processor spec: containers: - name: graphite image: graphite:3.0.0 ports: - containerPort: 8080 env: - name: GRAPHITE_CONFIG value: \"/etc/graphite/config.json\" - name: GRAPHITE_LOG_LEVEL value: \"INFO\" volumeMounts: - name: config mountPath: /etc/graphite - name: data mountPath: /data resources: requests: memory: \"256Mi\" cpu: \"250m\" limits: memory: \"1Gi\" cpu: \"1000m\" livenessProbe: httpGet: path: /health port: 8080 initialDelaySeconds: 30 periodSeconds: 10 readinessProbe: httpGet: path: /ready port: 8080 initialDelaySeconds: 5 periodSeconds: 5 volumes: - name: config configMap: name: graphite-config - name: data persistentVolumeClaim: claimName: graphite-storage --- # k8s/service.yaml apiVersion: v1 kind: Service metadata: name: graphite-service namespace: graphite-system spec: selector: app: graphite-processor ports: - port: 80 targetPort: 8080 protocol: TCP type: ClusterIP --- # k8s/pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: graphite-storage namespace: graphite-system spec: accessModes: - ReadWriteMany resources: requests: storage: 100Gi storageClassName: fast-ssd ``` ### 24.3 Cloud Deployment #### 24.3.1 AWS Deployment with Terraform ```hcl # terraform/main.tf terraform { required_version = \">= 1.0\" required_providers { aws = { source = \"hashicorp/aws\" version = \"~> 5.0\" } } } provider \"aws\" { region = var.aws_region } # VPC and Networking module \"vpc\" { source = \"terraform-aws-modules/vpc/aws\" name = \"graphite-vpc\" cidr = \"10.0.0.0/16\" azs = [\"${var.aws_region}a\", \"${var.aws_region}b\", \"${var.aws_region}c\"] private_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"] public_subnets = [\"10.0.101.0/24\", \"10.0.102.0/24\", \"10.0.103.0/24\"] enable_nat_gateway = true enable_vpn_gateway = false tags = { Environment = var.environment Project = \"graphite\" } } # EKS Cluster module \"eks\" { source = \"terraform-aws-modules/eks/aws\" cluster_name = \"graphite-cluster\" cluster_version = \"1.27\" vpc_id = module.vpc.vpc_id subnet_ids = module.vpc.private_subnets # Node groups eks_managed_node_groups = { general = { min_size = 2 max_size = 10 desired_size = 3 instance_types = [\"m5.large\"] capacity_type = \"ON_DEMAND\" k8s_labels = { Environment = var.environment NodeGroup = \"general\" } } compute_optimized = { min_size = 0 max_size = 5 desired_size = 1 instance_types = [\"c5.xlarge\"] capacity_type = \"SPOT\" k8s_labels = { Environment = var.environment NodeGroup = \"compute\" } taints = { dedicated = { key = \"compute-optimized\" value = \"true\" effect = \"NO_SCHEDULE\" } } } } tags = { Environment = var.environment Project = \"graphite\" } } # S3 Bucket for asset storage resource \"aws_s3_bucket\" \"graphite_assets\" { bucket = \"graphite-assets-${var.environment}-${random_string.bucket_suffix.result}\" tags = { Environment = var.environment Project = \"graphite\" } } resource \"aws_s3_bucket_versioning\" \"graphite_assets\" { bucket = aws_s3_bucket.graphite_assets.id versioning_configuration { status = \"Enabled\" } } resource \"aws_s3_bucket_server_side_encryption_configuration\" \"graphite_assets\" { bucket = aws_s3_bucket.graphite_assets.id rule { apply_server_side_encryption_by_default { sse_algorithm = \"AES256\" } } } # CloudFront distribution for CDN resource \"aws_cloudfront_distribution\" \"graphite_cdn\" { origin { domain_name = aws_s3_bucket.graphite_assets.bucket_regional_domain_name origin_id = \"graphite-s3-origin\" s3_origin_config { origin_access_identity = aws_cloudfront_origin_access_identity.graphite_oai.cloudfront_access_identity_path } } enabled = true default_cache_behavior { target_origin_id = \"graphite-s3-origin\" viewer_protocol_policy = \"redirect-to-https\" allowed_methods = [\"GET\", \"HEAD\", \"OPTIONS\"] cached_methods = [\"GET\", \"HEAD\"] forwarded_values { query_string = false cookies { forward = \"none\" } } min_ttl = 0 default_ttl = 3600 max_ttl = 86400 } restrictions { geo_restriction { restriction_type = \"none\" } } viewer_certificate { cloudfront_default_certificate = true } tags = { Environment = var.environment Project = \"graphite\" } } resource \"aws_cloudfront_origin_access_identity\" \"graphite_oai\" { comment = \"OAI for GRAPHITE assets\" } # Random string for S3 bucket uniqueness resource \"random_string\" \"bucket_suffix\" { length = 8 special = false upper = false } # Variables variable \"aws_region\" { description = \"AWS region\" type = string default = \"us-west-2\" } variable \"environment\" { description = \"Environment name\" type = string default = \"production\" } # Outputs output \"eks_cluster_endpoint\" { value = module.eks.cluster_endpoint } output \"s3_bucket_name\" { value = aws_s3_bucket.graphite_assets.bucket } output \"cloudfront_domain_name\" { value = aws_cloudfront_distribution.graphite_cdn.domain_name } ``` #### 24.3.2 Azure Resource Manager Template ```json { \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\", \"contentVersion\": \"1.0.0.0\", \"parameters\": { \"environment\": { \"type\": \"string\", \"defaultValue\": \"production\", \"allowedValues\": [\"development\", \"staging\", \"production\"] }, \"location\": { \"type\": \"string\", \"defaultValue\": \"[resourceGroup().location]\" } }, \"variables\": { \"resourcePrefix\": \"[concat('graphite-', parameters('environment'))]\", \"storageAccountName\": \"[concat(replace(variables('resourcePrefix'), '-', ''), uniqueString(resourceGroup().id))]\", \"aksClusterName\": \"[concat(variables('resourcePrefix'), '-aks')]\", \"acrName\": \"[concat(replace(variables('resourcePrefix'), '-', ''), 'acr')]\" }, \"resources\": [ { \"type\": \"Microsoft.Storage/storageAccounts\", \"apiVersion\": \"2021-09-01\", \"name\": \"[variables('storageAccountName')]\", \"location\": \"[parameters('location')]\", \"sku\": { \"name\": \"Standard_LRS\" }, \"kind\": \"StorageV2\", \"properties\": { \"encryption\": { \"services\": { \"blob\": { \"enabled\": true }, \"file\": { \"enabled\": true } }, \"keySource\": \"Microsoft.Storage\" }, \"supportsHttpsTrafficOnly\": true }, \"tags\": { \"Environment\": \"[parameters('environment')]\", \"Project\": \"graphite\" } }, { \"type\": \"Microsoft.ContainerRegistry/registries\", \"apiVersion\": \"2021-09-01\", \"name\": \"[variables('acrName')]\", \"location\": \"[parameters('location')]\", \"sku\": { \"name\": \"Standard\" }, \"properties\": { \"adminUserEnabled\": false }, \"tags\": { \"Environment\": \"[parameters('environment')]\", \"Project\": \"graphite\" } }, { \"type\": \"Microsoft.ContainerService/managedClusters\", \"apiVersion\": \"2021-10-01\", \"name\": \"[variables('aksClusterName')]\", \"location\": \"[parameters('location')]\", \"identity\": { \"type\": \"SystemAssigned\" }, \"properties\": { \"kubernetesVersion\": \"1.27.3\", \"dnsPrefix\": \"[variables('resourcePrefix')]\", \"agentPoolProfiles\": [ { \"name\": \"general\", \"count\": 3, \"vmSize\": \"Standard_D4s_v3\", \"osDiskSizeGB\": 128, \"mode\": \"System\", \"type\": \"VirtualMachineScaleSets\", \"enableAutoScaling\": true, \"minCount\": 2, \"maxCount\": 10 }, { \"name\": \"compute\", \"count\": 1, \"vmSize\": \"Standard_F8s_v2\", \"osDiskSizeGB\": 128, \"mode\": \"User\", \"type\": \"VirtualMachineScaleSets\", \"enableAutoScaling\": true, \"minCount\": 0, \"maxCount\": 5, \"nodeLabels\": { \"workload\": \"compute-intensive\" }, \"nodeTaints\": [ \"compute-optimized=true:NoSchedule\" ] } ], \"servicePrincipalProfile\": { \"clientId\": \"msi\" }, \"networkProfile\": { \"networkPlugin\": \"azure\", \"loadBalancerSku\": \"standard\" } }, \"tags\": { \"Environment\": \"[parameters('environment')]\", \"Project\": \"graphite\" } } ], \"outputs\": { \"storageAccountName\": { \"type\": \"string\", \"value\": \"[variables('storageAccountName')]\" }, \"aksClusterName\": { \"type\": \"string\", \"value\": \"[variables('aksClusterName')]\" }, \"acrLoginServer\": { \"type\": \"string\", \"value\": \"[reference(variables('acrName')).loginServer]\" } } } ``` This completes sections 22-24. Would you like me to continue with the final sections 25-28?`, `old_string`: `This completes sections 20 and 21. Would you like me to continue with sections 22-28?` }``

Response

`{"filePath":"/Users/james/git/graphite/part-4.md","oldString":"This completes sections 20 and 21. Would you like me to continue with sections 22-28?","newString":"---\n\n## 22. Implementation Guidelines\n\nThis section provides comprehensive guidance for implementing GRAPHITE in production environments, covering architectural decisions, coding standards, and best practices.\n\n### 22.1 Architecture Guidelines\n\n#### 22.1.1 Modular Design Principles\n```c\n// Core module structure for GRAPHITE implementation\ntypedef struct graphite_module {\n const char* name;\n const char* version;\n const graphite_module_interface* interface;\n void* private_data;\n graphite_module_state state;\n} graphite_module;\n\n// Well-defined module interfaces\ntypedef struct {\n graphite_result (*init)(void** context, const graphite_config* config);\n graphite_result (*process)(void* context, const graphite_input* input, graphite_output* output);\n void (*cleanup)(void* context);\n graphite_result (*get_info)(void* context, graphite_module_info* info);\n} graphite_module_interface;\n\n// Example: Compression module implementation\nstatic const graphite_module_interface compression_interface = {\n .init = compression_init,\n .process = compression_process,\n .cleanup = compression_cleanup,\n .get_info = compression_get_info\n};\n\n// Module registry for dependency injection\ntypedef struct {\n hashtable* modules; // name -> module mapping\n dynamic_array* load_order; // Module initialization order\n graphite_config* global_config;\n} graphite_module_registry;\n\n// Register modules with clear dependencies\ngraphite_result graphite_register_module(\n graphite_module_registry* registry,\n const char* name,\n const graphite_module_interface* interface,\n const char** dependencies,\n size_t dependency_count\n) {\n // Validate dependencies exist\n for (size_t i = 0; i < dependency_count; i++) {\n if (!hashtable_contains(registry->modules, dependencies[i])) {\n return GRAPHITE_ERROR_MISSING_DEPENDENCY;\n }\n }\n \n // Create module instance\n graphite_module* module = malloc(sizeof(graphite_module));\n module->name = strdup(name);\n module->interface = interface;\n module->state = GRAPHITE_MODULE_REGISTERED;\n \n // Initialize module\n graphite_result result = interface->init(&module->private_data, registry->global_config);\n if (result != GRAPHITE_SUCCESS) {\n free(module);\n return result;\n }\n \n module->state = GRAPHITE_MODULE_INITIALIZED;\n hashtable_insert(registry->modules, name, module);\n \n return GRAPHITE_SUCCESS;\n}\n```\n\n#### 22.1.2 Error Handling Strategy\n```c\n// Comprehensive error handling system\ntypedef enum {\n GRAPHITE_ERROR_CATEGORY_SYSTEM, // OS/system level errors\n GRAPHITE_ERROR_CATEGORY_FORMAT, // File format errors\n GRAPHITE_ERROR_CATEGORY_MEMORY, // Memory allocation errors\n GRAPHITE_ERROR_CATEGORY_IO, // I/O operation errors\n GRAPHITE_ERROR_CATEGORY_SECURITY, // Security/validation errors\n GRAPHITE_ERROR_CATEGORY_CONFIG, // Configuration errors\n GRAPHITE_ERROR_CATEGORY_NETWORK, // Network operation errors\n GRAPHITE_ERROR_CATEGORY_USER // User input errors\n} graphite_error_category;\n\ntypedef struct {\n graphite_result code;\n graphite_error_category category;\n const char* message;\n const char* file;\n int line;\n const char* function;\n uint64_t timestamp;\n void* context_data;\n} graphite_error_info;\n\n// Error context for detailed debugging\ntypedef struct {\n graphite_error_info* error_stack;\n size_t stack_size;\n size_t stack_capacity;\n graphite_log_callback log_callback;\n void* log_user_data;\n} graphite_error_context;\n\n// Error reporting macros\n#define GRAPHITE_SET_ERROR(ctx, code, cat, msg) \\\n graphite_set_error_impl(ctx, code, cat, msg, __FILE__, __LINE__, __func__)\n\n#define GRAPHITE_PROPAGATE_ERROR(ctx, result) \\\n do { \\\n if (result != GRAPHITE_SUCCESS) { \\\n graphite_add_error_context(ctx, __FILE__, __LINE__, __func__); \\\n return result; \\\n } \\\n } while(0)\n\n// Error handling implementation\nvoid graphite_set_error_impl(\n graphite_error_context* ctx,\n graphite_result code,\n graphite_error_category category,\n const char* message,\n const char* file,\n int line,\n const char* function\n) {\n if (!ctx) return;\n \n // Ensure stack capacity\n if (ctx->stack_size >= ctx->stack_capacity) {\n size_t new_capacity = ctx->stack_capacity ? ctx->stack_capacity * 2 : 16;\n graphite_error_info* new_stack = realloc(ctx->error_stack, \n new_capacity * sizeof(graphite_error_info));\n if (!new_stack) return; // Can't report out of memory for error reporting\n \n ctx->error_stack = new_stack;\n ctx->stack_capacity = new_capacity;\n }\n \n // Add error to stack\n graphite_error_info* error = &ctx->error_stack[ctx->stack_size++];\n error->code = code;\n error->category = category;\n error->message = message;\n error->file = file;\n error->line = line;\n error->function = function;\n error->timestamp = graphite_get_time_ms();\n \n // Log error if callback provided\n if (ctx->log_callback) {\n ctx->log_callback(GRAPHITE_LOG_ERROR, message, ctx->log_user_data);\n }\n}\n\n// Resource cleanup with error handling\ntypedef struct {\n void (*cleanup_func)(void* resource);\n void* resource;\n const char* description;\n} graphite_cleanup_item;\n\ntypedef struct {\n graphite_cleanup_item* items;\n size_t count;\n size_t capacity;\n} graphite_cleanup_stack;\n\n#define GRAPHITE_DEFER_CLEANUP(stack, func, resource, desc) \\\n graphite_defer_cleanup(stack, (void(*)(void*))func, resource, desc)\n\nvoid graphite_defer_cleanup(\n graphite_cleanup_stack* stack,\n void (*cleanup_func)(void*),\n void* resource,\n const char* description\n) {\n if (stack->count >= stack->capacity) {\n size_t new_capacity = stack->capacity ? stack->capacity * 2 : 16;\n graphite_cleanup_item* new_items = realloc(stack->items,\n new_capacity * sizeof(graphite_cleanup_item));\n if (!new_items) return; // Silent failure in cleanup registration\n \n stack->items = new_items;\n stack->capacity = new_capacity;\n }\n \n graphite_cleanup_item* item = &stack->items[stack->count++];\n item->cleanup_func = cleanup_func;\n item->resource = resource;\n item->description = description;\n}\n\nvoid graphite_execute_cleanup(graphite_cleanup_stack* stack) {\n // Execute in reverse order (LIFO)\n for (int i = (int)stack->count - 1; i >= 0; i--) {\n graphite_cleanup_item* item = &stack->items[i];\n if (item->cleanup_func && item->resource) {\n item->cleanup_func(item->resource);\n }\n }\n stack->count = 0;\n}\n```\n\n### 22.2 Performance Implementation Guidelines\n\n#### 22.2.1 Memory Management Best Practices\n```c\n// Pool-based allocation for frequent small objects\ntypedef struct {\n void* memory_block;\n size_t block_size;\n size_t object_size;\n size_t object_count;\n uint32_t* free_bitmap; // Bitmap of free objects\n size_t next_free_hint; // Hint for next free object\n atomic_size_t allocated_count;\n} graphite_object_pool;\n\ngraphite_object_pool* graphite_pool_create(size_t object_size, size_t initial_count) {\n // Align object size to cache line boundary\n size_t aligned_size = (object_size + 63) & ~63;\n \n graphite_object_pool* pool = malloc(sizeof(graphite_object_pool));\n if (!pool) return NULL;\n \n pool->object_size = aligned_size;\n pool->object_count = initial_count;\n pool->block_size = aligned_size * initial_count;\n \n // Allocate aligned memory block\n pool->memory_block = graphite_aligned_alloc(pool->block_size, 64);\n if (!pool->memory_block) {\n free(pool);\n return NULL;\n }\n \n // Initialize free bitmap (all objects initially free)\n size_t bitmap_size = (initial_count + 31) / 32;\n pool->free_bitmap = calloc(bitmap_size, sizeof(uint32_t));\n if (!pool->free_bitmap) {\n graphite_aligned_free(pool->memory_block);\n free(pool);\n return NULL;\n }\n \n // Mark all objects as free\n for (size_t i = 0; i < initial_count; i++) {\n size_t word_idx = i / 32;\n size_t bit_idx = i % 32;\n pool->free_bitmap[word_idx] |= (1U << bit_idx);\n }\n \n pool->next_free_hint = 0;\n atomic_init(&pool->allocated_count, 0);\n \n return pool;\n}\n\nvoid* graphite_pool_alloc(graphite_object_pool* pool) {\n // Fast path: check hint first\n size_t start_idx = pool->next_free_hint;\n for (size_t i = 0; i < pool->object_count; i++) {\n size_t idx = (start_idx + i) % pool->object_count;\n size_t word_idx = idx / 32;\n size_t bit_idx = idx % 32;\n \n uint32_t mask = 1U << bit_idx;\n if (pool->free_bitmap[word_idx] & mask) {\n // Found free object, mark as allocated\n pool->free_bitmap[word_idx] &= ~mask;\n pool->next_free_hint = (idx + 1) % pool->object_count;\n \n atomic_fetch_add(&pool->allocated_count, 1);\n \n // Return aligned pointer\n return (uint8_t*)pool->memory_block + (idx * pool->object_size);\n }\n }\n \n return NULL; // Pool exhausted\n}\n\nvoid graphite_pool_free(graphite_object_pool* pool, void* ptr) {\n if (!ptr || ptr < pool->memory_block) return;\n \n // Calculate object index\n ptrdiff_t offset = (uint8_t*)ptr - (uint8_t*)pool->memory_block;\n if (offset % pool->object_size != 0) return; // Invalid pointer\n \n size_t idx = offset / pool->object_size;\n if (idx >= pool->object_count) return; // Out of bounds\n \n // Mark as free\n size_t word_idx = idx / 32;\n size_t bit_idx = idx % 32;\n uint32_t mask = 1U << bit_idx;\n \n if (!(pool->free_bitmap[word_idx] & mask)) {\n pool->free_bitmap[word_idx] |= mask;\n atomic_fetch_sub(&pool->allocated_count, 1);\n \n // Update hint for faster allocation\n if (idx < pool->next_free_hint) {\n pool->next_free_hint = idx;\n }\n }\n}\n\n// RAII-style resource management\n#define GRAPHITE_SCOPED_POOL_ALLOC(pool, type) \\\n __attribute__((cleanup(graphite_pool_free_cleanup))) \\\n type* ptr = (type*)graphite_pool_alloc(pool); \\\n if (!ptr) return GRAPHITE_ERROR_ALLOCATION\n\nstatic void graphite_pool_free_cleanup(void* ptr_to_ptr) {\n void** ptr = (void**)ptr_to_ptr;\n if (*ptr) {\n // Note: This requires pool context - in practice, use a wrapper\n // that stores pool reference with the allocation\n graphite_pool_free(current_pool, *ptr);\n }\n}\n```\n\n#### 22.2.2 Cache-Friendly Data Structures\n```c\n// Structure of Arrays (SoA) for better cache utilization\ntypedef struct {\n // Instead of Array of Structures (AoS):\n // struct { uint32_t id; float position[3]; uint32_t flags; } nodes[];\n \n // Use Structure of Arrays (SoA):\n uint32_t* ids; // Cache line aligned\n float* positions; // 3 floats per node, packed\n uint32_t* flags; // Cache line aligned\n \n size_t count;\n size_t capacity;\n \n // Memory layout optimized for common access patterns\n void* memory_block; // Single allocation for all arrays\n} graphite_node_array;\n\ngraphite_node_array* graphite_nodes_create(size_t initial_capacity) {\n graphite_node_array* nodes = malloc(sizeof(graphite_node_array));\n if (!nodes) return NULL;\n \n // Calculate memory layout with cache line alignment\n size_t ids_size = initial_capacity * sizeof(uint32_t);\n size_t positions_size = initial_capacity * 3 * sizeof(float);\n size_t flags_size = initial_capacity * sizeof(uint32_t);\n \n // Align each array to cache line boundary\n ids_size = (ids_size + 63) & ~63;\n positions_size = (positions_size + 63) & ~63;\n flags_size = (flags_size + 63) & ~63;\n \n size_t total_size = ids_size + positions_size + flags_size;\n \n nodes->memory_block = graphite_aligned_alloc(total_size, 64);\n if (!nodes->memory_block) {\n free(nodes);\n return NULL;\n }\n \n // Set up array pointers\n uint8_t* base = (uint8_t*)nodes->memory_block;\n nodes->ids = (uint32_t*)base;\n nodes->positions = (float*)(base + ids_size);\n nodes->flags = (uint32_t*)(base + ids_size + positions_size);\n \n nodes->count = 0;\n nodes->capacity = initial_capacity;\n \n return nodes;\n}\n\n// Cache-friendly iteration patterns\nvoid graphite_nodes_process_positions(graphite_node_array* nodes, \n graphite_matrix4 transform) {\n // Process in chunks that fit in cache\n const size_t chunk_size = 64; // Tune based on cache size\n \n for (size_t start = 0; start < nodes->count; start += chunk_size) {\n size_t end = start + chunk_size;\n if (end > nodes->count) end = nodes->count;\n \n // Prefetch next chunk\n if (end < nodes->count) {\n __builtin_prefetch(&nodes->positions[end * 3], 0, 3);\n }\n \n // Process current chunk\n for (size_t i = start; i < end; i++) {\n float* pos = &nodes->positions[i * 3];\n graphite_transform_point(transform, pos);\n }\n }\n}\n\n// Branch-friendly data organization\ntypedef struct {\n // Group related data to minimize branches\n struct {\n uint32_t visible_count;\n uint32_t* visible_indices;\n } visible;\n \n struct {\n uint32_t culled_count;\n uint32_t* culled_indices;\n } culled;\n \n struct {\n uint32_t dirty_count;\n uint32_t* dirty_indices;\n } dirty;\n} graphite_node_buckets;\n\n// Bucket sorting for cache-friendly processing\nvoid graphite_bucket_nodes_by_state(graphite_node_array* nodes, \n graphite_node_buckets* buckets) {\n buckets->visible.visible_count = 0;\n buckets->culled.culled_count = 0;\n buckets->dirty.dirty_count = 0;\n \n // Single pass bucketing\n for (size_t i = 0; i < nodes->count; i++) {\n uint32_t flags = nodes->flags[i];\n \n if (flags & GRAPHITE_NODE_VISIBLE) {\n buckets->visible.visible_indices[buckets->visible.visible_count++] = i;\n } else if (flags & GRAPHITE_NODE_CULLED) {\n buckets->culled.culled_indices[buckets->culled.culled_count++] = i;\n }\n \n if (flags & GRAPHITE_NODE_DIRTY) {\n buckets->dirty.dirty_indices[buckets->dirty.dirty_count++] = i;\n }\n }\n}\n```\n\n### 22.3 Threading and Concurrency Guidelines\n\n#### 22.3.1 Lock-Free Data Structures\n```c\n// Lock-free queue for work distribution\ntypedef struct {\n atomic_ptr head;\n atomic_ptr tail;\n atomic_size_t size;\n} graphite_lockfree_queue;\n\ntypedef struct graphite_queue_node {\n atomic_ptr next;\n void* data;\n} graphite_queue_node;\n\ngraphite_lockfree_queue* graphite_queue_create(void) {\n graphite_lockfree_queue* queue = malloc(sizeof(graphite_lockfree_queue));\n if (!queue) return NULL;\n \n // Create dummy node\n graphite_queue_node* dummy = malloc(sizeof(graphite_queue_node));\n if (!dummy) {\n free(queue);\n return NULL;\n }\n \n atomic_init(&dummy->next, NULL);\n dummy->data = NULL;\n \n atomic_init(&queue->head, dummy);\n atomic_init(&queue->tail, dummy);\n atomic_init(&queue->size, 0);\n \n return queue;\n}\n\nbool graphite_queue_enqueue(graphite_lockfree_queue* queue, void* data) {\n graphite_queue_node* node = malloc(sizeof(graphite_queue_node));\n if (!node) return false;\n \n atomic_init(&node->next, NULL);\n node->data = data;\n \n graphite_queue_node* tail;\n \n while (true) {\n tail = atomic_load(&queue->tail);\n graphite_queue_node* next = atomic_load(&tail->next);\n \n if (tail == atomic_load(&queue->tail)) { // Tail hasn't changed\n if (next == NULL) {\n // Try to link node at the end of the list\n if (atomic_compare_exchange_weak(&tail->next, &next, node)) {\n break; // Successfully enqueued\n }\n } else {\n // Try to swing tail to the next node\n atomic_compare_exchange_weak(&queue->tail, &tail, next);\n }\n }\n }\n \n // Try to swing tail to the inserted node\n atomic_compare_exchange_weak(&queue->tail, &tail, node);\n atomic_fetch_add(&queue->size, 1);\n \n return true;\n}\n\nbool graphite_queue_dequeue(graphite_lockfree_queue* queue, void** data) {\n graphite_queue_node* head;\n graphite_queue_node* tail;\n graphite_queue_node* next;\n \n while (true) {\n head = atomic_load(&queue->head);\n tail = atomic_load(&queue->tail);\n next = atomic_load(&head->next);\n \n if (head == atomic_load(&queue->head)) { // Head hasn't changed\n if (head == tail) {\n if (next == NULL) {\n return false; // Queue is empty\n }\n // Try to swing tail to the next node\n atomic_compare_exchange_weak(&queue->tail, &tail, next);\n } else {\n if (next == NULL) {\n continue; // Another thread is modifying the queue\n }\n \n // Read data before CAS\n *data = next->data;\n \n // Try to swing head to the next node\n if (atomic_compare_exchange_weak(&queue->head, &head, next)) {\n atomic_fetch_sub(&queue->size, 1);\n free(head);\n return true;\n }\n }\n }\n }\n}\n\n// Work-stealing thread pool\ntypedef struct {\n graphite_lockfree_queue* global_queue;\n graphite_lockfree_queue** worker_queues;\n pthread_t* threads;\n atomic_bool shutdown;\n uint32_t thread_count;\n uint32_t current_thread_id; // Thread-local\n} graphite_thread_pool;\n\ntypedef struct {\n void (*function)(void* arg);\n void* argument;\n atomic_int* completion_counter; // For synchronization\n} graphite_work_item;\n\nstatic __thread uint32_t tls_thread_id = UINT32_MAX;\n\nvoid* graphite_worker_thread(void* arg) {\n graphite_thread_pool* pool = (graphite_thread_pool*)arg;\n uint32_t thread_id = atomic_fetch_add(&pool->current_thread_id, 1);\n tls_thread_id = thread_id;\n \n graphite_lockfree_queue* my_queue = pool->worker_queues[thread_id];\n \n while (!atomic_load(&pool->shutdown)) {\n graphite_work_item* work = NULL;\n \n // Try to get work from own queue first\n if (graphite_queue_dequeue(my_queue, (void**)&work)) {\n work->function(work->argument);\n if (work->completion_counter) {\n atomic_fetch_sub(work->completion_counter, 1);\n }\n free(work);\n continue;\n }\n \n // Try to steal work from other threads\n for (uint32_t i = 0; i < pool->thread_count; i++) {\n if (i == thread_id) continue;\n \n if (graphite_queue_dequeue(pool->worker_queues[i], (void**)&work)) {\n work->function(work->argument);\n if (work->completion_counter) {\n atomic_fetch_sub(work->completion_counter, 1);\n }\n free(work);\n goto continue_work;\n }\n }\n \n // Try global queue\n if (graphite_queue_dequeue(pool->global_queue, (void**)&work)) {\n work->function(work->argument);\n if (work->completion_counter) {\n atomic_fetch_sub(work->completion_counter, 1);\n }\n free(work);\n continue;\n }\n \n continue_work:\n // No work available, yield CPU\n sched_yield();\n }\n \n return NULL;\n}\n\n// Submit work to thread pool\nvoid graphite_pool_submit(graphite_thread_pool* pool, \n void (*function)(void*),\n void* argument,\n atomic_int* completion_counter) {\n graphite_work_item* work = malloc(sizeof(graphite_work_item));\n work->function = function;\n work->argument = argument;\n work->completion_counter = completion_counter;\n \n if (completion_counter) {\n atomic_fetch_add(completion_counter, 1);\n }\n \n // If called from worker thread, use local queue\n if (tls_thread_id < pool->thread_count) {\n graphite_queue_enqueue(pool->worker_queues[tls_thread_id], work);\n } else {\n // Use global queue for external submissions\n graphite_queue_enqueue(pool->global_queue, work);\n }\n}\n```\n\n---\n\n## 23. Quality Assurance & Testing Framework\n\nComprehensive testing strategy covering unit tests, integration tests, performance tests, and security validation.\n\n### 23.1 Testing Pyramid\n\n#### 23.1.1 Unit Testing Framework\n```c\n// Lightweight unit testing framework for GRAPHITE\ntypedef enum {\n GRAPHITE_TEST_PASS,\n GRAPHITE_TEST_FAIL,\n GRAPHITE_TEST_SKIP\n} graphite_test_result;\n\ntypedef struct {\n const char* name;\n const char* suite;\n graphite_test_result (*test_func)(void);\n uint64_t execution_time_ns;\n const char* failure_message;\n} graphite_test_case;\n\ntypedef struct {\n graphite_test_case* tests;\n size_t test_count;\n size_t capacity;\n \n // Statistics\n size_t passed;\n size_t failed;\n size_t skipped;\n uint64_t total_time_ns;\n} graphite_test_suite;\n\n// Test assertion macros\n#define GRAPHITE_ASSERT_EQ(expected, actual) \\\n do { \\\n if ((expected) != (actual)) { \\\n printf(\"ASSERTION FAILED: %s:%d\\n\", __FILE__, __LINE__); \\\n printf(\" Expected: %lld\\n\", (long long)(expected)); \\\n printf(\" Actual: %lld\\n\", (long long)(actual)); \\\n return GRAPHITE_TEST_FAIL; \\\n } \\\n } while(0)\n\n#define GRAPHITE_ASSERT_STR_EQ(expected, actual) \\\n do { \\\n if (strcmp((expected), (actual)) != 0) { \\\n printf(\"ASSERTION FAILED: %s:%d\\n\", __FILE__, __LINE__); \\\n printf(\" Expected: \\\"%s\\\"\\n\", (expected)); \\\n printf(\" Actual: \\\"%s\\\"\\n\", (actual)); \\\n return GRAPHITE_TEST_FAIL; \\\n } \\\n } while(0)\n\n#define GRAPHITE_ASSERT_NOT_NULL(ptr) \\\n do { \\\n if ((ptr) == NULL) { \\\n printf(\"ASSERTION FAILED: %s:%d\\n\", __FILE__, __LINE__); \\\n printf(\" Expected non-NULL pointer\\n\"); \\\n return GRAPHITE_TEST_FAIL; \\\n } \\\n } while(0)\n\n#define GRAPHITE_ASSERT_NULL(ptr) \\\n do { \\\n if ((ptr) != NULL) { \\\n printf(\"ASSERTION FAILED: %s:%d\\n\", __FILE__, __LINE__); \\\n printf(\" Expected NULL pointer\\n\"); \\\n return GRAPHITE_TEST_FAIL; \\\n } \\\n } while(0)\n\n// Test fixture support\ntypedef struct {\n void (*setup)(void);\n void (*teardown)(void);\n void* fixture_data;\n} graphite_test_fixture;\n\n// Example unit tests\ngraphite_test_result test_bundle_creation(void) {\n // Test basic bundle creation\n graphite_bundle_builder* builder = graphite_builder_create();\n GRAPHITE_ASSERT_NOT_NULL(builder);\n \n // Add some test data\n const char* test_string = \"Hello, GRAPHITE!\";\n uint32_t string_id = graphite_builder_add_string(builder, test_string);\n GRAPHITE_ASSERT_EQ(0, string_id); // First string should have ID 0\n \n // Create bundle\n graphite_bundle* bundle = graphite_builder_finalize(builder);\n GRAPHITE_ASSERT_NOT_NULL(bundle);\n \n // Verify string retrieval\n const char* retrieved = graphite_get_string(bundle, string_id);\n GRAPHITE_ASSERT_STR_EQ(test_string, retrieved);\n \n // Cleanup\n graphite_close(bundle);\n graphite_builder_destroy(builder);\n \n return GRAPHITE_TEST_PASS;\n}\n\ngraphite_test_result test_graph_traversal(void) {\n // Create a simple graph: A -> B -> C\n graphite_bundle_builder* builder = graphite_builder_create();\n \n // Create nodes\n graphite_node_id node_a = graphite_builder_create_node(builder);\n graphite_node_id node_b = graphite_builder_create_node(builder);\n graphite_node_id node_c = graphite_builder_create_node(builder);\n \n // Create edges\n graphite_builder_add_edge(builder, node_a, node_b, GRAPHITE_EDGE_REFERENCE);\n graphite_builder_add_edge(builder, node_b, node_c, GRAPHITE_EDGE_REFERENCE);\n \n // Finalize bundle\n graphite_bundle* bundle = graphite_builder_finalize(builder);\n GRAPHITE_ASSERT_NOT_NULL(bundle);\n \n // Test traversal\n const graphite_graph* root = graphite_root(bundle);\n GRAPHITE_ASSERT_NOT_NULL(root);\n \n // Verify graph structure\n GRAPHITE_ASSERT_EQ(3, root->header.node_cnt);\n GRAPHITE_ASSERT_EQ(2, root->header.edge_cnt);\n \n // Test edge traversal\n const graphite_graph* node_a_graph = graphite_get_child_graph(root, 0);\n GRAPHITE_ASSERT_NOT_NULL(node_a_graph);\n \n // Cleanup\n graphite_close(bundle);\n graphite_builder_destroy(builder);\n \n return GRAPHITE_TEST_PASS;\n}\n\n// Property-based testing support\ntypedef struct {\n void* (*generate)(size_t seed);\n void (*free_data)(void* data);\n bool (*property)(void* data);\n const char* description;\n} graphite_property_test;\n\nbool property_bundle_roundtrip(void* data) {\n graphite_test_data* test = (graphite_test_data*)data;\n \n // Create bundle with random data\n graphite_bundle_builder* builder = graphite_builder_create();\n \n for (size_t i = 0; i < test->string_count; i++) {\n graphite_builder_add_string(builder, test->strings[i]);\n }\n \n for (size_t i = 0; i < test->blob_count; i++) {\n graphite_builder_add_blob(builder, test->blobs[i].data, test->blobs[i].size);\n }\n \n graphite_bundle* bundle = graphite_builder_finalize(builder);\n if (!bundle) return false;\n \n // Verify all data can be retrieved correctly\n for (size_t i = 0; i < test->string_count; i++) {\n const char* retrieved = graphite_get_string(bundle, i);\n if (strcmp(test->strings[i], retrieved) != 0) {\n graphite_close(bundle);\n graphite_builder_destroy(builder);\n return false;\n }\n }\n \n for (size_t i = 0; i < test->blob_count; i++) {\n size_t size;\n const void* retrieved = graphite_get_blob(bundle, i, &size);\n if (size != test->blobs[i].size || \n memcmp(retrieved, test->blobs[i].data, size) != 0) {\n graphite_close(bundle);\n graphite_builder_destroy(builder);\n return false;\n }\n }\n \n graphite_close(bundle);\n graphite_builder_destroy(builder);\n return true;\n}\n\n// Fuzz testing integration\ntypedef struct {\n uint8_t* data;\n size_t size;\n uint32_t seed;\n} graphite_fuzz_input;\n\nvoid graphite_fuzz_bundle_parser(const graphite_fuzz_input* input) {\n // Parse bundle with fuzzing input\n graphite_bundle* bundle = graphite_open_from_memory(input->data, input->size);\n \n if (bundle) {\n // If parsing succeeded, try to access data safely\n const graphite_graph* root = graphite_root(bundle);\n if (root) {\n // Traverse graph carefully\n for (uint32_t i = 0; i < root->header.node_cnt && i < 1000; i++) {\n const graphite_graph* child = graphite_get_child_graph(root, i);\n if (child) {\n // Access some data\n volatile uint32_t dummy = child->header.node_cnt;\n (void)dummy;\n }\n }\n }\n \n graphite_close(bundle);\n }\n}\n\n// Test runner\nvoid graphite_run_tests(void) {\n graphite_test_suite suite = {0};\n \n // Register tests\n graphite_test_case tests[] = {\n {\"Bundle Creation\", \"Core\", test_bundle_creation, 0, NULL},\n {\"Graph Traversal\", \"Core\", test_graph_traversal, 0, NULL},\n // Add more tests...\n };\n \n suite.tests = tests;\n suite.test_count = sizeof(tests) / sizeof(tests[0]);\n \n printf(\"Running GRAPHITE test suite...\\n\");\n printf(\"================================\\n\");\n \n for (size_t i = 0; i < suite.test_count; i++) {\n graphite_test_case* test = &suite.tests[i];\n \n printf(\"Running %s::%s... \", test->suite, test->name);\n fflush(stdout);\n \n uint64_t start_time = graphite_get_precise_time_ns();\n graphite_test_result result = test->test_func();\n uint64_t end_time = graphite_get_precise_time_ns();\n \n test->execution_time_ns = end_time - start_time;\n \n switch (result) {\n case GRAPHITE_TEST_PASS:\n printf(\"PASS (%.2f ms)\\n\", test->execution_time_ns / 1e6);\n suite.passed++;\n break;\n case GRAPHITE_TEST_FAIL:\n printf(\"FAIL (%.2f ms)\\n\", test->execution_time_ns / 1e6);\n suite.failed++;\n break;\n case GRAPHITE_TEST_SKIP:\n printf(\"SKIP\\n\");\n suite.skipped++;\n break;\n }\n \n suite.total_time_ns += test->execution_time_ns;\n }\n \n printf(\"\\n\");\n printf(\"Results: %zu passed, %zu failed, %zu skipped\\n\",\n suite.passed, suite.failed, suite.skipped);\n printf(\"Total time: %.2f ms\\n\", suite.total_time_ns / 1e6);\n \n if (suite.failed > 0) {\n printf(\"TESTS FAILED!\\n\");\n exit(1);\n } else {\n printf(\"All tests passed!\\n\");\n }\n}\n```\n\n### 23.2 Integration Testing\n\n#### 23.2.1 End-to-End Pipeline Tests\n```c\n// Integration test framework\ntypedef struct {\n const char* temp_directory;\n char** created_files;\n size_t file_count;\n graphite_test_fixture fixture;\n} graphite_integration_context;\n\n// Test full asset pipeline\ngraphite_test_result test_asset_pipeline_integration(void) {\n graphite_integration_context ctx = {0};\n ctx.temp_directory = \"/tmp/graphite_test_XXXXXX\";\n \n // Create temporary directory\n char* temp_dir = mkdtemp((char*)ctx.temp_directory);\n GRAPHITE_ASSERT_NOT_NULL(temp_dir);\n \n // Create test assets\n char texture_path[256];\n snprintf(texture_path, sizeof(texture_path), \"%s/test_texture.png\", temp_dir);\n \n // Generate test PNG file\n graphite_result result = graphite_create_test_png(texture_path, 256, 256);\n GRAPHITE_ASSERT_EQ(GRAPHITE_SUCCESS, result);\n \n char mesh_path[256];\n snprintf(mesh_path, sizeof(mesh_path), \"%s/test_mesh.gltf\", temp_dir);\n \n // Generate test GLTF file\n result = graphite_create_test_gltf(mesh_path, texture_path);\n GRAPHITE_ASSERT_EQ(GRAPHITE_SUCCESS, result);\n \n // Create transform configuration\n char config_path[256];\n snprintf(config_path, sizeof(config_path), \"%s/transform_config.json\", temp_dir);\n \n const char* config_json = \n \"{\\n\"\n \" \\\"transforms\\\": [\\n\"\n \" {\\n\"\n \" \\\"name\\\": \\\"texture_compress\\\",\\n\"\n \" \\\"input_patterns\\\": [\\\"*.png\\\"],\\n\"\n \" \\\"output_format\\\": \\\"bc7\\\",\\n\"\n \" \\\"parameters\\\": {\\\"quality\\\": \\\"high\\\"}\\n\"\n \" },\\n\"\n \" {\\n\"\n \" \\\"name\\\": \\\"mesh_optimize\\\",\\n\"\n \" \\\"input_patterns\\\": [\\\"*.gltf\\\"],\\n\"\n \" \\\"output_format\\\": \\\"optimized_mesh\\\"\\n\"\n \" }\\n\"\n \" ]\\n\"\n \"}\\n\";\n \n FILE* config_file = fopen(config_path, \"w\");\n GRAPHITE_ASSERT_NOT_NULL(config_file);\n fwrite(config_json, 1, strlen(config_json), config_file);\n fclose(config_file);\n \n // Run asset pipeline\n char bundle_path[256];\n snprintf(bundle_path, sizeof(bundle_path), \"%s/output.graphite\", temp_dir);\n \n char command[1024];\n snprintf(command, sizeof(command),\n \"graphite pack --config %s --output %s %s\",\n config_path, bundle_path, temp_dir);\n \n int exit_code = system(command);\n GRAPHITE_ASSERT_EQ(0, exit_code);\n \n // Verify bundle was created\n FILE* bundle_file = fopen(bundle_path, \"rb\");\n GRAPHITE_ASSERT_NOT_NULL(bundle_file);\n fclose(bundle_file);\n \n // Load and verify bundle\n graphite_bundle* bundle = graphite_open(bundle_path);\n GRAPHITE_ASSERT_NOT_NULL(bundle);\n \n const graphite_graph* root = graphite_root(bundle);\n GRAPHITE_ASSERT_NOT_NULL(root);\n GRAPHITE_ASSERT_EQ(true, root->header.node_cnt > 0);\n \n // Verify integrity\n bool integrity_ok = graphite_verify_integrity(bundle);\n GRAPHITE_ASSERT_EQ(true, integrity_ok);\n \n // Cleanup\n graphite_close(bundle);\n \n // Remove temporary files\n char rm_command[512];\n snprintf(rm_command, sizeof(rm_command), \"rm -rf %s\", temp_dir);\n system(rm_command);\n \n return GRAPHITE_TEST_PASS;\n}\n\n// Multi-platform testing\ntypedef struct {\n const char* platform_name;\n const char* compiler;\n const char* flags;\n const char* test_command;\n} graphite_platform_config;\n\nstatic const graphite_platform_config test_platforms[] = {\n {\"Linux x86_64\", \"gcc\", \"-O3 -DNDEBUG\", \"./test_suite\"},\n {\"Linux x86_64 Debug\", \"gcc\", \"-O0 -g -fsanitize=address\", \"./test_suite\"},\n {\"Linux ARM64\", \"aarch64-linux-gnu-gcc\", \"-O3 -DNDEBUG\", \"qemu-aarch64 ./test_suite\"},\n {\"Windows x64\", \"x86_64-w64-mingw32-gcc\", \"-O3 -DNDEBUG\", \"wine ./test_suite.exe\"},\n {\"macOS x64\", \"clang\", \"-O3 -DNDEBUG -target x86_64-apple-macos10.12\", \"./test_suite\"}\n};\n\nvoid graphite_run_cross_platform_tests(void) {\n size_t platform_count = sizeof(test_platforms) / sizeof(test_platforms[0]);\n \n for (size_t i = 0; i < platform_count; i++) {\n const graphite_platform_config* platform = &test_platforms[i];\n \n printf(\"Testing on %s...\\n\", platform->platform_name);\n \n // Build for platform\n char build_command[1024];\n snprintf(build_command, sizeof(build_command),\n \"make clean && CC=%s CFLAGS='%s' make test_suite\",\n platform->compiler, platform->flags);\n \n int build_result = system(build_command);\n if (build_result != 0) {\n printf(\" Build FAILED\\n\");\n continue;\n }\n \n // Run tests\n int test_result = system(platform->test_command);\n if (test_result == 0) {\n printf(\" Tests PASSED\\n\");\n } else {\n printf(\" Tests FAILED (exit code: %d)\\n\", test_result);\n }\n }\n}\n```\n\n### 23.3 Performance Testing\n\n#### 23.3.1 Automated Performance Validation\n```c\n// Performance test framework\ntypedef struct {\n const char* test_name;\n void (*setup)(void** context);\n void (*benchmark)(void* context, graphite_benchmark_result* result);\n void (*teardown)(void* context);\n \n // Performance thresholds\n uint64_t max_time_ns;\n size_t max_memory_bytes;\n double min_throughput_mbps;\n} graphite_performance_test;\n\n// Regression detection\ntypedef struct {\n graphite_benchmark_result baseline;\n graphite_benchmark_result current;\n double regression_threshold; // Percentage\n} graphite_regression_analysis;\n\nbool graphite_detect_regression(const graphite_regression_analysis* analysis) {\n // Check time regression\n if (analysis->baseline.mean_time_ns > 0) {\n double time_regression = \n ((double)analysis->current.mean_time_ns - analysis->baseline.mean_time_ns) / \n analysis->baseline.mean_time_ns * 100.0;\n \n if (time_regression > analysis->regression_threshold) {\n printf(\"REGRESSION: Time increased by %.1f%%\\n\", time_regression);\n return true;\n }\n }\n \n // Check memory regression\n if (analysis->baseline.max_memory_bytes > 0) {\n double memory_regression = \n ((double)analysis->current.max_memory_bytes - analysis->baseline.max_memory_bytes) / \n analysis->baseline.max_memory_bytes * 100.0;\n \n if (memory_regression > analysis->regression_threshold) {\n printf(\"REGRESSION: Memory usage increased by %.1f%%\\n\", memory_regression);\n return true;\n }\n }\n \n return false;\n}\n\n// Performance test implementation\nvoid setup_large_bundle_test(void** context) {\n // Create large test bundle\n *context = graphite_create_large_test_bundle(1000000); // 1M nodes\n}\n\nvoid benchmark_large_bundle_open(void* context, graphite_benchmark_result* result) {\n graphite_bundle* test_bundle = (graphite_bundle*)context;\n \n // Benchmark bundle opening\n const int iterations = 100;\n uint64_t* times = malloc(sizeof(uint64_t) * iterations);\n \n for (int i = 0; i < iterations; i++) {\n uint64_t start = graphite_get_precise_time_ns();\n \n graphite_bundle* bundle = graphite_open(\"large_test.graphite\");\n \n uint64_t end = graphite_get_precise_time_ns();\n times[i] = end - start;\n \n if (bundle) {\n graphite_close(bundle);\n }\n }\n \n // Calculate statistics\n qsort(times, iterations, sizeof(uint64_t), compare_uint64);\n result->min_time_ns = times[0];\n result->max_time_ns = times[iterations - 1];\n result->median_time_ns = times[iterations / 2];\n result->p95_time_ns = times[(iterations * 95) / 100];\n result->p99_time_ns = times[(iterations * 99) / 100];\n \n uint64_t sum = 0;\n for (int i = 0; i < iterations; i++) {\n sum += times[i];\n }\n result->mean_time_ns = sum / iterations;\n \n free(times);\n}\n\nvoid teardown_large_bundle_test(void* context) {\n graphite_bundle* test_bundle = (graphite_bundle*)context;\n if (test_bundle) {\n graphite_close(test_bundle);\n }\n unlink(\"large_test.graphite\");\n}\n\n// Stress testing\nvoid graphite_stress_test_concurrent_access(void) {\n const char* bundle_path = \"stress_test.graphite\";\n const int thread_count = 32;\n const int iterations_per_thread = 10000;\n \n // Create test bundle\n graphite_create_test_bundle(bundle_path, 10000); // 10K nodes\n \n // Shared state\n atomic_int successful_operations = ATOMIC_VAR_INIT(0);\n atomic_int failed_operations = ATOMIC_VAR_INIT(0);\n \n // Thread function\n auto stress_worker = [](void* arg) -> void* {\n const char* path = (const char*)arg;\n \n for (int i = 0; i < iterations_per_thread; i++) {\n graphite_bundle* bundle = graphite_open(path);\n if (bundle) {\n // Perform random operations\n const graphite_graph* root = graphite_root(bundle);\n if (root && root->header.node_cnt > 0) {\n uint32_t random_node = rand() % root->header.node_cnt;\n const graphite_graph* node = graphite_get_child_graph(root, random_node);\n if (node) {\n atomic_fetch_add(&successful_operations, 1);\n } else {\n atomic_fetch_add(&failed_operations, 1);\n }\n } else {\n atomic_fetch_add(&failed_operations, 1);\n }\n graphite_close(bundle);\n } else {\n atomic_fetch_add(&failed_operations, 1);\n }\n }\n \n return NULL;\n };\n \n // Create threads\n pthread_t* threads = malloc(sizeof(pthread_t) * thread_count);\n \n uint64_t start_time = graphite_get_precise_time_ns();\n \n for (int i = 0; i < thread_count; i++) {\n pthread_create(&threads[i], NULL, stress_worker, (void*)bundle_path);\n }\n \n // Wait for completion\n for (int i = 0; i < thread_count; i++) {\n pthread_join(threads[i], NULL);\n }\n \n uint64_t end_time = graphite_get_precise_time_ns();\n \n // Report results\n int successful = atomic_load(&successful_operations);\n int failed = atomic_load(&failed_operations);\n double duration_seconds = (end_time - start_time) / 1e9;\n double ops_per_second = (successful + failed) / duration_seconds;\n \n printf(\"Stress Test Results:\\n\");\n printf(\" Threads: %d\\n\", thread_count);\n printf(\" Total operations: %d\\n\", successful + failed);\n printf(\" Successful: %d (%.1f%%)\\n\", successful, \n 100.0 * successful / (successful + failed));\n printf(\" Failed: %d (%.1f%%)\\n\", failed,\n 100.0 * failed / (successful + failed));\n printf(\" Duration: %.2f seconds\\n\", duration_seconds);\n printf(\" Throughput: %.0f ops/sec\\n\", ops_per_second);\n \n free(threads);\n unlink(bundle_path);\n \n // Fail test if too many operations failed\n if (failed > (successful + failed) * 0.01) { // More than 1% failure rate\n printf(\"STRESS TEST FAILED: Too many failed operations\\n\");\n exit(1);\n }\n}\n```\n\n---\n\n## 24. Deployment & Distribution\n\nComprehensive deployment strategies for GRAPHITE across different environments and distribution channels.\n\n### 24.1 Package Management Integration\n\n#### 24.1.1 Homebrew Formula\n```ruby\n# Formula/graphite.rb\nclass Graphite < Formula\n desc \"High-performance binary graph format for asset management\"\n homepage \"https://github.com/graphite-format/graphite\"\n url \"https://github.com/graphite-format/graphite/archive/v3.0.0.tar.gz\"\n sha256 \"abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890\"\n license \"MIT\"\n \n depends_on \"cmake\" => :build\n depends_on \"zstd\"\n depends_on \"blake3\"\n depends_on \"libsodium\"\n \n def install\n # Build with optimizations\n system \"cmake\", \"-S\", \".\", \"-B\", \"build\",\n \"-DCMAKE_BUILD_TYPE=Release\",\n \"-DGRAPHITE_BUILD_TOOLS=ON\",\n \"-DGRAPHITE_BUILD_TESTS=OFF\",\n \"-DGRAPHITE_ENABLE_SIMD=ON\",\n *std_cmake_args\n system \"cmake\", \"--build\", \"build\"\n system \"cmake\", \"--install\", \"build\"\n \n # Install additional tools\n bin.install \"build/tools/graphite-pack\"\n bin.install \"build/tools/graphite-info\"\n bin.install \"build/tools/graphite-verify\"\n \n # Install headers and libraries\n lib.install \"build/lib/libgraphite.a\"\n lib.install \"build/lib/libgraphite.dylib\" if OS.mac?\n lib.install \"build/lib/libgraphite.so\" if OS.linux?\n \n include.install Dir[\"include/graphite/*.h\"]\n \n # Install CMake configuration\n (lib/\"cmake/graphite\").install Dir[\"cmake/*.cmake\"]\n end\n\n test do\n # Create a simple test bundle\n (testpath/\"test.json\").write <<~EOS\n {\n \"assets\": [\n {\n \"name\": \"test_asset\",\n \"type\": \"generic\",\n \"data\": \"SGVsbG8gV29ybGQ=\"\n }\n ]\n }\n EOS\n \n # Test bundle creation\n system bin/\"graphite-pack\", \"--input\", \"test.json\", \"--output\", \"test.graphite\"\n assert_predicate testpath/\"test.graphite\", :exist?\n \n # Test bundle verification\n system bin/\"graphite-verify\", \"test.graphite\"\n \n # Test bundle info\n system bin/\"graphite-info\", \"test.graphite\"\n end\nend\n```\n\n#### 24.1.2 vcpkg Port\n```cmake\n# ports/graphite/portfile.cmake\nvcpkg_from_github(\n OUT_SOURCE_PATH SOURCE_PATH\n REPO graphite-format/graphite\n REF v3.0.0\n SHA512 abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890\n HEAD_REF main\n)\n\nvcpkg_check_features(OUT_FEATURE_OPTIONS FEATURE_OPTIONS\n FEATURES\n tools GRAPHITE_BUILD_TOOLS\n tests GRAPHITE_BUILD_TESTS\n simd GRAPHITE_ENABLE_SIMD\n encryption GRAPHITE_ENABLE_ENCRYPTION\n)\n\nvcpkg_cmake_configure(\n SOURCE_PATH \"${SOURCE_PATH}\"\n OPTIONS\n ${FEATURE_OPTIONS}\n -DGRAPHITE_BUILD_SHARED_LIBS=ON\n -DGRAPHITE_INSTALL_CMAKE_CONFIG=ON\n)\n\nvcpkg_cmake_build()\n\nif(\"tests\" IN_LIST FEATURES)\n vcpkg_cmake_config_fixup(CONFIG_PATH lib/cmake/graphite-tests)\nendif()\n\nvcpkg_cmake_config_fixup(CONFIG_PATH lib/cmake/graphite)\n\nif(\"tools\" IN_LIST FEATURES)\n vcpkg_copy_tools(\n TOOL_NAMES\n graphite-pack\n graphite-info \n graphite-verify\n graphite-benchmark\n AUTO_CLEAN\n )\nendif()\n\nfile(REMOVE_RECURSE \"${CURRENT_PACKAGES_DIR}/debug/include\")\nfile(REMOVE_RECURSE \"${CURRENT_PACKAGES_DIR}/debug/share\")\n\nfile(INSTALL \"${SOURCE_PATH}/LICENSE\" DESTINATION \"${CURRENT_PACKAGES_DIR}/share/${PORT}\" RENAME copyright)\n```\n\n### 24.2 Container Deployment\n\n#### 24.2.1 Docker Images\n```dockerfile\n# Dockerfile.alpine - Minimal production image\nFROM alpine:3.18 AS builder\n\n# Install build dependencies\nRUN apk add --no-cache \\\n build-base \\\n cmake \\\n git \\\n zstd-dev \\\n libsodium-dev\n\n# Copy source code\nCOPY . /src\nWORKDIR /src\n\n# Build GRAPHITE\nRUN cmake -S . -B build \\\n -DCMAKE_BUILD_TYPE=Release \\\n -DGRAPHITE_BUILD_TOOLS=ON \\\n -DGRAPHITE_BUILD_TESTS=OFF \\\n -DGRAPHITE_STATIC_LINKING=ON && \\\n cmake --build build --parallel $(nproc) && \\\n cmake --install build --prefix /usr/local\n\n# Production stage\nFROM alpine:3.18\n\n# Install runtime dependencies\nRUN apk add --no-cache \\\n zstd \\\n libsodium\n\n# Copy built binaries\nCOPY --from=builder /usr/local/bin/graphite* /usr/local/bin/\nCOPY --from=builder /usr/local/lib/libgraphite* /usr/local/lib/\nCOPY --from=builder /usr/local/include/graphite /usr/local/include/graphite\n\n# Create working directory\nWORKDIR /data\n\n# Default command\nENTRYPOINT [\"graphite\"]\nCMD [\"--help\"]\n\n# Labels\nLABEL org.opencontainers.image.title=\"GRAPHITE\"\nLABEL org.opencontainers.image.description=\"High-performance binary graph format\"\nLABEL org.opencontainers.image.version=\"3.0.0\"\nLABEL org.opencontainers.image.source=\"https://github.com/graphite-format/graphite\"\n```\n\n```dockerfile\n# Dockerfile.ubuntu - Development image with debugging tools\nFROM ubuntu:22.04\n\n# Install dependencies\nRUN apt-get update && apt-get install -y \\\n build-essential \\\n cmake \\\n git \\\n libzstd-dev \\\n libsodium-dev \\\n valgrind \\\n gdb \\\n perf-tools-unstable \\\n strace \\\n && rm -rf /var/lib/apt/lists/*\n\n# Copy source and build\nCOPY . /src\nWORKDIR /src\n\nRUN cmake -S . -B build \\\n -DCMAKE_BUILD_TYPE=Debug \\\n -DGRAPHITE_BUILD_TOOLS=ON \\\n -DGRAPHITE_BUILD_TESTS=ON \\\n -DGRAPHITE_ENABLE_SANITIZERS=ON && \\\n cmake --build build --parallel $(nproc) && \\\n cmake --install build\n\n# Install debugging symbols\nRUN mkdir -p /usr/lib/debug/usr/local/bin && \\\n cp build/tools/*.debug /usr/lib/debug/usr/local/bin/ 2>/dev/null || true\n\nWORKDIR /data\nENTRYPOINT [\"graphite\"]\n```\n\n#### 24.2.2 Kubernetes Deployment\n```yaml\n# k8s/namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n name: graphite-system\n labels:\n name: graphite-system\n\n---\n# k8s/configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n name: graphite-config\n namespace: graphite-system\ndata:\n config.json: |\n {\n \"compression\": {\n \"algorithm\": \"zstd\",\n \"level\": 9\n },\n \"security\": {\n \"require_signature\": true,\n \"max_bundle_size_mb\": 1024\n },\n \"performance\": {\n \"worker_threads\": 4,\n \"memory_pool_size_mb\": 256\n }\n }\n\n---\n# k8s/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: graphite-processor\n namespace: graphite-system\nspec:\n replicas: 3\n selector:\n matchLabels:\n app: graphite-processor\n template:\n metadata:\n labels:\n app: graphite-processor\n spec:\n containers:\n - name: graphite\n image: graphite:3.0.0\n ports:\n - containerPort: 8080\n env:\n - name: GRAPHITE_CONFIG\n value: \"/etc/graphite/config.json\"\n - name: GRAPHITE_LOG_LEVEL\n value: \"INFO\"\n volumeMounts:\n - name: config\n mountPath: /etc/graphite\n - name: data\n mountPath: /data\n resources:\n requests:\n memory: \"256Mi\"\n cpu: \"250m\"\n limits:\n memory: \"1Gi\"\n cpu: \"1000m\"\n livenessProbe:\n httpGet:\n path: /health\n port: 8080\n initialDelaySeconds: 30\n periodSeconds: 10\n readinessProbe:\n httpGet:\n path: /ready\n port: 8080\n initialDelaySeconds: 5\n periodSeconds: 5\n volumes:\n - name: config\n configMap:\n name: graphite-config\n - name: data\n persistentVolumeClaim:\n claimName: graphite-storage\n\n---\n# k8s/service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n name: graphite-service\n namespace: graphite-system\nspec:\n selector:\n app: graphite-processor\n ports:\n - port: 80\n targetPort: 8080\n protocol: TCP\n type: ClusterIP\n\n---\n# k8s/pvc.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n name: graphite-storage\n namespace: graphite-system\nspec:\n accessModes:\n - ReadWriteMany\n resources:\n requests:\n storage: 100Gi\n storageClassName: fast-ssd\n```\n\n### 24.3 Cloud Deployment\n\n#### 24.3.1 AWS Deployment with Terraform\n```hcl\n# terraform/main.tf\nterraform {\n required_version = \">= 1.0\"\n required_providers {\n aws = {\n source = \"hashicorp/aws\"\n version = \"~> 5.0\"\n }\n }\n}\n\nprovider \"aws\" {\n region = var.aws_region\n}\n\n# VPC and Networking\nmodule \"vpc\" {\n source = \"terraform-aws-modules/vpc/aws\"\n \n name = \"graphite-vpc\"\n cidr = \"10.0.0.0/16\"\n \n azs = [\"${var.aws_region}a\", \"${var.aws_region}b\", \"${var.aws_region}c\"]\n private_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n public_subnets = [\"10.0.101.0/24\", \"10.0.102.0/24\", \"10.0.103.0/24\"]\n \n enable_nat_gateway = true\n enable_vpn_gateway = false\n \n tags = {\n Environment = var.environment\n Project = \"graphite\"\n }\n}\n\n# EKS Cluster\nmodule \"eks\" {\n source = \"terraform-aws-modules/eks/aws\"\n \n cluster_name = \"graphite-cluster\"\n cluster_version = \"1.27\"\n \n vpc_id = module.vpc.vpc_id\n subnet_ids = module.vpc.private_subnets\n \n # Node groups\n eks_managed_node_groups = {\n general = {\n min_size = 2\n max_size = 10\n desired_size = 3\n \n instance_types = [\"m5.large\"]\n capacity_type = \"ON_DEMAND\"\n \n k8s_labels = {\n Environment = var.environment\n NodeGroup = \"general\"\n }\n }\n \n compute_optimized = {\n min_size = 0\n max_size = 5\n desired_size = 1\n \n instance_types = [\"c5.xlarge\"]\n capacity_type = \"SPOT\"\n \n k8s_labels = {\n Environment = var.environment\n NodeGroup = \"compute\"\n }\n \n taints = {\n dedicated = {\n key = \"compute-optimized\"\n value = \"true\"\n effect = \"NO_SCHEDULE\"\n }\n }\n }\n }\n \n tags = {\n Environment = var.environment\n Project = \"graphite\"\n }\n}\n\n# S3 Bucket for asset storage\nresource \"aws_s3_bucket\" \"graphite_assets\" {\n bucket = \"graphite-assets-${var.environment}-${random_string.bucket_suffix.result}\"\n \n tags = {\n Environment = var.environment\n Project = \"graphite\"\n }\n}\n\nresource \"aws_s3_bucket_versioning\" \"graphite_assets\" {\n bucket = aws_s3_bucket.graphite_assets.id\n versioning_configuration {\n status = \"Enabled\"\n }\n}\n\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"graphite_assets\" {\n bucket = aws_s3_bucket.graphite_assets.id\n \n rule {\n apply_server_side_encryption_by_default {\n sse_algorithm = \"AES256\"\n }\n }\n}\n\n# CloudFront distribution for CDN\nresource \"aws_cloudfront_distribution\" \"graphite_cdn\" {\n origin {\n domain_name = aws_s3_bucket.graphite_assets.bucket_regional_domain_name\n origin_id = \"graphite-s3-origin\"\n \n s3_origin_config {\n origin_access_identity = aws_cloudfront_origin_access_identity.graphite_oai.cloudfront_access_identity_path\n }\n }\n \n enabled = true\n \n default_cache_behavior {\n target_origin_id = \"graphite-s3-origin\"\n viewer_protocol_policy = \"redirect-to-https\"\n allowed_methods = [\"GET\", \"HEAD\", \"OPTIONS\"]\n cached_methods = [\"GET\", \"HEAD\"]\n \n forwarded_values {\n query_string = false\n cookies {\n forward = \"none\"\n }\n }\n \n min_ttl = 0\n default_ttl = 3600\n max_ttl = 86400\n }\n \n restrictions {\n geo_restriction {\n restriction_type = \"none\"\n }\n }\n \n viewer_certificate {\n cloudfront_default_certificate = true\n }\n \n tags = {\n Environment = var.environment\n Project = \"graphite\"\n }\n}\n\nresource \"aws_cloudfront_origin_access_identity\" \"graphite_oai\" {\n comment = \"OAI for GRAPHITE assets\"\n}\n\n# Random string for S3 bucket uniqueness\nresource \"random_string\" \"bucket_suffix\" {\n length = 8\n special = false\n upper = false\n}\n\n# Variables\nvariable \"aws_region\" {\n description = \"AWS region\"\n type = string\n default = \"us-west-2\"\n}\n\nvariable \"environment\" {\n description = \"Environment name\"\n type = string\n default = \"production\"\n}\n\n# Outputs\noutput \"eks_cluster_endpoint\" {\n value = module.eks.cluster_endpoint\n}\n\noutput \"s3_bucket_name\" {\n value = aws_s3_bucket.graphite_assets.bucket\n}\n\noutput \"cloudfront_domain_name\" {\n value = aws_cloudfront_distribution.graphite_cdn.domain_name\n}\n```\n\n#### 24.3.2 Azure Resource Manager Template\n```json\n{\n \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\",\n \"contentVersion\": \"1.0.0.0\",\n \"parameters\": {\n \"environment\": {\n \"type\": \"string\",\n \"defaultValue\": \"production\",\n \"allowedValues\": [\"development\", \"staging\", \"production\"]\n },\n \"location\": {\n \"type\": \"string\",\n \"defaultValue\": \"[resourceGroup().location]\"\n }\n },\n \"variables\": {\n \"resourcePrefix\": \"[concat('graphite-', parameters('environment'))]\",\n \"storageAccountName\": \"[concat(replace(variables('resourcePrefix'), '-', ''), uniqueString(resourceGroup().id))]\",\n \"aksClusterName\": \"[concat(variables('resourcePrefix'), '-aks')]\",\n \"acrName\": \"[concat(replace(variables('resourcePrefix'), '-', ''), 'acr')]\"\n },\n \"resources\": [\n {\n \"type\": \"Microsoft.Storage/storageAccounts\",\n \"apiVersion\": \"2021-09-01\",\n \"name\": \"[variables('storageAccountName')]\",\n \"location\": \"[parameters('location')]\",\n \"sku\": {\n \"name\": \"Standard_LRS\"\n },\n \"kind\": \"StorageV2\",\n \"properties\": {\n \"encryption\": {\n \"services\": {\n \"blob\": {\n \"enabled\": true\n },\n \"file\": {\n \"enabled\": true\n }\n },\n \"keySource\": \"Microsoft.Storage\"\n },\n \"supportsHttpsTrafficOnly\": true\n },\n \"tags\": {\n \"Environment\": \"[parameters('environment')]\",\n \"Project\": \"graphite\"\n }\n },\n {\n \"type\": \"Microsoft.ContainerRegistry/registries\",\n \"apiVersion\": \"2021-09-01\",\n \"name\": \"[variables('acrName')]\",\n \"location\": \"[parameters('location')]\",\n \"sku\": {\n \"name\": \"Standard\"\n },\n \"properties\": {\n \"adminUserEnabled\": false\n },\n \"tags\": {\n \"Environment\": \"[parameters('environment')]\",\n \"Project\": \"graphite\"\n }\n },\n {\n \"type\": \"Microsoft.ContainerService/managedClusters\",\n \"apiVersion\": \"2021-10-01\",\n \"name\": \"[variables('aksClusterName')]\",\n \"location\": \"[parameters('location')]\",\n \"identity\": {\n \"type\": \"SystemAssigned\"\n },\n \"properties\": {\n \"kubernetesVersion\": \"1.27.3\",\n \"dnsPrefix\": \"[variables('resourcePrefix')]\",\n \"agentPoolProfiles\": [\n {\n \"name\": \"general\",\n \"count\": 3,\n \"vmSize\": \"Standard_D4s_v3\",\n \"osDiskSizeGB\": 128,\n \"mode\": \"System\",\n \"type\": \"VirtualMachineScaleSets\",\n \"enableAutoScaling\": true,\n \"minCount\": 2,\n \"maxCount\": 10\n },\n {\n \"name\": \"compute\",\n \"count\": 1,\n \"vmSize\": \"Standard_F8s_v2\",\n \"osDiskSizeGB\": 128,\n \"mode\": \"User\",\n \"type\": \"VirtualMachineScaleSets\",\n \"enableAutoScaling\": true,\n \"minCount\": 0,\n \"maxCount\": 5,\n \"nodeLabels\": {\n \"workload\": \"compute-intensive\"\n },\n \"nodeTaints\": [\n \"compute-optimized=true:NoSchedule\"\n ]\n }\n ],\n \"servicePrincipalProfile\": {\n \"clientId\": \"msi\"\n },\n \"networkProfile\": {\n \"networkPlugin\": \"azure\",\n \"loadBalancerSku\": \"standard\"\n }\n },\n \"tags\": {\n \"Environment\": \"[parameters('environment')]\",\n \"Project\": \"graphite\"\n }\n }\n ],\n \"outputs\": {\n \"storageAccountName\": {\n \"type\": \"string\",\n \"value\": \"[variables('storageAccountName')]\"\n },\n \"aksClusterName\": {\n \"type\": \"string\",\n \"value\": \"[variables('aksClusterName')]\"\n },\n \"acrLoginServer\": {\n \"type\": \"string\",\n \"value\": \"[reference(variables('acrName')).loginServer]\"\n }\n }\n}\n```\n\nThis completes sections 22-24. Would you like me to continue with the final sections 25-28?","originalFile":"# GRAPHITE Specification - Part 4: Performance, Security & Production\n\n*Continuing from Section 19 (Cross-Platform Considerations)*\n\n---\n\n## 20. Performance Benchmarks & Testing\n\nGRAPHITE includes comprehensive performance testing frameworks to ensure consistent performance across platforms, workloads, and hardware configurations.\n\n### 20.1 Benchmarking Framework\n\n#### 20.1.1 Core Benchmark Infrastructure\n```c\n// Benchmark context and measurement\ntypedef struct {\n const char* name;\n const char* description;\n uint64_t iterations;\n uint64_t warmup_iterations;\n bool measure_memory;\n bool measure_cpu;\n bool measure_io;\n void* user_data;\n} graphite_benchmark_config;\n\ntypedef struct {\n uint64_t min_time_ns;\n uint64_t max_time_ns;\n uint64_t mean_time_ns;\n uint64_t median_time_ns;\n uint64_t p95_time_ns;\n uint64_t p99_time_ns;\n uint64_t std_dev_ns;\n \n size_t min_memory_bytes;\n size_t max_memory_bytes;\n size_t mean_memory_bytes;\n \n uint64_t cpu_cycles;\n uint64_t cache_misses;\n uint64_t branch_misses;\n uint64_t page_faults;\n \n uint64_t bytes_read;\n uint64_t bytes_written;\n uint32_t io_operations;\n} graphite_benchmark_result;\n\n// High-precision timing\nstatic inline uint64_t graphite_get_precise_time_ns(void) {\n#ifdef GRAPHITE_PLATFORM_WINDOWS\n LARGE_INTEGER freq, counter;\n QueryPerformanceFrequency(&freq);\n QueryPerformanceCounter(&counter);\n return (counter.QuadPart * 1000000000ULL) / freq.QuadPart;\n#elif defined(GRAPHITE_PLATFORM_LINUX) || defined(GRAPHITE_PLATFORM_MACOS)\n struct timespec ts;\n clock_gettime(CLOCK_MONOTONIC, &ts);\n return ts.tv_sec * 1000000000ULL + ts.tv_nsec;\n#else\n // Fallback to microsecond precision\n struct timeval tv;\n gettimeofday(&tv, NULL);\n return tv.tv_sec * 1000000000ULL + tv.tv_usec * 1000ULL;\n#endif\n}\n\n// CPU cycle counting\nstatic inline uint64_t graphite_get_cpu_cycles(void) {\n#ifdef GRAPHITE_ARCH_X64\n return __rdtsc();\n#elif defined(GRAPHITE_ARCH_ARM64)\n uint64_t cycles;\n asm volatile(\"mrs %0, cntvct_el0\" : \"=r\"(cycles));\n return cycles;\n#else\n // Fallback to time-based estimation\n static uint64_t cycles_per_ns = 0;\n if (cycles_per_ns == 0) {\n // Calibrate once (rough approximation)\n cycles_per_ns = 3; // Assume 3GHz average\n }\n return graphite_get_precise_time_ns() * cycles_per_ns;\n#endif\n}\n\n// Memory usage tracking\ntypedef struct {\n size_t peak_rss;\n size_t current_rss;\n size_t heap_allocated;\n size_t heap_freed;\n size_t mmap_allocated;\n size_t mmap_freed;\n} graphite_memory_stats;\n\ngraphite_memory_stats graphite_get_memory_stats(void) {\n graphite_memory_stats stats = {0};\n \n#ifdef GRAPHITE_PLATFORM_LINUX\n FILE* statm = fopen(\"/proc/self/statm\", \"r\");\n if (statm) {\n unsigned long size, resident, shared, text, lib, data, dt;\n if (fscanf(statm, \"%lu %lu %lu %lu %lu %lu %lu\", \n &size, &resident, &shared, &text, &lib, &data, &dt) == 7) {\n long page_size = sysconf(_SC_PAGESIZE);\n stats.current_rss = resident * page_size;\n }\n fclose(statm);\n }\n \n FILE* status = fopen(\"/proc/self/status\", \"r\");\n if (status) {\n char line[256];\n while (fgets(line, sizeof(line), status)) {\n if (strncmp(line, \"VmHWM:\", 6) == 0) {\n sscanf(line + 6, \"%zu\", &stats.peak_rss);\n stats.peak_rss *= 1024; // Convert from KB to bytes\n break;\n }\n }\n fclose(status);\n }\n \n#elif defined(GRAPHITE_PLATFORM_MACOS)\n struct rusage usage;\n if (getrusage(RUSAGE_SELF, &usage) == 0) {\n stats.peak_rss = usage.ru_maxrss;\n stats.current_rss = usage.ru_maxrss; // macOS doesn't provide current RSS easily\n }\n \n#elif defined(GRAPHITE_PLATFORM_WINDOWS)\n PROCESS_MEMORY_COUNTERS_EX pmc;\n if (GetProcessMemoryInfo(GetCurrentProcess(), (PROCESS_MEMORY_COUNTERS*)&pmc, sizeof(pmc))) {\n stats.current_rss = pmc.WorkingSetSize;\n stats.peak_rss = pmc.PeakWorkingSetSize;\n }\n#endif\n \n return stats;\n}\n```\n\n#### 20.1.2 Performance Counter Integration\n```c\n// Hardware performance counters (Linux perf_event)\n#ifdef GRAPHITE_PLATFORM_LINUX\n#include <linux/perf_event.h>\n#include <sys/syscall.h>\n\ntypedef struct {\n int cache_misses_fd;\n int cache_references_fd;\n int branch_misses_fd;\n int branch_instructions_fd;\n int page_faults_fd;\n int context_switches_fd;\n} graphite_perf_counters;\n\nstatic long perf_event_open(struct perf_event_attr *hw_event, pid_t pid,\n int cpu, int group_fd, unsigned long flags) {\n return syscall(__NR_perf_event_open, hw_event, pid, cpu, group_fd, flags);\n}\n\ngraphite_result graphite_init_perf_counters(graphite_perf_counters* counters) {\n struct perf_event_attr pe = {0};\n pe.type = PERF_TYPE_HARDWARE;\n pe.size = sizeof(struct perf_event_attr);\n pe.disabled = 1;\n pe.exclude_kernel = 1;\n pe.exclude_hv = 1;\n \n // Cache misses\n pe.config = PERF_COUNT_HW_CACHE_MISSES;\n counters->cache_misses_fd = perf_event_open(&pe, 0, -1, -1, 0);\n \n // Cache references\n pe.config = PERF_COUNT_HW_CACHE_REFERENCES;\n counters->cache_references_fd = perf_event_open(&pe, 0, -1, -1, 0);\n \n // Branch misses\n pe.config = PERF_COUNT_HW_BRANCH_MISSES;\n counters->branch_misses_fd = perf_event_open(&pe, 0, -1, -1, 0);\n \n // Branch instructions\n pe.config = PERF_COUNT_HW_BRANCH_INSTRUCTIONS;\n counters->branch_instructions_fd = perf_event_open(&pe, 0, -1, -1, 0);\n \n // Page faults\n pe.type = PERF_TYPE_SOFTWARE;\n pe.config = PERF_COUNT_SW_PAGE_FAULTS;\n counters->page_faults_fd = perf_event_open(&pe, 0, -1, -1, 0);\n \n // Context switches\n pe.config = PERF_COUNT_SW_CONTEXT_SWITCHES;\n counters->context_switches_fd = perf_event_open(&pe, 0, -1, -1, 0);\n \n return GRAPHITE_SUCCESS;\n}\n\nvoid graphite_start_perf_counters(graphite_perf_counters* counters) {\n ioctl(counters->cache_misses_fd, PERF_EVENT_IOC_RESET, 0);\n ioctl(counters->cache_references_fd, PERF_EVENT_IOC_RESET, 0);\n ioctl(counters->branch_misses_fd, PERF_EVENT_IOC_RESET, 0);\n ioctl(counters->branch_instructions_fd, PERF_EVENT_IOC_RESET, 0);\n ioctl(counters->page_faults_fd, PERF_EVENT_IOC_RESET, 0);\n ioctl(counters->context_switches_fd, PERF_EVENT_IOC_RESET, 0);\n \n ioctl(counters->cache_misses_fd, PERF_EVENT_IOC_ENABLE, 0);\n ioctl(counters->cache_references_fd, PERF_EVENT_IOC_ENABLE, 0);\n ioctl(counters->branch_misses_fd, PERF_EVENT_IOC_ENABLE, 0);\n ioctl(counters->branch_instructions_fd, PERF_EVENT_IOC_ENABLE, 0);\n ioctl(counters->page_faults_fd, PERF_EVENT_IOC_ENABLE, 0);\n ioctl(counters->context_switches_fd, PERF_EVENT_IOC_ENABLE, 0);\n}\n\nvoid graphite_stop_perf_counters(graphite_perf_counters* counters,\n graphite_benchmark_result* result) {\n ioctl(counters->cache_misses_fd, PERF_EVENT_IOC_DISABLE, 0);\n ioctl(counters->cache_references_fd, PERF_EVENT_IOC_DISABLE, 0);\n ioctl(counters->branch_misses_fd, PERF_EVENT_IOC_DISABLE, 0);\n ioctl(counters->branch_instructions_fd, PERF_EVENT_IOC_DISABLE, 0);\n ioctl(counters->page_faults_fd, PERF_EVENT_IOC_DISABLE, 0);\n ioctl(counters->context_switches_fd, PERF_EVENT_IOC_DISABLE, 0);\n \n long long cache_misses, branch_misses, page_faults;\n read(counters->cache_misses_fd, &cache_misses, sizeof(cache_misses));\n read(counters->branch_misses_fd, &branch_misses, sizeof(branch_misses));\n read(counters->page_faults_fd, &page_faults, sizeof(page_faults));\n \n result->cache_misses = cache_misses;\n result->branch_misses = branch_misses;\n result->page_faults = page_faults;\n}\n#endif // GRAPHITE_PLATFORM_LINUX\n```\n\n### 20.2 Standard Benchmark Suite\n\n#### 20.2.1 Core Operation Benchmarks\n```c\n// Bundle open/close benchmarks\nvoid benchmark_bundle_open(const char* bundle_path, graphite_benchmark_result* result) {\n graphite_benchmark_config config = {\n .name = \"bundle_open\",\n .description = \"Time to open and validate a GRAPHITE bundle\",\n .iterations = 1000,\n .warmup_iterations = 100,\n .measure_memory = true,\n .measure_cpu = true,\n .measure_io = true\n };\n \n graphite_perf_counters counters;\n graphite_init_perf_counters(&counters);\n \n uint64_t* times = malloc(sizeof(uint64_t) * config.iterations);\n graphite_memory_stats initial_memory = graphite_get_memory_stats();\n \n // Warmup\n for (uint64_t i = 0; i < config.warmup_iterations; i++) {\n graphite_bundle* bundle = graphite_open(bundle_path);\n if (bundle) {\n graphite_close(bundle);\n }\n }\n \n // Actual benchmark\n graphite_start_perf_counters(&counters);\n uint64_t start_cycles = graphite_get_cpu_cycles();\n \n for (uint64_t i = 0; i < config.iterations; i++) {\n uint64_t start_time = graphite_get_precise_time_ns();\n \n graphite_bundle* bundle = graphite_open(bundle_path);\n if (!bundle) {\n times[i] = UINT64_MAX; // Mark as failed\n continue;\n }\n \n uint64_t end_time = graphite_get_precise_time_ns();\n times[i] = end_time - start_time;\n \n graphite_close(bundle);\n }\n \n uint64_t end_cycles = graphite_get_cpu_cycles();\n graphite_stop_perf_counters(&counters, result);\n \n // Calculate statistics\n qsort(times, config.iterations, sizeof(uint64_t), compare_uint64);\n \n result->min_time_ns = times[0];\n result->max_time_ns = times[config.iterations - 1];\n result->median_time_ns = times[config.iterations / 2];\n result->p95_time_ns = times[(config.iterations * 95) / 100];\n result->p99_time_ns = times[(config.iterations * 99) / 100];\n \n // Calculate mean and standard deviation\n uint64_t sum = 0;\n for (uint64_t i = 0; i < config.iterations; i++) {\n sum += times[i];\n }\n result->mean_time_ns = sum / config.iterations;\n \n uint64_t variance_sum = 0;\n for (uint64_t i = 0; i < config.iterations; i++) {\n uint64_t diff = times[i] > result->mean_time_ns ? \n times[i] - result->mean_time_ns : \n result->mean_time_ns - times[i];\n variance_sum += diff * diff;\n }\n result->std_dev_ns = sqrt(variance_sum / config.iterations);\n \n result->cpu_cycles = end_cycles - start_cycles;\n \n graphite_memory_stats final_memory = graphite_get_memory_stats();\n result->max_memory_bytes = final_memory.peak_rss - initial_memory.peak_rss;\n \n free(times);\n}\n\n// Asset streaming benchmark\nvoid benchmark_asset_streaming(const char* bundle_path, \n uint32_t concurrent_requests,\n graphite_benchmark_result* result) {\n graphite_bundle* bundle = graphite_open(bundle_path);\n if (!bundle) {\n result->min_time_ns = UINT64_MAX;\n return;\n }\n \n const graphite_graph* root = graphite_root(bundle);\n if (!root || root->header.node_cnt == 0) {\n graphite_close(bundle);\n result->min_time_ns = UINT64_MAX;\n return;\n }\n \n // Create streaming context\n graphite_streaming_context* streaming = graphite_streaming_create(bundle);\n \n // Generate random asset access pattern\n uint32_t* asset_sequence = malloc(sizeof(uint32_t) * concurrent_requests);\n for (uint32_t i = 0; i < concurrent_requests; i++) {\n asset_sequence[i] = rand() % root->header.node_cnt;\n }\n \n uint64_t start_time = graphite_get_precise_time_ns();\n uint64_t start_cycles = graphite_get_cpu_cycles();\n \n // Submit streaming requests\n for (uint32_t i = 0; i < concurrent_requests; i++) {\n graphite_stream_request request = {\n .asset_id = asset_sequence[i],\n .priority = GRAPHITE_PRIORITY_MEDIUM,\n .request_time = graphite_get_precise_time_ns()\n };\n graphite_submit_stream_request(streaming, &request);\n }\n \n // Wait for all requests to complete\n while (graphite_streaming_pending_count(streaming) > 0) {\n graphite_streaming_process(streaming);\n usleep(100); // 100 microseconds\n }\n \n uint64_t end_time = graphite_get_precise_time_ns();\n uint64_t end_cycles = graphite_get_cpu_cycles();\n \n result->mean_time_ns = end_time - start_time;\n result->cpu_cycles = end_cycles - start_cycles;\n \n // Get streaming statistics\n graphite_streaming_stats stats = graphite_streaming_get_stats(streaming);\n result->cache_hits = stats.cache_hits;\n result->cache_misses = stats.cache_misses;\n result->bytes_read = stats.bytes_streamed;\n result->io_operations = stats.requests_completed;\n \n free(asset_sequence);\n graphite_streaming_destroy(streaming);\n graphite_close(bundle);\n}\n\n// Hot reload benchmark\nvoid benchmark_hot_reload(const char* bundle_path, graphite_benchmark_result* result) {\n graphite_bundle* original = graphite_open(bundle_path);\n if (!original) {\n result->min_time_ns = UINT64_MAX;\n return;\n }\n \n // Create temporary modified bundle\n char temp_path[256];\n snprintf(temp_path, sizeof(temp_path), \"%s.tmp\", bundle_path);\n \n // Create hot reload context\n graphite_hot_reload_config reload_config = {\n .bundle_path = temp_path,\n .atomic_reload = true,\n .preserve_handle_state = true\n };\n \n graphite_hot_reload_context* reload_ctx = graphite_hot_reload_init(&reload_config);\n \n uint64_t* reload_times = malloc(sizeof(uint64_t) * 100);\n \n for (int i = 0; i < 100; i++) {\n // Copy original to temp (simulating file change)\n graphite_copy_file(bundle_path, temp_path);\n \n uint64_t start_time = graphite_get_precise_time_ns();\n \n // Trigger hot reload\n graphite_trigger_reload(reload_ctx);\n \n // Wait for reload to complete\n while (graphite_reload_pending(reload_ctx)) {\n usleep(10);\n }\n \n uint64_t end_time = graphite_get_precise_time_ns();\n reload_times[i] = end_time - start_time;\n }\n \n // Calculate statistics\n qsort(reload_times, 100, sizeof(uint64_t), compare_uint64);\n result->min_time_ns = reload_times[0];\n result->max_time_ns = reload_times[99];\n result->median_time_ns = reload_times[50];\n result->p95_time_ns = reload_times[95];\n result->p99_time_ns = reload_times[99];\n \n free(reload_times);\n graphite_hot_reload_shutdown(reload_ctx);\n graphite_close(original);\n unlink(temp_path);\n}\n```\n\n#### 20.2.2 Scalability Benchmarks\n```c\n// Large bundle performance scaling\nvoid benchmark_bundle_scaling(graphite_benchmark_result* results, size_t result_count) {\n const char* test_bundles[] = {\n \"test_1mb.graphite\", // 1 MB\n \"test_10mb.graphite\", // 10 MB \n \"test_100mb.graphite\", // 100 MB\n \"test_1gb.graphite\", // 1 GB\n \"test_10gb.graphite\" // 10 GB\n };\n \n const size_t bundle_sizes[] = {\n 1024 * 1024, // 1 MB\n 10 * 1024 * 1024, // 10 MB\n 100 * 1024 * 1024, // 100 MB\n 1024 * 1024 * 1024, // 1 GB\n 10ULL * 1024 * 1024 * 1024 // 10 GB\n };\n \n size_t num_bundles = sizeof(test_bundles) / sizeof(test_bundles[0]);\n if (result_count < num_bundles) {\n num_bundles = result_count;\n }\n \n for (size_t i = 0; i < num_bundles; i++) {\n printf(\"Benchmarking %s (%zu bytes)...\\n\", test_bundles[i], bundle_sizes[i]);\n \n // Open/close benchmark\n benchmark_bundle_open(test_bundles[i], &results[i]);\n \n // Calculate throughput (MB/s)\n double mb_size = bundle_sizes[i] / (1024.0 * 1024.0);\n double seconds = results[i].mean_time_ns / 1e9;\n double throughput = mb_size / seconds;\n \n printf(\" Open time: %.2f ms (%.2f MB/s)\\n\", \n results[i].mean_time_ns / 1e6, throughput);\n printf(\" P95: %.2f ms, P99: %.2f ms\\n\",\n results[i].p95_time_ns / 1e6, results[i].p99_time_ns / 1e6);\n printf(\" Memory: %.2f MB peak\\n\", \n results[i].max_memory_bytes / (1024.0 * 1024.0));\n printf(\" Cache misses: %llu, Page faults: %llu\\n\",\n results[i].cache_misses, results[i].page_faults);\n }\n}\n\n// Concurrent access benchmark\nvoid benchmark_concurrent_access(const char* bundle_path, \n uint32_t thread_count,\n graphite_benchmark_result* result) {\n typedef struct {\n const char* bundle_path;\n uint32_t thread_id;\n uint64_t iterations;\n uint64_t total_time_ns;\n uint64_t successful_operations;\n } thread_context;\n \n thread_context* contexts = malloc(sizeof(thread_context) * thread_count);\n pthread_t* threads = malloc(sizeof(pthread_t) * thread_count);\n \n // Worker thread function\n auto worker_thread = [](void* arg) -> void* {\n thread_context* ctx = (thread_context*)arg;\n \n uint64_t start_time = graphite_get_precise_time_ns();\n \n for (uint64_t i = 0; i < ctx->iterations; i++) {\n graphite_bundle* bundle = graphite_open(ctx->bundle_path);\n if (bundle) {\n // Perform some operations\n const graphite_graph* root = graphite_root(bundle);\n if (root && root->header.node_cnt > 0) {\n // Access random asset\n uint32_t asset_idx = rand() % root->header.node_cnt;\n const graphite_graph* asset = graphite_get_child_graph(root, asset_idx);\n if (asset) {\n ctx->successful_operations++;\n }\n }\n graphite_close(bundle);\n }\n }\n \n uint64_t end_time = graphite_get_precise_time_ns();\n ctx->total_time_ns = end_time - start_time;\n \n return NULL;\n };\n \n uint64_t iterations_per_thread = 1000;\n \n // Initialize contexts and start threads\n uint64_t overall_start = graphite_get_precise_time_ns();\n \n for (uint32_t i = 0; i < thread_count; i++) {\n contexts[i] = (thread_context){\n .bundle_path = bundle_path,\n .thread_id = i,\n .iterations = iterations_per_thread,\n .total_time_ns = 0,\n .successful_operations = 0\n };\n \n pthread_create(&threads[i], NULL, worker_thread, &contexts[i]);\n }\n \n // Wait for all threads to complete\n for (uint32_t i = 0; i < thread_count; i++) {\n pthread_join(threads[i], NULL);\n }\n \n uint64_t overall_end = graphite_get_precise_time_ns();\n \n // Aggregate results\n uint64_t total_operations = 0;\n uint64_t total_successful = 0;\n uint64_t min_thread_time = UINT64_MAX;\n uint64_t max_thread_time = 0;\n \n for (uint32_t i = 0; i < thread_count; i++) {\n total_operations += contexts[i].iterations;\n total_successful += contexts[i].successful_operations;\n \n if (contexts[i].total_time_ns < min_thread_time) {\n min_thread_time = contexts[i].total_time_ns;\n }\n if (contexts[i].total_time_ns > max_thread_time) {\n max_thread_time = contexts[i].total_time_ns;\n }\n }\n \n result->mean_time_ns = overall_end - overall_start;\n result->min_time_ns = min_thread_time;\n result->max_time_ns = max_thread_time;\n result->io_operations = total_successful;\n \n // Calculate throughput (operations per second)\n double seconds = result->mean_time_ns / 1e9;\n double ops_per_second = total_successful / seconds;\n \n printf(\"Concurrent access (%u threads):\\n\", thread_count);\n printf(\" Total time: %.2f ms\\n\", result->mean_time_ns / 1e6);\n printf(\" Operations: %llu successful / %llu total\\n\", total_successful, total_operations);\n printf(\" Throughput: %.2f ops/sec\\n\", ops_per_second);\n printf(\" Thread variance: %.2f ms (min: %.2f ms, max: %.2f ms)\\n\",\n (max_thread_time - min_thread_time) / 1e6,\n min_thread_time / 1e6, max_thread_time / 1e6);\n \n free(contexts);\n free(threads);\n}\n```\n\n### 20.3 Performance Regression Testing\n\n#### 20.3.1 Automated Performance CI\n```bash\n#!/bin/bash\n# performance_ci.sh - Automated performance regression testing\n\nset -e\n\nBASELINE_RESULTS=\"baseline_performance.json\"\nCURRENT_RESULTS=\"current_performance.json\"\nREGRESSION_THRESHOLD=5.0 # 5% regression threshold\n\necho \"=== GRAPHITE Performance Regression Testing ===\"\n\n# Build current version\necho \"Building current version...\"\nmake clean && make release\n\n# Generate test bundles if they don't exist\necho \"Generating test bundles...\"\nif [ ! -f \"test_1mb.graphite\" ]; then\n ./tools/generate_test_bundles.sh\nfi\n\n# Run performance benchmarks\necho \"Running performance benchmarks...\"\n./graphite benchmark \\\n --bundle test_1mb.graphite \\\n --bundle test_10mb.graphite \\\n --bundle test_100mb.graphite \\\n --output ${CURRENT_RESULTS} \\\n --iterations 1000 \\\n --warmup 100 \\\n --detailed\n\n# Compare with baseline if it exists\nif [ -f \"${BASELINE_RESULTS}\" ]; then\n echo \"Comparing with baseline performance...\"\n \n # Parse results and calculate regressions\n python3 << EOF\nimport json\nimport sys\n\ndef load_results(filename):\n with open(filename, 'r') as f:\n return json.load(f)\n\ndef calculate_regression(baseline, current, metric):\n if baseline[metric] == 0:\n return 0.0\n return ((current[metric] - baseline[metric]) / baseline[metric]) * 100.0\n\nbaseline = load_results(\"${BASELINE_RESULTS}\")\ncurrent = load_results(\"${CURRENT_RESULTS}\")\n\nregressions = {}\ncritical_regressions = []\n\nfor test_name in baseline:\n if test_name not in current:\n continue\n \n baseline_test = baseline[test_name]\n current_test = current[test_name]\n \n # Check key metrics\n metrics = ['mean_time_ns', 'p95_time_ns', 'p99_time_ns', 'max_memory_bytes']\n \n for metric in metrics:\n if metric in baseline_test and metric in current_test:\n regression = calculate_regression(baseline_test, current_test, metric)\n regressions[f\"{test_name}.{metric}\"] = regression\n \n if regression > ${REGRESSION_THRESHOLD}:\n critical_regressions.append({\n 'test': test_name,\n 'metric': metric,\n 'regression': regression,\n 'baseline': baseline_test[metric],\n 'current': current_test[metric]\n })\n\n# Print results\nprint(f\"Performance Analysis Report\")\nprint(f\"=\" * 50)\n\nif critical_regressions:\n print(f\" CRITICAL REGRESSIONS DETECTED (>{REGRESSION_THRESHOLD}%):\")\n for reg in critical_regressions:\n print(f\" {reg['test']}.{reg['metric']}: {reg['regression']:.1f}% regression\")\n print(f\" Baseline: {reg['baseline']:,}\")\n print(f\" Current: {reg['current']:,}\")\n print()\n sys.exit(1)\nelse:\n print(\" No critical performance regressions detected\")\n \n # Show summary of all changes\n print(f\"\\nPerformance Changes Summary:\")\n for test_metric, regression in regressions.items():\n status = \"\" if regression > 0 else \"\" if regression < 0 else \"\"\n print(f\" {status} {test_metric}: {regression:+.1f}%\")\n\nprint(f\"\\nFull results saved to: ${CURRENT_RESULTS}\")\nEOF\n\n echo \"Performance regression check completed\"\nelse\n echo \"No baseline found. Saving current results as new baseline.\"\n cp \"${CURRENT_RESULTS}\" \"${BASELINE_RESULTS}\"\nfi\n\n# Generate performance report\necho \"Generating performance report...\"\npython3 tools/generate_perf_report.py \"${CURRENT_RESULTS}\" > performance_report.html\n\necho \"Performance testing completed successfully\"\n```\n\n#### 20.3.2 Performance Profiling Integration\n```c\n// Profiling hooks for development builds\n#ifdef GRAPHITE_PROFILE_BUILD\n\n#include <gperftools/profiler.h>\n\ntypedef struct {\n const char* profile_name;\n bool cpu_profiling;\n bool heap_profiling;\n bool enabled;\n} graphite_profiling_config;\n\nvoid graphite_start_profiling(const graphite_profiling_config* config) {\n if (!config->enabled) return;\n \n if (config->cpu_profiling) {\n char cpu_profile_path[256];\n snprintf(cpu_profile_path, sizeof(cpu_profile_path), \n \"%s_cpu.prof\", config->profile_name);\n ProfilerStart(cpu_profile_path);\n }\n \n if (config->heap_profiling) {\n char heap_profile_path[256];\n snprintf(heap_profile_path, sizeof(heap_profile_path),\n \"%s_heap\", config->profile_name);\n HeapProfilerStart(heap_profile_path);\n }\n}\n\nvoid graphite_stop_profiling(const graphite_profiling_config* config) {\n if (!config->enabled) return;\n \n if (config->cpu_profiling) {\n ProfilerStop();\n }\n \n if (config->heap_profiling) {\n HeapProfilerStop();\n }\n}\n\n// Automatic profiling for slow operations\n#define GRAPHITE_PROFILE_SLOW_OP(name, threshold_ms, block) do { \\\n uint64_t start_time = graphite_get_precise_time_ns(); \\\n graphite_profiling_config prof_config = { \\\n .profile_name = name, \\\n .cpu_profiling = true, \\\n .heap_profiling = false, \\\n .enabled = false \\\n }; \\\n \\\n block; \\\n \\\n uint64_t end_time = graphite_get_precise_time_ns(); \\\n uint64_t duration_ms = (end_time - start_time) / 1000000; \\\n \\\n if (duration_ms > threshold_ms) { \\\n printf(\"Slow operation detected: %s took %llu ms\\n\", name, duration_ms); \\\n /* Re-run with profiling enabled */ \\\n prof_config.enabled = true; \\\n graphite_start_profiling(&prof_config); \\\n block; \\\n graphite_stop_profiling(&prof_config); \\\n } \\\n} while(0)\n\n#else\n#define GRAPHITE_PROFILE_SLOW_OP(name, threshold_ms, block) do { block; } while(0)\n#endif // GRAPHITE_PROFILE_BUILD\n```\n\n---\n\n## 21. Security Model & Threat Analysis\n\nGRAPHITE implements comprehensive security measures to protect against malicious bundles, data corruption, and supply chain attacks.\n\n### 21.1 Threat Model\n\n#### 21.1.1 Attack Vectors\n```c\n// Comprehensive threat classification\ntypedef enum {\n GRAPHITE_THREAT_MALFORMED_BUNDLE, // Crafted to crash parser\n GRAPHITE_THREAT_OVERSIZED_ALLOCATION, // Memory exhaustion attack\n GRAPHITE_THREAT_INFINITE_RECURSION, // Stack overflow via deep graphs\n GRAPHITE_THREAT_INTEGER_OVERFLOW, // Arithmetic overflow exploitation\n GRAPHITE_THREAT_PATH_TRAVERSAL, // Directory traversal in paths\n GRAPHITE_THREAT_DECOMPRESSION_BOMB, // ZIP bomb style attack\n GRAPHITE_THREAT_TIMING_ATTACK, // Side-channel timing analysis\n GRAPHITE_THREAT_CACHE_COLLISION, // Algorithmic complexity attack\n GRAPHITE_THREAT_SUPPLY_CHAIN, // Compromised build pipeline\n GRAPHITE_THREAT_PRIVILEGE_ESCALATION, // Local privilege escalation\n GRAPHITE_THREAT_COUNT\n} graphite_threat_type;\n\n// Threat assessment matrix\ntypedef struct {\n graphite_threat_type type;\n const char* description;\n uint8_t likelihood; // 1-5 scale\n uint8_t impact; // 1-5 scale\n uint8_t risk_score; // likelihood * impact\n const char* mitigation;\n} graphite_threat_assessment;\n\nstatic const graphite_threat_assessment threat_matrix[] = {\n {\n .type = GRAPHITE_THREAT_MALFORMED_BUNDLE,\n .description = \"Maliciously crafted bundle designed to crash parser\",\n .likelihood = 4,\n .impact = 3,\n .risk_score = 12,\n .mitigation = \"Comprehensive input validation, fuzzing, bounds checking\"\n },\n {\n .type = GRAPHITE_THREAT_OVERSIZED_ALLOCATION,\n .description = \"Bundle with huge size fields causing memory exhaustion\",\n .likelihood = 3,\n .impact = 4,\n .risk_score = 12,\n .mitigation = \"Memory limits, allocation guards, progressive loading\"\n },\n {\n .type = GRAPHITE_THREAT_INFINITE_RECURSION,\n .description = \"Circular graph references causing stack overflow\",\n .likelihood = 3,\n .impact = 3,\n .risk_score = 9,\n .mitigation = \"Recursion depth limits, cycle detection, iterative traversal\"\n },\n {\n .type = GRAPHITE_THREAT_DECOMPRESSION_BOMB,\n .description = \"Highly compressed data expanding to huge size\",\n .likelihood = 2,\n .impact = 4,\n .risk_score = 8,\n .mitigation = \"Decompression ratio limits, incremental decompression\"\n },\n {\n .type = GRAPHITE_THREAT_SUPPLY_CHAIN,\n .description = \"Compromised build tools injecting malicious content\",\n .likelihood = 2,\n .impact = 5,\n .risk_score = 10,\n .mitigation = \"Code signing, reproducible builds, dependency verification\"\n }\n};\n```\n\n#### 21.1.2 Security Boundaries\n```c\n// Security context for sandboxed operations\ntypedef struct {\n // Memory limits\n size_t max_memory_allocation; // Maximum single allocation\n size_t max_total_memory; // Maximum total memory usage\n size_t max_decompressed_size; // Maximum decompressed data size\n \n // Processing limits\n uint32_t max_recursion_depth; // Maximum graph traversal depth\n uint32_t max_processing_time_ms; // Maximum processing time per operation\n uint32_t max_file_size; // Maximum bundle file size\n \n // Feature restrictions\n bool allow_external_references; // Allow external file references\n bool allow_code_execution; // Allow embedded scripts/plugins\n bool allow_network_access; // Allow network operations\n bool allow_file_system_access; // Allow file system operations\n \n // Validation requirements\n bool require_signature; // Require cryptographic signature\n bool require_integrity_check; // Require full integrity verification\n bool strict_parsing; // Reject any ambiguous content\n} graphite_security_context;\n\n// Default security contexts for different environments\nstatic const graphite_security_context graphite_security_strict = {\n .max_memory_allocation = 64 * 1024 * 1024, // 64 MB\n .max_total_memory = 512 * 1024 * 1024, // 512 MB\n .max_decompressed_size = 1024 * 1024 * 1024, // 1 GB\n .max_recursion_depth = 64,\n .max_processing_time_ms = 30000, // 30 seconds\n .max_file_size = 2ULL * 1024 * 1024 * 1024, // 2 GB\n .allow_external_references = false,\n .allow_code_execution = false,\n .allow_network_access = false,\n .allow_file_system_access = false,\n .require_signature = true,\n .require_integrity_check = true,\n .strict_parsing = true\n};\n\nstatic const graphite_security_context graphite_security_development = {\n .max_memory_allocation = 1024 * 1024 * 1024, // 1 GB\n .max_total_memory = 8ULL * 1024 * 1024 * 1024, // 8 GB\n .max_decompressed_size = 16ULL * 1024 * 1024 * 1024, // 16 GB\n .max_recursion_depth = 256,\n .max_processing_time_ms = 300000, // 5 minutes\n .max_file_size = 100ULL * 1024 * 1024 * 1024, // 100 GB\n .allow_external_references = true,\n .allow_code_execution = false,\n .allow_network_access = false,\n .allow_file_system_access = true,\n .require_signature = false,\n .require_integrity_check = true,\n .strict_parsing = false\n};\n```\n\n### 21.2 Input Validation & Sanitization\n\n#### 21.2.1 Defensive Bundle Parsing\n```c\n// Secure bundle parser with comprehensive validation\ntypedef struct {\n const uint8_t* data;\n size_t size;\n size_t position;\n const graphite_security_context* security;\n uint32_t recursion_depth;\n uint64_t start_time_ms;\n size_t allocated_memory;\n} graphite_secure_parser;\n\n// Safe integer operations with overflow checking\nstatic inline bool safe_add_size_t(size_t a, size_t b, size_t* result) {\n if (a > SIZE_MAX - b) {\n return false; // Overflow would occur\n }\n *result = a + b;\n return true;\n}\n\nstatic inline bool safe_mul_size_t(size_t a, size_t b, size_t* result) {\n if (a != 0 && b > SIZE_MAX / a) {\n return false; // Overflow would occur\n }\n *result = a * b;\n return true;\n}\n\n// Secure memory allocation with limits\nstatic void* secure_alloc(graphite_secure_parser* parser, size_t size) {\n // Check individual allocation limit\n if (size > parser->security->max_memory_allocation) {\n return NULL;\n }\n \n // Check total memory limit\n size_t new_total;\n if (!safe_add_size_t(parser->allocated_memory, size, &new_total)) {\n return NULL; // Overflow\n }\n \n if (new_total > parser->security->max_total_memory) {\n return NULL; // Would exceed limit\n }\n \n void* ptr = malloc(size);\n if (ptr) {\n parser->allocated_memory = new_total;\n }\n \n return ptr;\n}\n\n// Secure data reading with bounds checking\nstatic graphite_result secure_read_bytes(graphite_secure_parser* parser,\n void* dest, size_t count) {\n // Check time limit\n uint64_t current_time = graphite_get_time_ms();\n if (current_time - parser->start_time_ms > parser->security->max_processing_time_ms) {\n return GRAPHITE_ERROR_TIMEOUT;\n }\n \n // Check bounds\n size_t new_position;\n if (!safe_add_size_t(parser->position, count, &new_position)) {\n return GRAPHITE_ERROR_OVERFLOW;\n }\n \n if (new_position > parser->size) {\n return GRAPHITE_ERROR_BOUNDS;\n }\n \n memcpy(dest, parser->data + parser->position, count);\n parser->position = new_position;\n \n return GRAPHITE_SUCCESS;\n}\n\n// Secure varint decoding with overflow protection\nstatic graphite_result secure_read_varint(graphite_secure_parser* parser,\n uint64_t* value) {\n *value = 0;\n uint32_t shift = 0;\n \n for (int i = 0; i < 10; i++) { // Max 10 bytes for 64-bit varint\n uint8_t byte;\n graphite_result result = secure_read_bytes(parser, &byte, 1);\n if (result != GRAPHITE_SUCCESS) {\n return result;\n }\n \n // Check for overflow\n if (shift >= 64) {\n return GRAPHITE_ERROR_VARINT_OVERFLOW;\n }\n \n uint64_t value_part = (byte & 0x7F);\n if (shift < 64 && value_part > (UINT64_MAX >> shift)) {\n return GRAPHITE_ERROR_VARINT_OVERFLOW;\n }\n \n *value |= value_part << shift;\n \n if ((byte & 0x80) == 0) {\n return GRAPHITE_SUCCESS;\n }\n \n shift += 7;\n }\n \n return GRAPHITE_ERROR_VARINT_TOO_LONG;\n}\n\n// Secure string validation\nstatic graphite_result secure_validate_string(const char* str, size_t length) {\n if (!str) return GRAPHITE_ERROR_NULL_POINTER;\n \n // Check for null termination\n bool found_null = false;\n for (size_t i = 0; i < length; i++) {\n if (str[i] == '\\0') {\n found_null = true;\n break;\n }\n \n // Check for valid UTF-8 (basic validation)\n uint8_t byte = (uint8_t)str[i];\n if (byte >= 0x80) {\n // Multi-byte UTF-8 character - validate sequence\n // (Simplified validation - full UTF-8 validation is more complex)\n if ((byte & 0xE0) == 0xC0) {\n // 2-byte sequence\n if (i + 1 >= length || (str[i + 1] & 0xC0) != 0x80) {\n return GRAPHITE_ERROR_INVALID_UTF8;\n }\n i++; // Skip next byte\n } else if ((byte & 0xF0) == 0xE0) {\n // 3-byte sequence\n if (i + 2 >= length || \n (str[i + 1] & 0xC0) != 0x80 || \n (str[i + 2] & 0xC0) != 0x80) {\n return GRAPHITE_ERROR_INVALID_UTF8;\n }\n i += 2; // Skip next 2 bytes\n } else if ((byte & 0xF8) == 0xF0) {\n // 4-byte sequence\n if (i + 3 >= length ||\n (str[i + 1] & 0xC0) != 0x80 ||\n (str[i + 2] & 0xC0) != 0x80 ||\n (str[i + 3] & 0xC0) != 0x80) {\n return GRAPHITE_ERROR_INVALID_UTF8;\n }\n i += 3; // Skip next 3 bytes\n } else {\n return GRAPHITE_ERROR_INVALID_UTF8;\n }\n }\n }\n \n if (!found_null) {\n return GRAPHITE_ERROR_STRING_NOT_TERMINATED;\n }\n \n return GRAPHITE_SUCCESS;\n}\n```\n\n#### 21.2.2 Decompression Safety\n```c\n// Secure decompression with bomb protection\ntypedef struct {\n size_t max_output_size;\n size_t max_ratio;\n uint32_t max_time_ms;\n void* (*progress_callback)(size_t decompressed, void* user_data);\n void* user_data;\n} graphite_secure_decompress_config;\n\ngraphite_result graphite_secure_decompress(\n const void* compressed_data,\n size_t compressed_size,\n void** decompressed_data,\n size_t* decompressed_size,\n const graphite_secure_decompress_config* config\n) {\n if (!compressed_data || !decompressed_data || !decompressed_size || !config) {\n return GRAPHITE_ERROR_NULL_POINTER;\n }\n \n // Initialize decompression stream\n z_stream stream = {0};\n if (inflateInit(&stream) != Z_OK) {\n return GRAPHITE_ERROR_DECOMPRESS_INIT;\n }\n \n stream.next_in = (Bytef*)compressed_data;\n stream.avail_in = compressed_size;\n \n // Allocate initial output buffer\n size_t output_capacity = compressed_size * 4; // Initial guess\n if (output_capacity > config->max_output_size) {\n output_capacity = config->max_output_size;\n }\n \n uint8_t* output_buffer = malloc(output_capacity);\n if (!output_buffer) {\n inflateEnd(&stream);\n return GRAPHITE_ERROR_ALLOCATION;\n }\n \n stream.next_out = output_buffer;\n stream.avail_out = output_capacity;\n \n size_t total_output = 0;\n uint64_t start_time = graphite_get_time_ms();\n \n int ret;\n do {\n ret = inflate(&stream, Z_NO_FLUSH);\n \n if (ret != Z_OK && ret != Z_STREAM_END) {\n free(output_buffer);\n inflateEnd(&stream);\n return GRAPHITE_ERROR_DECOMPRESS_FAILED;\n }\n \n //`