**Document Version:** 0.1.0 **Date:** 2025-06-28 **Status:** Design Specification - Pre-Production **Classification:** Public Technical Specification **Target Audience:** Systems Engineers, Game Engine Developers, Asset Pipeline Architects --- ## Document Information | Field | Value | |-------|-------| | **Specification Version** | 0.1.0 | | **Document Type** | Technical Specification | | **Implementation Complexity** | Expert Level | | **Estimated Implementation Time** | 8-12 sprints (56-84 developer days) | | **Language Requirements** | C23 with `_BitInt(40)` support | | **Target Platforms** | Linux, macOS, Windows (x86_64, ARM64, i386, RISC-V) | | **Dependencies** | zstd, BLAKE3, optional (io_uring, NUMA, CUDA) | --- ## Table of Contents 1. [Executive Summary](#executive-summary) 2. [Architecture Overview](#architecture-overview) 3. [Core Principles & Design Philosophy](#core-principles--design-philosophy) 4. [Binary Format Specification](#binary-format-specification) 5. [Graph Model & Data Structures](#graph-model--data-structures) 6. [Integrity & Security System](#integrity--security-system) 7. [Compression & Optimization](#compression--optimization) 8. [Performance Engineering](#performance-engineering) 9. [Core API Specification](#core-api-specification) 10. [Tooling API Specification](#tooling-api-specification) 11. [Unity Integration API](#unity-integration-api) 12. [Unreal Engine Integration API](#unreal-engine-integration-api) 13. [Godot Integration API](#godot-integration-api) 14. [Command Line Interface](#command-line-interface) 15. [Asset Pipeline Integration](#asset-pipeline-integration) 16. [Content Delivery Network Integration](#content-delivery-network-integration) 17. [Hot Reload System](#hot-reload-system) 18. [Asset Streaming Architecture](#asset-streaming-architecture) 19. [Cross-Platform Considerations](#cross-platform-considerations) 20. [Performance Benchmarks & Testing](#performance-benchmarks--testing) 21. [Security Model & Threat Analysis](#security-model--threat-analysis) 22. [Implementation Guidelines](#implementation-guidelines) 23. [Quality Assurance & Testing Framework](#quality-assurance--testing-framework) 24. [Deployment & Distribution](#deployment--distribution) 25. [Migration & Compatibility](#migration--compatibility) 26. [Ecosystem & Tooling](#ecosystem--tooling) 27. [Future Roadmap](#future-roadmap) 28. [Appendices](#appendices) --- ## Executive Summary ### Vision Statement GRAPHITE (Graph-based Resource Asset Processing and Interchange Technology Environment) represents a fundamental reimagining of digital asset management for modern applications. Unlike traditional asset formats that treat files as isolated entities, GRAPHITE recognizes that assets exist within complex webs of relationships, dependencies, transformations, and conditional behaviors. ### Revolutionary Paradigm ```mermaid graph TB subgraph \"Traditional Asset Management\" A1[texture.png] A2[model.obj] A3[audio.wav] A4[script.js] A5[config.json] end subgraph \"GRAPHITE Universe\" B1[Asset Graph<br/>Properties + Data] B2[Dependency Graph<br/>Load Order + Conditions] B3[Transform Graph<br/>Processing Pipeline] B4[Bundle Graph<br/>Collection + Metadata] B5[String Pool Graph<br/>Shared Strings] B1 --> B2 B2 --> B3 B3 --> B4 B4 --> B5 subgraph \"Recursive Composition\" C1[Level 1: Categories] C2[Level 2: Collections] C3[Level 3: Assets] C4[Level 4: Components] C1 --> C2 C2 --> C3 C3 --> C4 end end ``` ### Core Innovations #### 1. Everything-Is-A-Graph Model Every component in GRAPHITE is represented as a graph: - **Individual Assets**: Leaf graphs (0 nodes, 0 edges, data in properties) - **Asset Collections**: Graphs with nodes representing individual assets - **Dependencies**: Edges between asset graphs with rich metadata - **Transforms**: Graphs containing input/output subgraphs and processing logic - **Bundles**: Composite graphs containing multiple asset graphs - **Pipelines**: Transform chains represented as directed acyclic graphs #### 2. Zero-Copy Memory Architecture ```mermaid graph LR A[Memory-Mapped File] --> B[Chunk Table Access] B --> C[One-Time Hydration] C --> D[Direct Pointer Access] E[Traditional Loading] --> F[malloc + memcpy] F --> G[Multiple Allocations] G --> H[Cache Misses] style A fill:#e8f5e8 style B fill:#e8f5e8 style C fill:#e8f5e8 style D fill:#e8f5e8 style E fill:#ffebee style F fill:#ffebee style G fill:#ffebee style H fill:#ffebee ``` #### 3. Cryptographic Integrity by Design BLAKE3 Merkle trees provide tamper-evident verification at every level: ```mermaid graph TD A[File Header<br/>BLAKE3 Root Hash] --> B[Hash Tree Root<br/>Chunk Index 0] B --> C[Branch Node<br/>Protects Chunks 0-7] B --> D[Branch Node<br/>Protects Chunks 8-15] C --> E[Leaf: Texture Data<br/>Chunk 0] C --> F[Leaf: Mesh Data<br/>Chunk 1] C --> G[Leaf: Audio Data<br/>Chunk 2] C --> H[Leaf: Script Data<br/>Chunk 3] D --> I[Leaf: Config Data<br/>Chunk 8] D --> J[Leaf: Font Data<br/>Chunk 9] D --> K[Leaf: Animation Data<br/>Chunk 10] D --> L[Leaf: Shader Data<br/>Chunk 11] style A fill:#ff6b6b style B fill:#4ecdc4 style C fill:#45b7d1 style D fill:#45b7d1 style E fill:#96ceb4 style F fill:#96ceb4 style G fill:#96ceb4 style H fill:#96ceb4 style I fill:#96ceb4 style J fill:#96ceb4 style K fill:#96ceb4 style L fill:#96ceb4 ``` ### Technical Specifications | Feature | Specification | |---------|---------------| | **File Size Support** | Up to 1 TB using C23 `_BitInt(40)` offsets | | **Load Performance** | <100ms for 1GB bundles on 8-core systems | | **Task Latency** | P99 <1ms for individual operations | | **Memory Efficiency** | Arena allocation ≤1.2× total data size | | **Integrity** | BLAKE3 Merkle trees + per-chunk CRC32 | | **Compression** | zstd with dictionary training + content-aware optimization | | **Platforms** | Linux, macOS, Windows, FreeBSD, Android, iOS | | **Architectures** | x86_64, ARM64, i386, RISC-V | | **Compilers** | Clang 15+, GCC 13+, MSVC 2022 17.5+, ICC 2024+ | ### Business Impact #### For Game Developers - **95% reduction** in asset loading times through zero-copy architecture - **Unified pipeline** eliminating format-specific tools and workflows - **Built-in hot-reload** enabling live development without restarts - **Cryptographic verification** ensuring asset integrity in production - **Automatic optimization** reducing manual performance tuning #### For Engine Developers - **Single integration point** replacing dozens of format-specific loaders - **Native graph processing** enabling advanced dependency management - **Predictable performance** through arena allocation and prefetching - **Production-grade security** with cryptographic tamper detection - **Cross-platform consistency** eliminating platform-specific bugs #### For Content Creators - **Unified toolchain** with consistent interface across all asset types - **Visual dependency management** through graph visualization tools - **Automated optimization** with intelligent compression recommendations - **Version control friendly** with binary diff support - **Content delivery optimization** with CDN-aware chunking --- ## Architecture Overview ### System Architecture ```mermaid graph TB subgraph \"Application Layer\" A[Game Engine] B[Content Creation Tools] C[Asset Processors] D[Build Systems] end subgraph \"GRAPHITE Core APIs\" E[graphite_core.h<br/>Loading & Runtime Access] F[graphite_tooling.h<br/>Creation & Analysis] G[graphite_unity.h<br/>Unity Integration] H[graphite_unreal.h<br/>Unreal Integration] I[graphite_godot.h<br/>Godot Integration] J[graphite_web.h<br/>WebAssembly Support] end subgraph \"GRAPHITE Runtime Engine\" K[Memory Manager<br/>NUMA-aware arenas] L[I/O Subsystem<br/>Async loading & streaming] M[Integrity Engine<br/>BLAKE3 verification] N[Compression Engine<br/>zstd with dictionaries] O[Cache Manager<br/>Intelligent prefetching] P[Hot Reload System<br/>Live asset updates] end subgraph \"Platform Abstraction Layer\" Q[Linux<br/>io_uring, huge pages] R[Windows<br/>Overlapped I/O, IOCP] S[macOS<br/>Unified memory, Metal] T[FreeBSD<br/>kqueue, ZFS integration] U[Mobile<br/>Android, iOS optimizations] end subgraph \"Hardware Acceleration Layer\" V[x86_64<br/>SIMD CRC32, AVX512] W[ARM64<br/>Hardware CRC, NEON] X[i386<br/>Software fallbacks] Y[RISC-V<br/>Vector extensions] Z[GPU<br/>CUDA, OpenCL, Vulkan Compute] end A --> E B --> F C --> F D --> F A --> G A --> H A --> I E --> K F --> L G --> M H --> N I --> O J --> P K --> Q L --> R M --> S N --> T O --> U Q --> V R --> W S --> X T --> Y U --> Z ``` ### Data Flow Architecture ```mermaid sequenceDiagram participant App as Application participant Core as GRAPHITE Core participant IO as I/O Subsystem participant Mem as Memory Manager participant Int as Integrity Engine participant Cache as Cache Manager participant FS as File System App->>Core: graphite_open(\"bundle.graphite\") Core->>IO: mmap_file() IO->>FS: Memory map request FS-->>IO: Mapped memory region Core->>Int: verify_header() Int->>Int: Check magic, version, endianness Core->>Mem: calculate_arena_size() Mem->>Mem: Scan chunk table for totals Mem-->>Core: Arena size calculated Core->>Mem: allocate_arena() Mem->>FS: mmap arena (huge pages if available) FS-->>Mem: Arena allocated par Parallel Processing Core->>Int: verify_chunk_crcs() Core->>IO: decompress_chunks() Core->>Int: verify_hash_tree() Core->>Cache: setup_prefetching() end Core->>Mem: hydrate_pointers() Mem->>Mem: Convert offsets to pointers Core-->>App: Bundle ready for use loop Runtime Access App->>Core: graphite_get_node() Core->>Cache: check_cache() alt Cache Hit Cache-->>Core: Cached data else Cache Miss Core->>IO: async_load_chunk() IO-->>Core: Chunk data Core->>Cache: update_cache() end Core-->>App: Direct pointer access end ``` ### Memory Architecture ```mermaid graph TB subgraph \"Virtual Memory Space\" subgraph \"File Mapping (Read-Only)\" A[File Header<br/>128 bytes<br/>BLAKE3 root hash] B[Chunk Table<br/>24 bytes × N<br/>Offset/size pairs] C[Data Chunks<br/>Variable size<br/>Graphs, blobs, compressed data] end subgraph \"Arena (Read-Write)\" D[Node Pointer Tables<br/>8 bytes × nodes<br/>Hydrated graph references] E[Edge Descriptor Tables<br/>16 bytes × edges<br/>Relationship metadata] F[Property Tables<br/>8 bytes × props<br/>Key-value pairs] G[String Cache<br/>Interned strings<br/>Fast lookup table] H[Decompression Buffers<br/>Temporary storage<br/>zstd workspace] end subgraph \"Cache Layer\" I[L1 Cache<br/>Recently accessed<br/>Hot data] J[L2 Cache<br/>Prefetched data<br/>Predicted access] K[L3 Cache<br/>Background loaded<br/>Streaming data] end end A --> D B --> E C --> F D --> I E --> J F --> K style A fill:#f9f9f9 style B fill:#f9f9f9 style C fill:#f9f9f9 style D fill:#e1f5fe style E fill:#e1f5fe style F fill:#e1f5fe style G fill:#e1f5fe style H fill:#fff3e0 style I fill:#e8f5e8 style J fill:#e8f5e8 style K fill:#e8f5e8 ``` --- ## Core Principles & Design Philosophy ### 1. Universal Graph Abstraction The fundamental insight of GRAPHITE is that all asset system components can be elegantly represented as graphs. This provides unprecedented consistency and composability across the entire asset pipeline. #### Asset as Graph ```mermaid graph LR A[Asset Graph] --> B[Properties] B --> C[data_blob_id: 42] B --> D[mime_type: \"image/png\"] B --> E[size: 204800] B --> F[created: \"2025-06-28T10:30:00Z\"] B --> G[checksum: \"blake3:a1b2c3...\"] B --> H[compression: \"zstd:level5\"] ``` #### Collection as Graph ```mermaid graph TB A[UI Asset Collection] --> B[Button Sprites] A --> C[Icon Set] A --> D[Font Atlas] B --> E[button_normal.png] B --> F[button_hover.png] B --> G[button_pressed.png] C --> H[icon_settings.svg] C --> I[icon_home.svg] C --> J[icon_profile.svg] D --> K[ui_font_regular.ttf] D --> L[ui_font_bold.ttf] style A fill:#ff6b6b style B fill:#4ecdc4 style C fill:#4ecdc4 style D fill:#4ecdc4 ``` #### Transform as Graph ```mermaid graph LR subgraph \"Input Subgraph\" A[main.scss] B[_variables.scss] C[_mixins.scss] B --> A C --> A end subgraph \"Transform Pipeline\" D[SCSS Parser<br/>Properties: syntax=\"scss\"] E[Import Resolver<br/>Properties: search_paths=[...]] F[CSS Compiler<br/>Properties: target=\"es5\"] G[Autoprefixer<br/>Properties: browsers=[\">1%\"]] H[Minifier<br/>Properties: preserve_comments=false] D --> E E --> F F --> G G --> H end subgraph \"Output Subgraph\" I[main.css] J[main.min.css] K[main.css.map] I --> J I --> K end A --> D H --> I style A fill:#96ceb4 style I fill:#feca57 ``` ### 2. Recursive Composition Without Limits Graphs can contain other graphs at arbitrary depth, enabling natural hierarchical organization that mirrors real-world asset relationships: ```mermaid graph TB subgraph \"Level 0: Game Bundle\" A[Complete Game Asset Bundle] end subgraph \"Level 1: Category Graphs\" A --> B[Level Assets] A --> C[Character Assets] A --> D[Audio Assets] A --> E[UI Assets] end subgraph \"Level 2: Collection Graphs\" B --> F[Level 1 Terrain] B --> G[Level 1 Props] C --> H[Player Character] C --> I[NPC Collection] D --> J[Music Tracks] D --> K[Sound Effects] end subgraph \"Level 3: Asset Instance Graphs\" F --> L[heightmap.raw] F --> M[terrain_diffuse.png] F --> N[terrain_normal.png] H --> O[player_mesh.obj] H --> P[player_textures.png] H --> Q[player_animations.fbx] end subgraph \"Level 4: Component Graphs\" Q --> R[walk_cycle] Q --> S[idle_animation] Q --> T[jump_animation] P --> U[diffuse_map] P --> V[normal_map] P --> W[specular_map] end ``` ### 3. Zero-Copy Performance Philosophy Performance is not an afterthought but a core architectural principle. Every design decision is evaluated through the lens of memory efficiency and runtime speed: ```mermaid graph LR A[File on Disk] --> B[Memory Mapping<br/>OS handles I/O] B --> C[Chunk Table Scan<br/>O(1) access pattern] C --> D[Arena Allocation<br/>Single large allocation] D --> E[Pointer Hydration<br/>One-time offset→pointer] E --> F[Runtime Ready<br/>Direct memory access] G[Traditional Approach] --> H[fopen + malloc<br/>Multiple allocations] H --> I[fread loops<br/>Copy operations] I --> J[Format parsing<br/>String processing] J --> K[Object construction<br/>Scattered allocations] K --> L[Runtime Overhead<br/>Pointer chasing] style A fill:#e8f5e8 style B fill:#e8f5e8 style C fill:#e8f5e8 style D fill:#e8f5e8 style E fill:#e8f5e8 style F fill:#e8f5e8 style G fill:#ffebee style H fill:#ffebee style I fill:#ffebee style J fill:#ffebee style K fill:#ffebee style L fill:#ffebee ``` ### 4. Security as a Foundation Security is built into the format at the foundational level, not bolted on as an afterthought: ```mermaid graph TB A[Content Creation] --> B[BLAKE3 Hash Computation] B --> C[Merkle Tree Construction] C --> D[Root Hash Embedding] D --> E[Bundle Creation] F[Content Loading] --> G[Extract Root Hash] G --> H[Reconstruct Merkle Tree] H --> I{Verification} I -->|Success| J[Continue Loading] I -->|Failure| K[Abort with Evidence] L[Tamper Attempt] --> M[Modify Content] M --> N[Hash Mismatch] N --> O[Immediate Detection] style A fill:#96ceb4 style E fill:#96ceb4 style F fill:#96ceb4 style J fill:#96ceb4 style K fill:#ff6b6b style L fill:#ff6b6b style M fill:#ff6b6b style N fill:#ff6b6b style O fill:#ff6b6b ``` ### 5. Adaptive Intelligence GRAPHITE learns and adapts to usage patterns, optimizing itself automatically: ```mermaid graph TD A[Access Pattern Analysis] --> B[Hot Data Identification] B --> C[Predictive Prefetching] C --> D[Cache Optimization] E[Compression Analysis] --> F[Content Type Detection] F --> G[Algorithm Selection] G --> H[Dictionary Training] I[Performance Monitoring] --> J[Bottleneck Detection] J --> K[Automatic Tuning] K --> L[Configuration Updates] D --> M[Improved Performance] H --> M L --> M M --> A M --> E M --> I ``` --- ## Binary Format Specification ### File Structure Overview GRAPHITE files use a carefully designed binary layout optimized for memory mapping and efficient access: ``` ┌─────────────────────────────────┐ Offset 0x00 │ File Header 128 bytes │ ← Fixed size, 64-byte aligned ├─────────────────────────────────┤ Offset 0x80 │ Chunk Table #chunks × 24 B │ ← Array of fixed-width entries ├─────────────────────────────────┤ Variable offset │ Data Chunks Variable │ ← Graphs, blobs, compressed data │ ┌─────────────────────────────┐ │ │ │ Graph Chunks │ │ ← Node/edge tables + properties │ │ Blob Chunks │ │ ← Raw asset data │ │ Hash Tree Chunks │ │ ← BLAKE3 integrity tree │ │ String Pool Chunks │ │ ← Deduplicated strings │ │ Compressed Chunks │ │ ← zstd compressed data │ │ Dictionary Chunks │ │ ← Compression dictionaries │ └─────────────────────────────┘ │ └─────────────────────────────────┘ ``` ### File Header Specification The file header contains all essential metadata needed for loading and verification: ```c // All fields in little-endian byte order // Header is exactly 128 bytes for optimal alignment typedef struct { // Magic and version identification (8 bytes) char magic[4]; // \"GRPH\" (0x47525048) uint8_t version_major; // 0 (major version) uint8_t version_minor; // 1 (minor version) uint8_t endian_marker; // 0x01 (little-endian only) uint8_t header_flags; // Header-specific flags // File size and structure (16 bytes) uint64_t file_size; // Total file size in bytes uint64_t chunk_count; // Number of chunks in table // Critical chunk references (24 bytes) uint64_t root_graph_index; // Index of main graph chunk uint64_t string_pool_index; // Index of string pool chunk uint64_t integrity_root_index; // Index of hash tree root // File metadata (16 bytes) uint32_t file_flags; // File-level flags (see below) uint32_t compression_method; // Primary compression algorithm uint64_t creation_timestamp; // Unix timestamp of creation // Integrity and verification (32 bytes) uint8_t file_digest[32]; // BLAKE3 hash of entire file // (excluding this field) // Performance hints (16 bytes) uint32_t suggested_cache_size; // Recommended cache size uint32_t suggested_arena_size; // Recommended arena size uint32_t access_pattern_hint; // Expected access patterns uint32_t optimization_flags; // Performance optimization hints // Reserved for future expansion (16 bytes) uint8_t reserved[16]; // Must be zero } graphite_file_header; // Compile-time size verification static_assert(sizeof(graphite_file_header) == 128, \"File header must be exactly 128 bytes\"); ``` #### Header Flags Specification | Bit | Flag Name | Description | |-----|-----------|-------------| | 0 | `MANDATORY_INTEGRITY_CHECK` | Hash verification required for loading | | 1 | `COMPRESSED_CHUNKS_PRESENT` | File contains zstd compressed chunks | | 2 | `ENCRYPTED_CHUNKS_PRESENT` | File contains AES-GCM encrypted chunks | | 3 | `DICTIONARY_COMPRESSION` | Uses compression dictionaries | | 4 | `SIGNED_BUNDLE` | Contains cryptographic signature | | 5 | `STREAMING_OPTIMIZED` | Optimized for streaming access | | 6 | `NUMA_AWARE` | Contains NUMA optimization hints | | 7 | `GPU_ACCELERATION` | Contains GPU acceleration hints | | 8-15 | Reserved | Must be zero | | 16-31 | Vendor Extensions | Available for implementation-specific use | ### Chunk Table Specification Each chunk table entry provides precise location and metadata for data chunks: ```c typedef struct { // Offset and size using C23 _BitInt for exact precision _BitInt(40) offset; // File offset (5 bytes, supports 1TB) _BitInt(40) size; // Chunk size (5 bytes, supports 1TB) // Type and metadata (4 bytes) uint8_t kind; // Chunk type (see below) uint8_t flags; // Chunk flags (see below) uint16_t priority; // Loading priority hint // Integrity and performance (8 bytes) uint32_t crc32; // IEEE 802.3 CRC32 of chunk data uint32_t expected_load_time; // Expected load time in microseconds // Reserved for alignment (2 bytes) uint16_t reserved; // Padding for 8-byte alignment } chunk_table_entry; // Compile-time size verification static_assert(sizeof(chunk_table_entry) == 24, \"Chunk table entry must be exactly 24 bytes\"); ``` #### Chunk Types | Kind | Type | Structure | Description | |------|------|-----------|-------------| | 0 | `CHUNK_BLOB` | Raw binary data | Images, audio, arbitrary binary content | | 1 | `CHUNK_GRAPH` | Graph structure | Node/edge/property tables with graph header | | 2 | `CHUNK_HASH_LEAF` | Hash leaf node | Points to data chunk with BLAKE3 digest | | 3 | `CHUNK_HASH_BRANCH` | Hash branch node | Contains child hash references | | 4 | `CHUNK_STRING_POOL` | String storage | UTF-8 strings with deduplication | | 5 | `CHUNK_DICTIONARY` | Compression dict | zstd compression dictionary | | 6 | `CHUNK_METADATA` | Bundle metadata | Author, version, build info | | 7 | `CHUNK_TRANSFORM` | Transform definition | Asset processing pipeline | | 8-15 | Reserved | Future use | Reserved for format extensions | | 16-255 | Vendor | Implementation-specific | Available for custom chunk types | #### Chunk Flags | Bit | Flag Name | Description | |-----|-----------|-------------| | 0 | `ZSTD_COMPRESSED` | Chunk data is zstd compressed | | 1 | `AES_ENCRYPTED` | Chunk data is AES-GCM encrypted | | 2 | `DICTIONARY_COMPRESSED` | Uses compression dictionary | | 3 | `INTEGRITY_CRITICAL` | Integrity failure aborts entire load | | 4 | `CACHE_HINT` | Should be cached in memory | | 5 | `STREAM_HINT` | Suitable for streaming | | 6 | `GPU_ACCESSIBLE` | Can be accessed from GPU | | 7 | `NUMA_LOCAL` | Should be allocated on local NUMA node | ### Graph Chunk Structure Graph chunks contain the core graph data structures with optimized layout: ```c // Graph chunk header (64 bytes, 64-byte aligned for cache efficiency) typedef struct { // Counts and basic metadata (16 bytes) uint32_t node_count; // Number of child graphs uint32_t edge_count; // Number of relationships uint32_t property_count; // Number of key-value properties uint32_t graph_flags; // Graph-specific flags // Table offsets from start of chunk (32 bytes) uint64_t node_table_offset; // Offset to node index table uint64_t edge_table_offset; // Offset to edge descriptor table uint64_t property_table_offset; // Offset to property table uint64_t metadata_offset; // Offset to graph metadata // Performance and optimization hints (16 bytes) uint32_t estimated_access_frequency; // Expected access frequency uint32_t suggested_prefetch_count; // Number of nodes to prefetch uint32_t parallel_execution_hint; // Parallelization suggestions uint32_t cache_locality_hint; // Cache optimization hints } graph_chunk_header; // Compile-time size verification static_assert(sizeof(graph_chunk_header) == 64, \"Graph chunk header must be exactly 64 bytes\"); ``` #### Graph Flags | Bit | Flag Name | Description | |-----|-----------|-------------| | 0 | `HAS_CYCLES` | Graph contains circular references | | 1 | `PARALLEL_GROUP` | Child nodes can execute concurrently | | 2 | `STRING_POOL` | Graph represents string pool | | 3 | `READONLY` | Graph should not be modified | | 4 | `SORTED_NODES` | Nodes are sorted by some criterion | | 5 | `SORTED_EDGES` | Edges are sorted by some criterion | | 6 | `COMPRESSED_PROPERTIES` | Properties use compression | | 7 | `CACHED_METADATA` | Metadata is cached for performance | | 8-15 | Optimization Hints | Implementation-specific optimization flags | | 16-31 | Vendor Extensions | Available for custom use | ### Advanced Chunk Types #### String Pool Chunk Format ```c typedef struct { graph_chunk_header header; // Standard graph header // String pool specific metadata uint32_t total_string_bytes; // Total bytes of string data uint32_t average_string_length; // Average string length uint32_t hash_table_size; // Size of hash table for lookups uint32_t deduplication_ratio; // Space saved by deduplication (basis points) // Offset to string data sections uint64_t string_data_offset; // Offset to raw string data uint64_t hash_table_offset; // Offset to lookup hash table uint64_t index_table_offset; // Offset to string index table } string_pool_chunk; ``` #### Dictionary Chunk Format ```c typedef struct { uint32_t dictionary_size; // Size of dictionary data uint32_t algorithm_version; // zstd version used for training uint32_t training_sample_count; // Number of samples used for training uint32_t effective_compression_ratio; // Achieved compression improvement // Dictionary training metadata uint64_t training_timestamp; // When dictionary was trained uint32_t target_chunk_types; // Chunk types this dictionary targets uint32_t reserved; // Future use // Dictionary data follows immediately uint8_t dictionary_data[]; // Raw zstd dictionary } dictionary_chunk; ``` --- ## Graph Model & Data Structures ### Theoretical Foundation GRAPHITE's graph model is based on formal graph theory but extended with practical considerations for asset management: **Definition**: A GRAPHITE graph G is defined as G = (V, E, P, M) where: - **V** = set of vertices (nodes), each referencing another graph or asset - **E** = set of edges (relationships), each containing semantic metadata - **P** = set of properties (key-value pairs with typed values) - **M** = metadata (graph-level information and optimization hints) ### Core Graph Types #### 1. Asset Graphs (Leaf Nodes) Asset graphs represent individual files or data blobs with no child nodes: ```c // Asset graph structure (specialized graph with no children) typedef struct { graph_chunk_header header; // node_count = 0, edge_count = 0 property_table properties; // Asset metadata and references // No node or edge tables } asset_graph; // Standard asset properties static const char* ASSET_PROPERTIES[] = { \"data_blob_id\", // Chunk index of actual data \"mime_type\", // Content type (image/png, etc.) \"original_size\", // Size before compression \"compressed_size\", // Size after compression \"checksum_blake3\", // BLAKE3 content hash \"checksum_crc32\", // CRC32 content hash \"created_timestamp\", // Creation time (ISO 8601) \"modified_timestamp\", // Last modification time \"creator_tool\", // Tool that created this asset \"creator_version\", // Version of creator tool \"processing_pipeline\", // Reference to transform graph \"quality_settings\", // Quality/compression settings \"target_platforms\", // Intended target platforms \"usage_frequency\", // Expected access frequency hint \"cache_priority\", // Caching priority hint NULL }; ``` Example asset graph for a texture: ```mermaid graph LR A[Texture Asset Graph] --> B[Properties] B --> C[data_blob_id: 42] B --> D[mime_type: \"image/png\"] B --> E[original_size: 2097152] B --> F[compressed_size: 524288] B --> G[checksum_blake3: \"a1b2c3d4...\"] B --> H[created_timestamp: \"2025-06-28T10:30:00Z\"] B --> I[creator_tool: \"Photoshop\"] B --> J[quality_settings: \"lossless\"] B --> K[target_platforms: [\"desktop\", \"mobile\"]] ``` #### 2. Collection Graphs Collection graphs organize related assets with dependency relationships: ```mermaid graph TB A[UI Component Collection] --> B[Button Assets] A --> C[Icon Assets] A --> D[Font Assets] A --> E[Style Definitions] B --> F[button_normal.png] B --> G[button_hover.png] B --> H[button_pressed.png] B --> I[button_disabled.png] C --> J[icon_home.svg] C --> K[icon_settings.svg] C --> L[icon_profile.svg] D --> M[ui_font_regular.ttf] D --> N[ui_font_bold.ttf] E --> O[button_styles.css] E --> P[color_palette.json] % Dependency edges F -.-> O G -.-> O H -.-> O I -.-> O style A fill:#ff6b6b style B fill:#4ecdc4 style C fill:#4ecdc4 style D fill:#4ecdc4 style E fill:#4ecdc4 ``` #### 3. Transform Graphs Transform graphs represent complex processing pipelines with input/output relationships: ```mermaid graph LR subgraph \"SCSS to CSS Transform Graph\" subgraph \"Input Subgraph\" A[main.scss] B[_variables.scss] C[_mixins.scss] D[_components.scss] B --> A C --> A D --> A end subgraph \"Transform Pipeline\" E[SCSS Parser<br/>ast_generator] F[Import Resolver<br/>dependency_resolver] G[Variable Processor<br/>variable_substitution] H[Mixin Expander<br/>mixin_expansion] I[CSS Generator<br/>css_output] J[Autoprefixer<br/>vendor_prefixes] K[Minifier<br/>size_optimization] E --> F F --> G G --> H H --> I I --> J J --> K end subgraph \"Output Subgraph\" L[main.css] M[main.min.css] N[main.css.map] O[dependency_graph.json] L --> M L --> N L --> O end A --> E K --> L end style A fill:#96ceb4 style L fill:#feca57 style E fill:#74b9ff style F fill:#74b9ff style G fill:#74b9ff style H fill:#74b9ff style I fill:#74b9ff style J fill:#74b9ff style K fill:#74b9ff ``` #### 4. Bundle Graphs Bundle graphs represent complete asset packages with complex internal organization: ```mermaid graph TB subgraph \"Game Level Bundle\" A[Level 1 Assets] --> B[Environment] A --> C[Characters] A --> D[Audio] A --> E[Scripts] A --> F[Configuration] subgraph \"Environment Assets\" B --> G[Terrain System] B --> H[Lighting Data] B --> I[Props Collection] G --> J[heightmap.raw] G --> K[terrain_diffuse.dds] G --> L[terrain_normal.dds] G --> M[terrain_splat.dds] H --> N[lightmap_0.hdr] H --> O[lightmap_1.hdr] H --> P[light_probes.dat] I --> Q[tree_variants.fbx] I --> R[rock_collection.obj] I --> S[grass_billboard.png] end subgraph \"Character Assets\" C --> T[Player Character] C --> U[NPCs] T --> V[player_mesh.fbx] T --> W[player_textures.dds] T --> X[player_animations.fbx] T --> Y[player_audio.ogg] U --> Z[npc_meshes.fbx] U --> AA[npc_textures.dds] U --> BB[npc_ai_data.json] end % Dependency relationships V -.-> W V -.-> X T -.-> Y J -.-> K J -.-> L J -.-> M end style A fill:#ff6b6b style B fill:#4ecdc4 style C fill:#4ecdc4 style D fill:#4ecdc4 style E fill:#4ecdc4 style F fill:#4ecdc4 ``` ### Advanced Graph Structures #### 5. Parallel Execution Graphs These graphs indicate nodes that can be processed concurrently: ```c // Parallel group graph with execution hints typedef struct { graph_chunk_header header; // flags |= PARALLEL_GROUP node_index_table nodes; // Nodes that can execute in parallel edge_descriptor_table edges; // Dependencies between nodes property_table configuration; // Parallelization hints // Parallel execution metadata uint32_t max_parallel_degree; // Maximum parallelism uint32_t memory_requirements; // Total memory needed uint32_t cpu_intensive_nodes; // Number of CPU-heavy nodes uint32_t io_intensive_nodes; // Number of I/O-heavy nodes } parallel_group_graph; ``` ```mermaid graph TB subgraph \"Parallel Image Processing Pipeline\" A[Source Image] --> B[Resize Operation<br/>⚡ Parallel] A --> C[Format Conversion<br/>⚡ Parallel] A --> D[Compression<br/>⚡ Parallel] A --> E[Thumbnail Generation<br/>⚡ Parallel] A --> F[Metadata Extraction<br/>⚡ Parallel] B --> G[Quality Assessment] C --> G D --> G E --> G F --> G G --> H[Final Asset Package] end style B fill:#e8f5e8 style C fill:#e8f5e8 style D fill:#e8f5e8 style E fill:#e8f5e8 style F fill:#e8f5e8 style G fill:#feca57 style H fill:#ff6b6b ``` #### 6. Conditional Execution Graphs These graphs represent conditional logic and branching behavior: ```mermaid graph TD A[Source Asset] --> B{Platform Check} B -->|Desktop| C[High Quality Pipeline] B -->|Mobile| D[Mobile Optimization Pipeline] B -->|Web| E[Web Compression Pipeline] C --> F[4K Texture Generation] C --> G[High Poly Mesh] C --> H[Uncompressed Audio] D --> I[1K Texture Generation] D --> J[LOD Mesh Generation] D --> K[OGG Compression] E --> L[WebP Texture] E --> M[Simplified Mesh] E --> N[WebM Audio] F --> O[Desktop Asset Bundle] G --> O H --> O I --> P[Mobile Asset Bundle] J --> P K --> P L --> Q[Web Asset Bundle] M --> Q N --> Q style A fill:#96ceb4 style B fill:#74b9ff style O fill:#feca57 style P fill:#feca57 style Q fill:#feca57 ``` ### Edge Semantics and Relationships Edges in GRAPHITE are themselves graphs, allowing rich relationship modeling: #### Simple Dependency Edge ```c // Basic dependency relationship typedef struct { graph_chunk_header header; // node_count = 0, edge_count = 0 property_table properties; // Dependency metadata } dependency_edge; // Common dependency properties static const char* DEPENDENCY_PROPERTIES[] = { \"type\", // \"dependency\", \"import\", \"reference\" \"optional\", // \"true\" or \"false\" \"load_order\", // \"before\", \"after\", \"concurrent\" \"cache_policy\", // \"always\", \"conditional\", \"never\" \"version_constraint\", // Semantic version requirement \"platform_constraint\", // Platform-specific dependency \"feature_flag\", // Feature flag requirement \"performance_impact\", // Expected performance impact NULL }; ``` #### Complex Transform Edge ```c // Multi-step transformation edge with rich semantics typedef struct { graph_chunk_header header; // Complex internal structure node_index_table transform_steps; // Individual transformation steps edge_descriptor_table step_flow; // Dependencies between steps property_table configuration; // Transform parameters // Transform-specific metadata uint32_t estimated_duration_ms; // Expected processing time uint32_t memory_peak_mb; // Peak memory usage uint32_t cpu_intensity; // CPU usage intensity (0-100) uint32_t quality_loss; // Quality loss factor (0-100) } transform_pipeline_edge; ``` #### Conditional Logic Edge ```mermaid graph TB A[Source Node] --> B[Condition Evaluator] B --> C{Environment Check} C -->|development| D[Debug Transform] C -->|staging| E[Staging Transform] C -->|production| F[Production Transform] B --> G{Platform Check} G -->|windows| H[Windows-specific Processing] G -->|linux| I[Linux-specific Processing] G -->|macos| J[macOS-specific Processing] D --> K[Target Node] E --> K F --> K H --> K I --> K J --> K style B fill:#74b9ff style C fill:#fd79a8 style G fill:#fd79a8 style K fill:#00b894 ``` ### Property System The property system provides flexible, strongly-typed metadata storage: #### Property Types ```c typedef enum { PROPERTY_STRING, // String pool reference PROPERTY_INTEGER, // 64-bit signed integer PROPERTY_FLOAT, // 64-bit IEEE 754 float PROPERTY_BOOLEAN, // True/false value PROPERTY_TIMESTAMP, // Unix timestamp with nanoseconds PROPERTY_BLOB_REFERENCE, // Reference to blob chunk PROPERTY_GRAPH_REFERENCE, // Reference to graph chunk PROPERTY_ARRAY, // Array of other properties PROPERTY_OBJECT, // Nested property object PROPERTY_VERSION, // Semantic version string PROPERTY_UUID, // 128-bit UUID PROPERTY_COLOR, // RGBA color value PROPERTY_VECTOR2, // 2D vector (x, y) PROPERTY_VECTOR3, // 3D vector (x, y, z) PROPERTY_VECTOR4, // 4D vector (x, y, z, w) PROPERTY_MATRIX3, // 3x3 matrix PROPERTY_MATRIX4, // 4x4 matrix PROPERTY_QUATERNION, // Quaternion rotation PROPERTY_BOUNDING_BOX, // 3D bounding box PROPERTY_URL, // URL/URI reference PROPERTY_HASH, // Cryptographic hash } property_type; ``` #### Property Encoding ```c // Property entry in property table with efficient encoding typedef struct { uint32_t key_string_id; // String pool ID for key uint32_t value_type; // Property type from enum above uint64_t value_data; // Type-specific value data uint64_t extended_data; // Additional data for complex types } property_entry; // Complex property structures for arrays and objects typedef struct { uint32_t element_count; // Number of elements/fields uint32_t total_size_bytes; // Total size of all elements property_entry elements[]; // Array elements or object fields } complex_property; // Geometric types typedef struct { float x, y; } vector2_property; typedef struct { float x, y, z; } vector3_property; typedef struct { float x, y, z, w; } vector4_property; typedef struct { float m[9]; // 3x3 matrix in column-major order } matrix3_property; typedef struct { float m[16]; // 4x4 matrix in column-major order } matrix4_property; typedef struct { float x, y, z, w; // Quaternion (x, y, z, w) } quaternion_property; typedef struct { vector3_property min; // Minimum corner vector3_property max; // Maximum corner } bounding_box_property; ``` #### Reserved Property Keys Standard property keys with well-defined semantics: | Key | Type | Description | |-----|------|-------------| | `data_blob_id` | Integer | Chunk index containing asset data | | `mime_type` | String | MIME type of content | | `size` | Integer | Original uncompressed size | | `compressed_size` | Integer | Size after compression | | `checksum_blake3` | Hash | BLAKE3 content hash | | `checksum_crc32` | Integer | CRC32 content hash | | `created` | Timestamp | Creation time with nanosecond precision | | `modified` | Timestamp | Last modification time | | `version` | Version | Semantic version string | | `author` | String | Creator identification | | `license` | String | License information | | `copyright` | String | Copyright notice | | `dependencies` | Array | List of dependency specifications | | `platform_requirements` | Array | Required platform features | | `feature_flags` | Array | Required feature flags | | `compression_algorithm` | String | Compression method used | | `compression_ratio` | Float | Achieved compression ratio | | `compression_quality` | Integer | Quality setting used (0-100) | | `load_priority` | Integer | Loading priority hint (0-100) | | `cache_duration` | Integer | Cache duration in seconds | | `usage_frequency` | Float | Expected access frequency | | `memory_footprint` | Integer | Expected memory usage in bytes | | `gpu_memory_footprint` | Integer | Expected GPU memory usage | | `processing_time_hint` | Integer | Expected processing time in microseconds | | `quality_level` | Integer | Quality level (0-100) | | `lod_level` | Integer | Level of detail | | `target_platforms` | Array | Intended target platforms | | `feature_level` | String | Required feature level | | `shader_model` | String | Required shader model | | `texture_format` | String | Texture format specification | | `audio_format` | String | Audio format specification | | `video_format` | String | Video format specification | | `mesh_format` | String | Mesh format specification | | `animation_format` | String | Animation format specification | | `physics_properties` | Object | Physics simulation properties | | `render_properties` | Object | Rendering properties | | `audio_properties` | Object | Audio playback properties | | `transform` | Matrix4 | 4x4 transformation matrix | | `position` | Vector3 | 3D position | | `rotation` | Quaternion | Rotation quaternion | | `scale` | Vector3 | Scale factors | | `bounding_box` | BoundingBox | 3D bounding box | | `color` | Color | RGBA color value | | `uuid` | UUID | Unique identifier | | `url` | URL | External resource reference | | `tags` | Array | Searchable tags | | `categories` | Array | Asset categories | | `keywords` | Array | Search keywords | --- ## Integrity & Security System ### Comprehensive Security Architecture GRAPHITE implements a multi-layered security architecture designed to detect and prevent various types of attacks: ```mermaid graph TB subgraph \"Security Layers\" A[File Level Security<br/>BLAKE3 Root Hash] B[Chunk Level Security<br/>CRC32 Checksums] C[Content Level Security<br/>Individual Hash Leaves] D[Transport Level Security<br/>Optional AES-GCM] E[Access Level Security<br/>Permission Checks] F[Runtime Level Security<br/>Memory Protection] end subgraph \"Threat Detection\" G[Tamper Detection<br/>Hash Verification] H[Corruption Detection<br/>CRC Verification] I[Replay Attack Prevention<br/>Timestamp Validation] J[Format Attack Prevention<br/>Bounds Checking] K[DoS Attack Prevention<br/>Resource Limits] L[Memory Attack Prevention<br/>Safe Allocation] end A --> G B --> H C --> G D --> I E --> J F --> K F --> L style A fill:#ff6b6b style G fill:#00b894 ``` ### BLAKE3 Merkle Tree Implementation #### Hash Tree Structure and Design GRAPHITE uses BLAKE3 for its superior performance and security properties: ```mermaid graph TD A[BLAKE3 Root Hash<br/>Stored in File Header<br/>32 bytes] --> B[Branch Node L1<br/>Chunks 0-15<br/>Chunk Index 1] A --> C[Branch Node L1<br/>Chunks 16-31<br/>Chunk Index 2] B --> D[Branch Node L2<br/>Chunks 0-7<br/>Chunk Index 3] B --> E[Branch Node L2<br/>Chunks 8-15<br/>Chunk Index 4] C --> F[Branch Node L2<br/>Chunks 16-23<br/>Chunk Index 5] C --> G[Branch Node L2<br/>Chunks 24-31<br/>Chunk Index 6] D --> H[Leaf Node<br/>Texture Data<br/>Chunk 0] D --> I[Leaf Node<br/>Mesh Data<br/>Chunk 1] D --> J[Leaf Node<br/>Audio Data<br/>Chunk 2] D --> K[Leaf Node<br/>Script Data<br/>Chunk 3] E --> L[Leaf Node<br/>Config Data<br/>Chunk 8] E --> M[Leaf Node<br/>Font Data<br/>Chunk 9] E --> N[Leaf Node<br/>Animation Data<br/>Chunk 10] E --> O[Leaf Node<br/>Shader Data<br/>Chunk 11] H --> P[Raw Chunk Data<br/>CRC32 Protected] I --> Q[Raw Chunk Data<br/>CRC32 Protected] J --> R[Raw Chunk Data<br/>CRC32 Protected] K --> S[Raw Chunk Data<br/>CRC32 Protected] style A fill:#e74c3c style B fill:#3498db style C fill:#3498db style D fill:#2ecc71 style E fill:#2ecc71 style F fill:#2ecc71 style G fill:#2ecc71 style H fill:#f39c12 style I fill:#f39c12 style J fill:#f39c12 style K fill:#f39c12 style L fill:#f39c12 style M fill:#f39c12 style N fill:#f39c12 style O fill:#f39c12 ``` #### Hash Node Structures ```c // Hash leaf chunk (protects individual data chunks) typedef struct { graph_chunk_header header; // node_count = 0, edge_count = 0 property_table properties; // Hash metadata // Hash leaf specific data uint32_t target_chunk_index; // Index of protected chunk uint32_t hash_algorithm; // BLAKE3 = 1, reserved for future uint8_t computed_hash[32]; // BLAKE3 hash of target chunk uint64_t computation_timestamp; // When hash was computed uint32_t verification_flags; // Verification requirements uint32_t reserved; // Future expansion } hash_leaf_chunk; // Hash branch chunk (combines child hashes) typedef struct { graph_chunk_header header; // Contains child hash references node_index_table child_hashes; // References to child hash chunks edge_descriptor_table hash_tree; // Tree structure relationships property_table branch_metadata; // Branch-specific properties // Branch specific data uint32_t fanout_factor; // Number of children (2-32) uint32_t tree_depth; // Depth in overall tree uint8_t computed_hash[32]; // BLAKE3 hash of concatenated children uint64_t computation_timestamp; // When hash was computed uint32_t child_verification_mask; // Which children require verification uint32_t reserved; // Future expansion } hash_branch_chunk; ``` #### Advanced Verification Algorithms ```c // Comprehensive verification with detailed error reporting typedef enum { VERIFICATION_SUCCESS, // All hashes verified successfully VERIFICATION_FILE_CORRUPTED, // File-level corruption detected VERIFICATION_CHUNK_CORRUPTED, // Specific chunk corruption VERIFICATION_TAMPER_DETECTED, // Deliberate modification detected VERIFICATION_MISSING_HASH, // Required hash not found VERIFICATION_ALGORITHM_UNKNOWN, // Unsupported hash algorithm VERIFICATION_TIMEOUT, // Verification took too long VERIFICATION_MEMORY_ERROR, // Memory allocation failed VERIFICATION_IO_ERROR, // I/O error during verification VERIFICATION_PARTIAL_FAILURE, // Some chunks failed verification } verification_result; // Detailed verification context typedef struct { verification_result result; // Overall result uint32_t chunks_verified; // Number of chunks verified uint32_t chunks_failed; // Number of chunks that failed uint32_t* failed_chunk_indices; // Indices of failed chunks uint64_t verification_time_ns; // Time taken for verification const char* error_message; // Human-readable error description // Detailed failure information struct { uint32_t chunk_index; // Which chunk failed verification_result reason; // Why it failed uint8_t expected_hash[32]; // Expected hash value uint8_t computed_hash[32]; // Computed hash value } *failure_details; uint32_t failure_count; // Number of detailed failures } verification_context; // High-performance parallel verification verification_context* verify_bundle_integrity_parallel( const graphite_bundle* bundle, uint32_t thread_count, bool fail_fast ) { verification_context* ctx = allocate_verification_context(); // Step 1: Verify file header and basic structure if (!verify_file_header(bundle)) { ctx->result = VERIFICATION_FILE_CORRUPTED; ctx->error_message = \"File header is corrupted or invalid\"; return ctx; } // Step 2: Verify chunk table integrity if (!verify_chunk_table(bundle)) { ctx->result = VERIFICATION_FILE_CORRUPTED; ctx->error_message = \"Chunk table is corrupted\"; return ctx; } // Step 3: Parallel chunk verification thread_pool* pool = create_verification_thread_pool(thread_count); atomic_uint verified_count = 0; atomic_uint failed_count = 0; for (uint32_t i = 0; i < bundle->header.chunk_count; i++) { verification_task* task = create_verification_task(bundle, i, ctx); submit_verification_task(pool, task); if (fail_fast && atomic_load(&failed_count) > 0) { cancel_remaining_tasks(pool); break; } } wait_for_verification_completion(pool); // Step 4: Verify hash tree if present if (bundle->header.integrity_root_index != 0) { verification_result tree_result = verify_hash_tree_parallel( bundle, pool, ctx); if (tree_result != VERIFICATION_SUCCESS) { ctx->result = tree_result; } } // Step 5: Final verification of root hash if (ctx->result == VERIFICATION_SUCCESS) { uint8_t computed_file_hash[32]; if (!compute_file_hash_excluding_header(bundle, computed_file_hash)) { ctx->result = VERIFICATION_IO_ERROR; ctx->error_message = \"Failed to compute file hash\"; } else if (memcmp(computed_file_hash, bundle->header.file_digest, 32) != 0) { ctx->result = VERIFICATION_TAMPER_DETECTED; ctx->error_message = \"File hash mismatch - tampering detected\"; } } destroy_thread_pool(pool); return ctx; } // Incremental verification for streaming scenarios typedef struct { const graphite_bundle* bundle; uint32_t next_chunk_to_verify; uint32_t chunks_verified; uint32_t chunks_failed; bool verification_complete; verification_result overall_result; } incremental_verification_state; bool verify_next_chunk_batch( incremental_verification_state* state, uint32_t batch_size, uint32_t timeout_ms ) { auto start_time = high_resolution_clock::now(); uint32_t verified_in_batch = 0; while (verified_in_batch < batch_size && state->next_chunk_to_verify < state->bundle->header.chunk_count) { // Check timeout auto current_time = high_resolution_clock::now(); auto elapsed = duration_cast<milliseconds>(current_time - start_time); if (elapsed.count() >= timeout_ms) { break; } // Verify next chunk bool chunk_valid = verify_single_chunk( state->bundle, state->next_chunk_to_verify); if (chunk_valid) { state->chunks_verified++; } else { state->chunks_failed++; if (state->overall_result == VERIFICATION_SUCCESS) { state->overall_result = VERIFICATION_CHUNK_CORRUPTED; } } state->next_chunk_to_verify++; verified_in_batch++; } // Check if verification is complete if (state->next_chunk_to_verify >= state->bundle->header.chunk_count) { state->verification_complete = true; // Verify root hash if all chunks passed if (state->overall_result == VERIFICATION_SUCCESS) { if (!verify_root_hash(state->bundle)) { state->overall_result = VERIFICATION_TAMPER_DETECTED; } } } return verified_in_batch > 0; } ``` ### Encryption Support #### AES-GCM Chunk Encryption For sensitive content, GRAPHITE supports AES-GCM encryption at the chunk level: ```c // Encrypted chunk header typedef struct { uint32_t encryption_algorithm; // AES_GCM_256 = 1 uint32_t key_derivation_method; // PBKDF2 = 1, SCRYPT = 2, ARGON2 = 3 uint8_t initialization_vector[16]; // Random IV for this chunk uint8_t authentication_tag[16]; // GCM authentication tag uint32_t encrypted_size; // Size of encrypted payload uint32_t salt_size; // Size of key derivation salt uint8_t salt[]; // Key derivation salt (variable length) uint8_t encrypted_data[]; // AES-GCM encrypted content } encrypted_chunk_header; // Encryption context for bundle creation typedef struct { uint8_t master_key[32]; // AES-256 master key uint32_t key_iterations; // PBKDF2/SCRYPT iteration count uint32_t memory_cost; // SCRYPT/ARGON2 memory cost uint32_t parallelism; // ARGON2 parallelism factor uint8_t salt[32]; // Random salt for key derivation bool per_chunk_iv; // Use unique IV per chunk bool compress_before_encrypt; // Compress then encrypt } encryption_context; // Key derivation functions bool derive_chunk_key( const encryption_context* ctx, uint32_t chunk_index, uint8_t* derived_key ) { uint8_t chunk_salt[32]; // Create chunk-specific salt memcpy(chunk_salt, ctx->salt, 32); chunk_salt[0] ^= (chunk_index >> 24) & 0xFF; chunk_salt[1] ^= (chunk_index >> 16) & 0xFF; chunk_salt[2] ^= (chunk_index >> 8) & 0xFF; chunk_salt[3] ^= chunk_index & 0xFF; switch (ctx->key_derivation_method) { case KEY_DERIVATION_PBKDF2: return pbkdf2_sha256( ctx->master_key, 32, chunk_salt, 32, ctx->key_iterations, derived_key, 32 ); case KEY_DERIVATION_SCRYPT: return scrypt( ctx->master_key, 32, chunk_salt, 32, ctx->key_iterations, ctx->memory_cost, 1, // parallelism derived_key, 32 ); case KEY_DERIVATION_ARGON2: return argon2id_hash_raw( ctx->key_iterations, ctx->memory_cost, ctx->parallelism, ctx->master_key, 32, chunk_salt, 32, derived_key, 32 ); default: return false; } } ``` ### Security Threat Mitigation Matrix | Attack Vector | Threat Level | Mitigation Strategy | Implementation | |---------------|--------------|---------------------|----------------| | **File Tampering** | High | BLAKE3 Merkle Tree | Root hash verification + recursive tree validation | | **Bit Rot/Corruption** | Medium | CRC32 per chunk | Hardware CRC32 when available, parallel verification | | **Replay Attacks** | Medium | Timestamp validation | Creation timestamp in header, optional expiration | | **Format String Attacks** | Low | No dynamic formats | All format strings are compile-time constants | | **Buffer Overflows** | High | Bounds checking | All offsets validated against file size limits | | **Integer Overflows** | Medium | Safe arithmetic | Checked arithmetic for all size calculations | | **Memory Corruption** | High | Arena allocation | Isolated allocation patterns, guard pages | | **Decompression Bombs** | Medium | Size limits | Maximum expansion ratio enforcement | | **Hash Collisions** | Low | BLAKE3 | Cryptographically secure hash function | | **Resource Exhaustion** | Medium | Resource quotas | Arena size limits, timeout protection | | **Side Channel** | Low | Constant time ops | Timing-attack resistant comparisons | | **Supply Chain** | High | Signature verification | Optional cryptographic signatures | ### Advanced Security Features #### Signature Verification ```c // Digital signature support for bundle authenticity typedef struct { uint32_t signature_algorithm; // ED25519 = 1, RSA_PSS = 2 uint32_t signature_size; // Size of signature data uint8_t public_key[32]; // Public key for verification uint8_t signature[]; // Digital signature of bundle hash } signature_chunk; bool verify_bundle_signature( const graphite_bundle* bundle, const uint8_t* trusted_public_key ) { // Find signature chunk signature_chunk* sig = find_signature_chunk(bundle); if (!sig) { return false; // No signature present } // Verify public key matches trusted key if (memcmp(sig->public_key, trusted_public_key, 32) != 0) { return false; // Untrusted public key } // Verify signature switch (sig->signature_algorithm) { case SIGNATURE_ED25519: return ed25519_verify( sig->signature, bundle->header.file_digest, 32, sig->public_key ); case SIGNATURE_RSA_PSS: return rsa_pss_verify( sig->signature, sig->signature_size, bundle->header.file_digest, 32, sig->public_key ); default: return false; // Unknown algorithm } } ``` #### Audit Trail Support ```c // Optional audit trail for tracking bundle access typedef struct { uint64_t access_timestamp; // When bundle was accessed uint8_t accessor_id[16]; // UUID of accessing entity uint32_t access_type; // READ = 1, VERIFY = 2, MODIFY = 3 uint32_t chunk_count_accessed; // Number of chunks accessed uint8_t access_hash[32]; // Hash of access pattern } audit_entry; void record_bundle_access( graphite_bundle* bundle, const uint8_t* accessor_id, uint32_t access_type ) { if (!bundle->audit_enabled) { return; } audit_entry entry = { .access_timestamp = get_unix_timestamp_ns(), .access_type = access_type, .chunk_count_accessed = bundle->chunks_accessed_this_session }; memcpy(entry.accessor_id, accessor_id, 16); // Compute hash of access pattern blake3_hash( &bundle->access_pattern, sizeof(bundle->access_pattern), entry.access_hash ); append_audit_entry(bundle, &entry); } ``` --- ## Compression & Optimization ### Advanced Compression Architecture GRAPHITE implements a sophisticated compression system that adapts to content types and usage patterns: ```mermaid graph TB subgraph \"Compression Decision Engine\" A[Content Analysis] --> B{Content Type} B -->|Text/JSON/Script| C[zstd Level 3-5] B -->|Binary/Media| D{Size Analysis} B -->|Already Compressed| E[No Compression] D -->|< 64KB| F[No Compression<br/>Header overhead] D -->|64KB - 1MB| G[zstd Level 5<br/>Balanced] D -->|1MB - 50MB| H[zstd Level 7<br/>Good compression] D -->|> 50MB| I{Update Frequency} I -->|Frequent| J[zstd Level 5<br/>Fast decompress] I -->|Rare| K[zstd Level 9<br/>Maximum compression] end subgraph \"Dictionary Training\" L[Collect Samples] --> M[Content Clustering] M --> N[Train Dictionaries] N --> O[Validate Effectiveness] O --> P[Store Best Dictionary] end subgraph \"Adaptive Optimization\" Q[Monitor Performance] --> R[Analyze Patterns] R --> S[Update Parameters] S --> T[Retrain Dictionaries] T --> Q end C --> L G --> L H --> L K --> L ``` ### Intelligent Content Analysis #### Content Type Detection and Classification ```c // Advanced content type detection with confidence scoring typedef enum { CONTENT_UNKNOWN, CONTENT_TEXT_PLAIN, CONTENT_TEXT_JSON, CONTENT_TEXT_XML, CONTENT_TEXT_YAML, CONTENT_TEXT_SCRIPT_JS, CONTENT_TEXT_SCRIPT_PY, CONTENT_TEXT_SCRIPT_SHADER, CONTENT_TEXT_CONFIG, CONTENT_IMAGE_PNG, CONTENT_IMAGE_JPEG, CONTENT_IMAGE_DDS, CONTENT_IMAGE_KTX, CONTENT_IMAGE_ASTC, CONTENT_AUDIO_WAV, CONTENT_AUDIO_OGG, CONTENT_AUDIO_MP3, CONTENT_AUDIO_FLAC, CONTENT_VIDEO_MP4, CONTENT_VIDEO_WEBM, CONTENT_MESH_OBJ, CONTENT_MESH_FBX, CONTENT_MESH_GLTF, CONTENT_ANIMATION_FBX, CONTENT_ANIMATION_GLTF, CONTENT_FONT_TTF, CONTENT_FONT_OTF, CONTENT_FONT_WOFF, CONTENT_ARCHIVE_ZIP, CONTENT_ARCHIVE_TAR, CONTENT_BINARY_EXECUTABLE, CONTENT_BINARY_LIBRARY, CONTENT_BINARY_UNKNOWN } content_type; typedef struct { content_type type; // Detected content type float confidence; // Confidence score (0.0-1.0) const char* mime_type; // MIME type string uint32_t magic_number_match; // Magic number match quality uint32_t filename_hint_weight; // Weight of filename hint uint32_t content_analysis_weight; // Weight of content analysis } content_detection_result; content_detection_result detect_content_type_advanced( const void* data, size_t size, const char* filename_hint ) { content_detection_result result = { .type = CONTENT_UNKNOWN, .confidence = 0.0f, .mime_type = \"application/octet-stream\" }; if (size == 0) { return result; } const uint8_t* bytes = (const uint8_t*)data; // Magic number detection with confidence scoring struct magic_signature { const uint8_t* signature; size_t signature_length; content_type type; const char* mime_type; float confidence_boost; } signatures[] = { {(uint8_t*)\"\\x89PNG\\r\ \\x1a\ \", 8, CONTENT_IMAGE_PNG, \"image/png\", 1.0f}, {(uint8_t*)\"\\xFF\\xD8\\xFF\", 3, CONTENT_IMAGE_JPEG, \"image/jpeg\", 0.9f}, {(uint8_t*)\"DDS \", 4, CONTENT_IMAGE_DDS, \"image/x-dds\", 1.0f}, {(uint8_t*)\"RIFF\", 4, CONTENT_AUDIO_WAV, \"audio/wav\", 0.8f}, // Could be other RIFF {(uint8_t*)\"OggS\", 4, CONTENT_AUDIO_OGG, \"audio/ogg\", 1.0f}, {(uint8_t*)\"ID3\", 3, CONTENT_AUDIO_MP3, \"audio/mpeg\", 0.9f}, {(uint8_t*)\"fLaC\", 4, CONTENT_AUDIO_FLAC, \"audio/flac\", 1.0f}, {(uint8_t*)\"\\x00\\x00\\x00\\x18ftypmp4\", 12, CONTENT_VIDEO_MP4, \"video/mp4\", 1.0f}, {(uint8_t*)\"\\x1a\\x45\\xdf\\xa3\", 4, CONTENT_VIDEO_WEBM, \"video/webm\", 1.0f}, {(uint8_t*)\"\\x00\\x01\\x00\\x00\", 4, CONTENT_FONT_TTF, \"font/ttf\", 0.8f}, {(uint8_t*)\"OTTO\", 4, CONTENT_FONT_OTF, \"font/otf\", 1.0f}, {(uint8_t*)\"wOFF\", 4, CONTENT_FONT_WOFF, \"font/woff\", 1.0f}, {(uint8_t*)\"PK\\x03\\x04\", 4, CONTENT_ARCHIVE_ZIP, \"application/zip\", 0.9f}, {(uint8_t*)\"ustar\", 5, CONTENT_ARCHIVE_TAR, \"application/x-tar\", 1.0f}, }; // Check magic numbers for (size_t i = 0; i < sizeof(signatures) / sizeof(signatures[0]); i++) { if (size >= signatures[i].signature_length && memcmp(bytes, signatures[i].signature, signatures[i].signature_length) == 0) { result.type = signatures[i].type; result.mime_type = signatures[i].mime_type; result.confidence = signatures[i].confidence_boost * 0.8f; result.magic_number_match = 100; break; } } // Filename hint analysis if (filename_hint && result.type == CONTENT_UNKNOWN) { struct filename_hint { const char* extension; content_type type; const char* mime_type; float confidence; } hints[] = { {\".json\", CONTENT_TEXT_JSON, \"application/json\", 0.9f}, {\".xml\", CONTENT_TEXT_XML, \"application/xml\", 0.9f}, {\".yaml\", CONTENT_TEXT_YAML, \"application/x-yaml\", 0.9f}, {\".yml\", CONTENT_TEXT_YAML, \"application/x-yaml\", 0.9f}, {\".js\", CONTENT_TEXT_SCRIPT_JS, \"application/javascript\", 0.8f}, {\".py\", CONTENT_TEXT_SCRIPT_PY, \"text/x-python\", 0.8f}, {\".glsl\", CONTENT_TEXT_SCRIPT_SHADER, \"text/x-glsl\", 0.9f}, {\".hlsl\", CONTENT_TEXT_SCRIPT_SHADER, \"text/x-hlsl\", 0.9f}, {\".cfg\", CONTENT_TEXT_CONFIG, \"text/plain\", 0.7f}, {\".ini\", CONTENT_TEXT_CONFIG, \"text/plain\", 0.7f}, {\".obj\", CONTENT_MESH_OBJ, \"model/obj\", 0.8f}, {\".fbx\", CONTENT_MESH_FBX, \"model/fbx\", 0.9f}, {\".gltf\", CONTENT_MESH_GLTF, \"model/gltf+json\", 0.9f}, {\".glb\", CONTENT_MESH_GLTF, \"model/gltf-binary\", 0.9f}, }; const char* ext = strrchr(filename_hint, '.'); if (ext) { for (size_t i = 0; i < sizeof(hints) / sizeof(hints[0]); i++) { if (strcasecmp(ext, hints[i].extension) == 0) { result.type = hints[i].type; result.mime_type = hints[i].mime_type; result.confidence = hints[i].confidence * 0.6f; result.filename_hint_weight = 60; break; } } } } // Content analysis for text-based formats if (result.type == CONTENT_UNKNOWN || result.confidence < 0.8f) { if (is_likely_text(data, min(size, 4096))) { // Analyze text content for specific formats if (bytes[0] == '{' || bytes[0] == '[') { if (is_valid_json_start(data, min(size, 1024))) { result.type = CONTENT_TEXT_JSON; result.mime_type = \"application/json\"; result.confidence = max(result.confidence, 0.7f); result.content_analysis_weight = 70; } } else if (memcmp(bytes, \"<?xml\", 5) == 0 || bytes[0] == '<') { result.type = CONTENT_TEXT_XML; result.mime_type = \"application/xml\"; result.confidence = max(result.confidence, 0.7f); result.content_analysis_weight = 70; } else { result.type = CONTENT_TEXT_PLAIN; result.mime_type = \"text/plain\"; result.confidence = max(result.confidence, 0.5f); result.content_analysis_weight = 50; } } } return result; } // Content entropy analysis for compression decisions typedef struct { double entropy; // Shannon entropy (0-8 bits) double compression_potential; // Estimated compression ratio uint32_t repeated_byte_count; // Number of repeated bytes uint32_t pattern_count; // Number of detected patterns bool already_compressed; // Appears to be already compressed } entropy_analysis; entropy_analysis analyze_content_entropy(const void* data, size_t size) { entropy_analysis analysis = {0}; if (size == 0) { return analysis; } const uint8_t* bytes = (const uint8_t*)data; // Calculate byte frequency distribution uint32_t frequency[256] = {0}; for (size_t i = 0; i < size; i++) { frequency[bytes[i]]++; } // Calculate Shannon entropy double entropy = 0.0; for (int i = 0; i < 256; i++) { if (frequency[i] > 0) { double p = (double)frequency[i] / size; entropy -= p * log2(p); } } analysis.entropy = entropy; // Estimate compression potential based on entropy if (entropy < 1.0) { analysis.compression_potential = 0.9; // Highly compressible } else if (entropy < 4.0) { analysis.compression_potential = 0.7; // Good compression } else if (entropy < 6.0) { analysis.compression_potential = 0.5; // Moderate compression } else if (entropy < 7.0) { analysis.compression_potential = 0.3; // Low compression } else { analysis.compression_potential = 0.1; // Likely already compressed analysis.already_compressed = true; } // Count repeated bytes (simple pattern detection) uint32_t repeated = 0; for (size_t i = 1; i < size; i++) { if (bytes[i] == bytes[i-1]) { repeated++; } } analysis.repeated_byte_count = repeated; // Simple pattern detection (2-byte, 4-byte patterns) uint32_t patterns = 0; for (size_t i = 0; i < size - 4; i += 4) { uint32_t pattern = *(uint32_t*)(bytes + i); for (size_t j = i + 4; j < size - 4; j += 4) { if (*(uint32_t*)(bytes + j) == pattern) { patterns++; break; } } } analysis.pattern_count = patterns; return analysis; } ``` ### Advanced zstd Integration #### Adaptive Compression Level Selection ```c // Comprehensive compression configuration typedef struct { int level; // zstd compression level (0-22) bool enable_dictionary; // Use dictionary compression size_t dictionary_size; // Maximum dictionary size size_t min_chunk_size; // Minimum size to attempt compression double min_compression_ratio; // Minimum compression ratio to keep uint32_t max_compression_time_ms; // Maximum time to spend compressing bool adaptive_level; // Automatically adjust level based on content bool parallel_compression; // Use multiple threads for large chunks uint32_t thread_count; // Number of compression threads } compression_config; // Compression decision matrix with machine learning typedef struct { content_type content_type; size_t size_range_min; size_t size_range_max; double entropy_min; double entropy_max; int recommended_level; bool use_dictionary; double expected_ratio; uint32_t expected_time_ms; } compression_rule; static const compression_rule COMPRESSION_RULES[] = { // Text content - high compression potential {CONTENT_TEXT_JSON, 1024, 1024*1024, 0.0, 6.0, 5, true, 0.3, 50}, {CONTENT_TEXT_XML, 1024, 1024*1024, 0.0, 6.0, 5, true, 0.4, 50}, {CONTENT_TEXT_SCRIPT_JS, 1024, 1024*1024, 0.0, 6.0, 6, true, 0.3, 75}, {CONTENT_TEXT_PLAIN, 1024, 1024*1024, 0.0, 6.0, 4, true, 0.5, 30}, // Binary content - variable compression {CONTENT_MESH_OBJ, 10*1024, 50*1024*1024, 0.0, 7.0, 7, false, 0.6, 200}, {CONTENT_MESH_FBX, 10*1024, 50*1024*1024, 0.0, 7.0, 6, false, 0.7, 150}, // Already compressed content - skip compression {CONTENT_IMAGE_JPEG, 0, SIZE_MAX, 7.0, 8.0, 0, false, 1.0, 0}, {CONTENT_IMAGE_PNG, 0, SIZE_MAX, 6.5, 8.0, 0, false, 1.0, 0}, {CONTENT_AUDIO_OGG, 0, SIZE_MAX, 7.0, 8.0, 0, false, 1.0, 0}, {CONTENT_AUDIO_MP3, 0, SIZE_MAX, 7.0, 8.0, 0, false, 1.0, 0}, // Large files - prefer speed {CONTENT_BINARY_UNKNOWN, 100*1024*1024, SIZE_MAX, 0.0, 8.0, 3, false, 0.8, 500}, // Small files - skip compression due to overhead {CONTENT_UNKNOWN, 0, 512, 0.0, 8.0, 0, false, 1.0, 0}, }; compression_config select_optimal_compression( const void* data, size_t size, content_detection_result content, entropy_analysis entropy ) { compression_config config = { .level = 5, // Default level .enable_dictionary = false, .dictionary_size = 64 * 1024, .min_chunk_size = 1024, .min_compression_ratio = 0.95, .max_compression_time_ms = 1000, .adaptive_level = true, .parallel_compression = size > 1024 * 1024, .thread_count = get_cpu_count() }; // Find matching rule for (size_t i = 0; i < sizeof(COMPRESSION_RULES) / sizeof(COMPRESSION_RULES[0]); i++) { const compression_rule* rule = &COMPRESSION_RULES[i]; if ((rule->content_type == content.type || rule->content_type == CONTENT_UNKNOWN) && size >= rule->size_range_min && size <= rule->size_range_max && entropy.entropy >= rule->entropy_min && entropy.entropy <= rule->entropy_max) { config.level = rule->recommended_level; config.enable_dictionary = rule->use_dictionary; config.min_compression_ratio = rule->expected_ratio; config.max_compression_time_ms = rule->expected_time_ms; break; } } // Adaptive adjustments based on entropy if (config.adaptive_level) { if (entropy.entropy < 2.0) { config.level = min(config.level + 2, 9); // Highly compressible } else if (entropy.entropy > 6.0) { config.level = max(config.level - 2, 1); // Low compressibility } } // Don't compress if already compressed if (entropy.already_compressed) { config.level = 0; config.enable_dictionary = false; } return config; } ``` #### Dictionary Training with Machine Learning ```c // Advanced dictionary training with content clustering typedef struct { void** samples; // Training sample data size_t* sample_sizes; // Size of each sample content_type* sample_types; // Content type of each sample size_t sample_count; // Number of samples size_t max_dict_size; // Maximum dictionary size uint32_t clustering_iterations; // K-means iterations for clustering float min_compression_improvement; // Minimum improvement required } advanced_training_set; typedef struct { uint8_t* dictionary_data; // Dictionary bytes size_t dictionary_size; // Dictionary size content_type target_type; // Target content type double improvement_ratio; // Compression improvement achieved uint32_t training_sample_count; // Number of samples used uint64_t training_time_ms; // Time spent training } trained_dictionary; // Cluster samples by content similarity typedef struct { uint32_t* sample_indices; // Indices of samples in this cluster uint32_t sample_count; // Number of samples in cluster content_type dominant_type; // Most common content type double average_entropy; // Average entropy of samples uint8_t representative_bytes[1024]; // Representative byte sequence } content_cluster; content_cluster* cluster_training_samples( const advanced_training_set* training, uint32_t target_cluster_count, uint32_t* actual_cluster_count ) { // Simple k-means clustering based on byte frequency distribution content_cluster* clusters = malloc(target_cluster_count * sizeof(content_cluster)); // Calculate byte frequency for each sample double** sample_frequencies = malloc(training->sample_count * sizeof(double*)); for (size_t i = 0; i < training->sample_count; i++) { sample_frequencies[i] = malloc(256 * sizeof(double)); // Calculate normalized byte frequency uint32_t frequency[256] = {0}; const uint8_t* data = (const uint8_t*)training->samples[i]; size_t size = training->sample_sizes[i]; for (size_t j = 0; j < size; j++) { frequency[data[j]]++; } for (int k = 0; k < 256; k++) { sample_frequencies[i][k] = (double)frequency[k] / size; } } // Initialize cluster centroids randomly double** centroids = malloc(target_cluster_count * sizeof(double*)); for (uint32_t i = 0; i < target_cluster_count; i++) { centroids[i] = malloc(256 * sizeof(double)); uint32_t seed_sample = rand() % training->sample_count; memcpy(centroids[i], sample_frequencies[seed_sample], 256 * sizeof(double)); } // K-means iterations uint32_t* assignments = malloc(training->sample_count * sizeof(uint32_t)); for (uint32_t iter = 0; iter < 50; iter++) { // Max 50 iterations bool changed = false; // Assign samples to nearest centroid for (size_t i = 0; i < training->sample_count; i++) { uint32_t best_cluster = 0; double best_distance = euclidean_distance( sample_frequencies[i], centroids[0], 256); for (uint32_t j = 1; j < target_cluster_count; j++) { double distance = euclidean_distance( sample_frequencies[i], centroids[j], 256); if (distance < best_distance) { best_distance = distance; best_cluster = j; } } if (assignments[i] != best_cluster) { assignments[i] = best_cluster; changed = true; } } if (!changed) break; // Update centroids for (uint32_t j = 0; j < target_cluster_count; j++) { memset(centroids[j], 0, 256 * sizeof(double)); uint32_t cluster_size = 0; for (size_t i = 0; i < training->sample_count; i++) { if (assignments[i] == j) { for (int k = 0; k < 256; k++) { centroids[j][k] += sample_frequencies[i][k]; } cluster_size++; } } if (cluster_size > 0) { for (int k = 0; k < 256; k++) { centroids[j][k] /= cluster_size; } } } } // Build cluster structures for (uint32_t i = 0; i < target_cluster_count; i++) { clusters[i].sample_indices = malloc(training->sample_count * sizeof(uint32_t)); clusters[i].sample_count = 0; for (size_t j = 0; j < training->sample_count; j++) { if (assignments[j] == i) { clusters[i].sample_indices[clusters[i].sample_count++] = j; } } // Determine dominant content type uint32_t type_counts[32] = {0}; // Assuming < 32 content types for (uint32_t j = 0; j < clusters[i].sample_count; j++) { uint32_t sample_idx = clusters[i].sample_indices[j]; if (training->sample_types[sample_idx] < 32) { type_counts[training->sample_types[sample_idx]]++; } } uint32_t max_count = 0; for (int j = 0; j < 32; j++) { if (type_counts[j] > max_count) { max_count = type_counts[j]; clusters[i].dominant_type = (content_type)j; } } } // Cleanup for (size_t i = 0; i < training->sample_count; i++) { free(sample_frequencies[i]); } free(sample_frequencies); for (uint32_t i = 0; i < target_cluster_count; i++) { free(centroids[i]); } free(centroids); free(assignments); *actual_cluster_count = target_cluster_count; return clusters; } // Train dictionaries for each cluster trained_dictionary* train_dictionaries_advanced( const advanced_training_set* training ) { uint32_t cluster_count; content_cluster* clusters = cluster_training_samples( training, min(8, (uint32_t)(training->sample_count / 100)), &cluster_count); trained_dictionary* dictionaries = malloc(cluster_count * sizeof(trained_dictionary)); for (uint32_t i = 0; i < cluster_count; i++) { if (clusters[i].sample_count < 5) { // Skip clusters with too few samples dictionaries[i].dictionary_data = NULL; continue; } // Collect samples for this cluster size_t total_training_size = 0; for (uint32_t j = 0; j < clusters[i].sample_count; j++) { uint32_t sample_idx = clusters[i].sample_indices[j]; total_training_size += training->sample_sizes[sample_idx]; } uint8_t* combined_data = malloc(total_training_size); size_t offset = 0; for (uint32_t j = 0; j < clusters[i].sample_count; j++) { uint32_t sample_idx = clusters[i].sample_indices[j]; memcpy(combined_data + offset, training->samples[sample_idx], training->sample_sizes[sample_idx]); offset += training->sample_sizes[sample_idx]; } // Train dictionary using zstd size_t dict_size = min(training->max_dict_size, total_training_size / 4); uint8_t* dict_buffer = malloc(dict_size); auto start_time = high_resolution_clock::now(); size_t actual_dict_size = ZDICT_trainFromBuffer( dict_buffer, dict_size, combined_data, total_training_size ); auto end_time = high_resolution_clock::now(); uint64_t training_time = duration_cast<milliseconds>( end_time - start_time).count(); if (ZDICT_isError(actual_dict_size)) { dictionaries[i].dictionary_data = NULL; free(dict_buffer); free(combined_data); continue; } // Test compression improvement double improvement = test_dictionary_effectiveness( dict_buffer, actual_dict_size, &clusters[i], training ); dictionaries[i].dictionary_data = dict_buffer; dictionaries[i].dictionary_size = actual_dict_size; dictionaries[i].target_type = clusters[i].dominant_type; dictionaries[i].improvement_ratio = improvement; dictionaries[i].training_sample_count = clusters[i].sample_count; dictionaries[i].training_time_ms = training_time; free(combined_data); } // Cleanup clusters for (uint32_t i = 0; i < cluster_count; i++) { free(clusters[i].sample_indices); } free(clusters); return dictionaries; } ``` ### Real-Time Compression Performance Monitoring ```c // Performance monitoring for compression decisions typedef struct { uint64_t total_bytes_compressed; uint64_t total_compression_time_ns; uint64_t total_decompression_time_ns; double average_compression_ratio; uint32_t compression_attempts; uint32_t compression_successes; uint32_t dictionary_hits; uint32_t dictionary_misses; // Performance by content type struct { content_type type; uint64_t bytes_processed; uint64_t compression_time_ns; double average_ratio; uint32_t attempts; } per_type_stats[32]; // Adaptive thresholds double current_cpu_usage; double target_cpu_usage; uint32_t current_memory_pressure; uint32_t target_memory_pressure; } compression_performance_monitor; void update_compression_performance( compression_performance_monitor* monitor, content_type type, size_t original_size, size_t compressed_size, uint64_t compression_time_ns, bool used_dictionary ) { monitor->total_bytes_compressed += original_size; monitor->total_compression_time_ns += compression_time_ns; monitor->compression_attempts++; if (compressed_size < original_size) { monitor->compression_successes++; double ratio = (double)compressed_size / original_size; monitor->average_compression_ratio = (monitor->average_compression_ratio * (monitor->compression_successes - 1) + ratio) / monitor->compression_successes; } if (used_dictionary) { monitor->dictionary_hits++; } else { monitor->dictionary_misses++; } // Update per-type statistics for (int i = 0; i < 32; i++) { if (monitor->per_type_stats[i].type == type || monitor->per_type_stats[i].type == CONTENT_UNKNOWN) { if (monitor->per_type_stats[i].type == CONTENT_UNKNOWN) { monitor->per_type_stats[i].type = type; } monitor->per_type_stats[i].bytes_processed += original_size; monitor->per_type_stats[i].compression_time_ns += compression_time_ns; monitor->per_type_stats[i].attempts++; if (compressed_size < original_size) { double ratio = (double)compressed_size / original_size; monitor->per_type_stats[i].average_ratio = (monitor->per_type_stats[i].average_ratio * (monitor->per_type_stats[i].attempts - 1) + ratio) / monitor->per_type_stats[i].attempts; } break; } } } // Adaptive compression decision based on current performance bool should_compress_adaptive( compression_performance_monitor* monitor, content_type type, size_t size, double estimated_compression_time_ms ) { // Check CPU usage threshold if (monitor->current_cpu_usage > monitor->target_cpu_usage * 1.2) { return false; // Skip compression to reduce CPU load } // Check memory pressure if (monitor->current_memory_pressure > monitor->target_memory_pressure) { return size > 1024 * 1024; // Only compress large files } // Check historical performance for this content type for (int i = 0; i < 32; i++) { if (monitor->per_type_stats[i].type == type) { // If compression ratio is poor for this type, skip if (monitor->per_type_stats[i].average_ratio > 0.9) { return false; } // If compression is too slow for this type, skip small files double avg_time_per_mb = (double)monitor->per_type_stats[i].compression_time_ns / (monitor->per_type_stats[i].bytes_processed / (1024.0 * 1024.0)); if (avg_time_per_mb > 1000.0 * 1000.0 * 1000.0) { // > 1 second per MB return size > 10 * 1024 * 1024; // Only compress files > 10MB } break; } } return true; // Default to compress } ``` --- ## Performance Engineering ### High-Performance Memory Management GRAPHITE's performance philosophy centers on predictable, cache-friendly memory access patterns: ```mermaid graph TB subgraph \"Memory Hierarchy Optimization\" A[L1 Cache<br/>32-64KB<br/>Direct pointer access] --> B[L2 Cache<br/>256KB-8MB<br/>Smart prefetching] B --> C[L3 Cache<br/>8-64MB<br/>NUMA-aware allocation] C --> D[Main Memory<br/>GB-TB<br/>Huge pages + arena allocation] D --> E[Storage<br/>NVMe/SSD<br/>Async I/O + memory mapping] end subgraph \"Parallelization Strategy\" F[File I/O<br/>io_uring/Overlapped<br/>Parallel chunk loading] --> G[Decompression<br/>Per-chunk threads<br/>SIMD acceleration] G --> H[Verification<br/>Parallel hash tree<br/>Hardware CRC32] H --> I[Hydration<br/>Parallel pointer conversion<br/>Cache-line aligned] end subgraph \"Hardware Acceleration\" J[SIMD Instructions<br/>AVX512, NEON<br/>CRC32, BLAKE3] --> K[Hardware Prefetch<br/>Platform-specific hints<br/>Stride pattern detection] K --> L[GPU Compute<br/>CUDA, OpenCL, Vulkan<br/>Parallel verification] end A --> F B --> G C --> H D --> I E --> J ``` #### Advanced Arena Allocation ```c // High-performance arena allocator with NUMA awareness typedef struct { void* base_address; // Base address of arena size_t total_size; // Total arena size size_t used_size; // Currently used bytes size_t alignment; // Required alignment uint32_t numa_node; // NUMA node for allocation bool use_huge_pages; // Whether to use huge pages bool use_guard_pages; // Whether to use guard pages // Free block management struct free_block { size_t size; struct free_block* next; }* free_list; // Allocation tracking for debugging struct allocation_info { void* address; size_t size; const char* file; int line; uint64_t timestamp; }* allocations; uint32_t allocation_count; uint32_t max_allocations; // Performance counters uint64_t total_allocations; uint64_t total_deallocations; uint64_t bytes_allocated; uint64_t bytes_deallocated; uint64_t peak_usage; uint32_t fragmentation_events; } arena_allocator; // Calculate optimal arena size with advanced heuristics typedef struct { size_t node_pointers; // 8 bytes × total_nodes size_t edge_descriptors; // 16 bytes × total_edges size_t property_data; // Variable size based on types size_t string_cache; // Estimated string overhead size_t decompression_buffers; // Temporary decompression space size_t prefetch_buffers; // Prefetching working set size_t alignment_padding; // Cache line alignment size_t numa_overhead; // NUMA allocation overhead size_t guard_pages; // Debug guard pages size_t safety_buffer; // Emergency allocation space size_t total_arena_size; // Sum of all components // Performance predictions double predicted_cache_hit_ratio; uint32_t predicted_page_faults; uint64_t predicted_allocation_time_ns; } arena_sizing_analysis; arena_sizing_analysis calculate_optimal_arena_size( const graphite_bundle* bundle ) { arena_sizing_analysis analysis = {0}; // Scan all graph chunks to count totals and analyze complexity uint64_t total_nodes = 0; uint64_t total_edges = 0; uint64_t total_properties = 0; uint64_t max_graph_depth = 0; uint64_t total_string_bytes = 0; for (uint32_t i = 0; i < bundle->header.chunk_count; i++) { const chunk_table_entry* entry = get_chunk_entry(bundle, i); if (entry->kind == CHUNK_GRAPH) { const graph_chunk_header* graph = get_graph_header(bundle, i); total_nodes += graph->node_count; total_edges += graph->edge_count; total_properties += graph->property_count; // Estimate graph depth for cache locality analysis uint32_t depth = estimate_graph_depth(bundle, i); max_graph_depth = max(max_graph_depth, depth); } else if (entry->kind == CHUNK_STRING_POOL) { total_string_bytes += entry->size; } } // Base allocations analysis.node_pointers = total_nodes * sizeof(void*); analysis.edge_descriptors = total_edges * sizeof(edge_descriptor_runtime); // Property data sizing based on type analysis analysis.property_data = estimate_property_memory_usage(bundle, total_properties); // String cache with deduplication factor double dedup_factor = estimate_string_deduplication_factor(bundle); analysis.string_cache = (size_t)(total_string_bytes * dedup_factor * 1.2); // 20% overhead // Decompression buffers for compressed chunks analysis.decompression_buffers = calculate_decompression_buffer_size(bundle); // Prefetch buffers based on access patterns analysis.prefetch_buffers = calculate_prefetch_buffer_size( total_nodes, max_graph_depth); // Alignment padding for cache line optimization analysis.alignment_padding = align_to_cache_line(analysis.node_pointers) - analysis.node_pointers + align_to_cache_line(analysis.edge_descriptors) - analysis.edge_descriptors + 64 * 1024; // Additional alignment buffer // NUMA overhead for multi-node systems int numa_node_count = get_numa_node_count(); if (numa_node_count > 1) { analysis.numa_overhead = (analysis.node_pointers + analysis.edge_descriptors) * 0.1; // 10% overhead } // Guard pages for debugging builds #ifdef DEBUG analysis.guard_pages = 8 * get_page_size(); // 8 pages #endif // Safety buffer based on complexity double complexity_factor = calculate_bundle_complexity_factor(bundle); analysis.safety_buffer = (size_t)( (analysis.node_pointers + analysis.edge_descriptors + analysis.property_data) * complexity_factor * 0.15); // 15% safety margin // Total size calculation analysis.total_arena_size = analysis.node_pointers + analysis.edge_descriptors + analysis.property_data + analysis.string_cache + analysis.decompression_buffers + analysis.prefetch_buffers + analysis.alignment_padding + analysis.numa_overhead + analysis.guard_pages + analysis.safety_buffer; // Round up to optimal page boundary size_t page_size = get_optimal_page_size(analysis.total_arena_size); analysis.total_arena_size = ((analysis.total_arena_size + page_size - 1) / page_size) * page_size; // Performance predictions analysis.predicted_cache_hit_ratio = predict_cache_hit_ratio(total_nodes, max_graph_depth); analysis.predicted_page_faults = predict_page_fault_count(analysis.total_arena_size, page_size); analysis.predicted_allocation_time_ns = predict_allocation_time(analysis.total_arena_size, numa_node_count > 1); return analysis; } // High-performance arena allocation with platform optimizations arena_allocator* create_optimized_arena(const arena_sizing_analysis* sizing) { arena_allocator* arena = malloc(sizeof(arena_allocator)); memset(arena, 0, sizeof(arena_allocator)); arena->total_size = sizing->total_arena_size; arena->alignment = 64; // Cache line alignment arena->numa_node = get_current_numa_node(); arena->use_huge_pages = sizing->total_arena_size >= 2 * 1024 * 1024; arena->use_guard_pages = sizing->guard_pages > 0; #ifdef __linux__ // Linux-specific optimizations int flags = MAP_PRIVATE | MAP_ANONYMOUS; if (arena->use_huge_pages) { flags |= MAP_HUGETLB; } #ifdef HAVE_NUMA if (get_numa_node_count() > 1) { // Allocate on specific NUMA node arena->base_address = numa_alloc_onnode(arena->total_size, arena->numa_node); } else #endif { arena->base_address = mmap(NULL, arena->total_size, PROT_READ | PROT_WRITE, flags, -1, 0); } if (arena->base_address == MAP_FAILED) { // Fallback without huge pages arena->use_huge_pages = false; arena->base_address = mmap(NULL, arena->total_size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); } if (arena->base_address != MAP_FAILED) { // Provide memory access hints madvise(arena->base_address, arena->total_size, MADV_SEQUENTIAL); if (arena->use_huge_pages) { madvise(arena->base_address, arena->total_size, MADV_HUGEPAGE); } } #elif defined(_WIN32) // Windows-specific optimizations DWORD flags = MEM_COMMIT | MEM_RESERVE; if (arena->use_huge_pages && check_large_page_privilege()) { flags |= MEM_LARGE_PAGES; arena->base_address = VirtualAlloc(NULL, arena->total_size, flags, PAGE_READWRITE); if (!arena->base_address) { // Fallback without large pages arena->use_huge_pages = false; arena->base_address = VirtualAlloc(NULL, arena->total_size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); } } else { arena->base_address = VirtualAlloc(NULL, arena->total_size, flags, PAGE_READWRITE); } #elif defined(__APPLE__) // macOS-specific optimizations arena->base_address = mmap(NULL, arena->total_size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); if (arena->base_address != MAP_FAILED) { // macOS memory hints madvise(arena->base_address, arena->total_size, MADV_SEQUENTIAL); } #else // Generic Unix allocation arena->base_address = mmap(NULL, arena->total_size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); #endif if (!arena->base_address) { free(arena); return NULL; } // Initialize free list with entire arena arena->free_list = (struct free_block*)arena->base_address; arena->free_list->size = arena->total_size; arena->free_list->next = NULL; // Setup allocation tracking for debug builds #ifdef DEBUG arena->max_allocations = 10000; arena->allocations = malloc(arena->max_allocations * sizeof(struct allocation_info)); #endif return arena; } // Cache-friendly allocation with alignment void* arena_alloc_aligned(arena_allocator* arena, size_t size, size_t alignment) { if (!arena || size == 0) { return NULL; } // Align size to minimum alignment size = (size + alignment - 1) & ~(alignment - 1); // Find suitable free block struct free_block** current = &arena->free_list; while (*current) { struct free_block* block = *current; // Calculate aligned address within this block uintptr_t block_addr = (uintptr_t)block; uintptr_t aligned_addr = (block_addr + alignment - 1) & ~(alignment - 1); size_t alignment_overhead = aligned_addr - block_addr; if (block->size >= size + alignment_overhead) { // Found suitable block void* result = (void*)aligned_addr; // Update free list if (block->size == size + alignment_overhead) { // Exact fit - remove block from free list *current = block->next; } else { // Split block struct free_block* new_block = (struct free_block*)(aligned_addr + size); new_block->size = block->size - size - alignment_overhead; new_block->next = block->next; *current = new_block; } arena->used_size += size + alignment_overhead; arena->total_allocations++; arena->bytes_allocated += size; arena->peak_usage = max(arena->peak_usage, arena->used_size); // Track allocation for debugging #ifdef DEBUG if (arena->allocation_count < arena->max_allocations) { arena->allocations[arena->allocation_count] = (struct allocation_info) { .address = result, .size = size, .timestamp = get_timestamp_ns() }; arena->allocation_count++; } #endif return result; } current = &block->next; } // No suitable block found return NULL; } ``` ### Advanced Asynchronous I/O #### Linux io_uring Implementation with Performance Optimization ```c #ifdef HAVE_IO_URING typedef struct { struct io_uring ring; // io_uring instance uint32_t queue_depth; // Maximum concurrent operations uint32_t pending_ops; // Currently pending operations // Performance optimization struct iovec* iovecs; // Pre-allocated I/O vectors void** buffers; // Pre-allocated buffers uint32_t* chunk_indices; // Chunk index tracking // Advanced features bool use_registered_buffers; // Use io_uring buffer registration bool use_kernel_polling; // Use kernel-side polling bool use_sqe_async; // Use SQE async mode // Performance monitoring uint64_t total_operations; uint64_t total_bytes_read; uint64_t total_wait_time_ns; double average_latency_ns; // Error handling uint32_t error_count; uint32_t timeout_count; uint32_t retry_count; } advanced_async_io; bool setup_advanced_async_io(advanced_async_io* ctx, uint32_t queue_depth) { ctx->queue_depth = queue_depth; ctx->pending_ops = 0; // Setup io_uring with advanced features struct io_uring_params params; memset(&params, 0, sizeof(params)); // Enable advanced features if available params.flags = IORING_SETUP_CQSIZE | IORING_SETUP_CLAMP; params.cq_entries = queue_depth * 2; // Larger completion queue // Try to enable kernel polling for low latency if (ctx->use_kernel_polling) { params.flags |= IORING_SETUP_IOPOLL; } int ret = io_uring_queue_init_params(queue_depth, &ctx->ring, &params); if (ret < 0) { // Fallback to basic io_uring ret = io_uring_queue_init(queue_depth, &ctx->ring, 0); if (ret < 0) { return false; } ctx->use_kernel_polling = false; } // Pre-allocate I/O structures for performance ctx->iovecs = malloc(queue_depth * sizeof(struct iovec)); ctx->buffers = malloc(queue_depth * sizeof(void*)); ctx->chunk_indices = malloc(queue_depth * sizeof(uint32_t)); if (!ctx->iovecs || !ctx->buffers || !ctx->chunk_indices) { io_uring_queue_exit(&ctx->ring); free(ctx->iovecs); free(ctx->buffers); free(ctx->chunk_indices); return false; } // Pre-allocate aligned buffers for (uint32_t i = 0; i < queue_depth; i++) { ctx->buffers[i] = aligned_alloc(4096, 1024 * 1024); // 1MB aligned buffers if (!ctx->buffers[i]) { // Cleanup on failure for (uint32_t j = 0; j < i; j++) { free(ctx->buffers[j]); } io_uring_queue_exit(&ctx->ring); free(ctx->iovecs); free(ctx->buffers); free(ctx->chunk_indices); return false; } } // Register buffers with kernel for zero-copy if (ctx->use_registered_buffers) { ret = io_uring_register_buffers(&ctx->ring, ctx->iovecs, queue_depth); if (ret < 0) { ctx->use_registered_buffers = false; } } return true; } void queue_optimized_read( advanced_async_io* ctx, int fd, uint32_t chunk_index, size_t size, off_t offset ) { if (ctx->pending_ops >= ctx->queue_depth) { // Wait for at least one completion wait_for_completions(ctx, 1); } uint32_t op_index = ctx->pending_ops; // Setup I/O vector ctx->iovecs[op_index].iov_base = ctx->buffers[op_index]; ctx->iovecs[op_index].iov_len = min(size,`, `file_path`: `/home/user/git/graphite/spec_claude.md` }